{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/site-packages/theano/tensor/signal/downsample.py:6: UserWarning: downsample module has been moved to the theano.tensor.signal.pool module.\n",
      "  \"downsample module has been moved to the theano.tensor.signal.pool module.\")\n"
     ]
    }
   ],
   "source": [
    "%matplotlib nbagg\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from ProbabilisticDynamicsModel import *\n",
    "from utils import *\n",
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-08-04 17:01:08.945616 PDT | Warning: skipping Gym environment monitoring since snapshot_dir not configured.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-08-04 17:01:08,947] Making new env: Reacher-v1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-08-04 17:01:09.348993 PDT | observation space: Box(11,)\n",
      "2017-08-04 17:01:09.350009 PDT | action space: Box(2,)\n",
      "2017-08-04 17:01:10.857294 PDT | Populating workers...\n",
      "2017-08-04 17:01:10.859198 PDT | Populated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0%                          100%\n",
      "[##############################] | ETA: 00:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-08-04 17:01:13.198973 PDT | itr #0 | fitting baseline...\n",
      "2017-08-04 17:01:13.206541 PDT | itr #0 | fitted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Total time elapsed: 00:00:02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m=: Compiling function f_loss\u001b[0m\n",
      "\u001b[35mdone in 0.484 seconds\u001b[0m\n",
      "\u001b[35m=: Compiling function constraint\u001b[0m\n",
      "\u001b[35mdone in 0.281 seconds\u001b[0m\n",
      "2017-08-04 17:01:13.978962 PDT | itr #0 | computing loss before\n",
      "2017-08-04 17:01:13.981602 PDT | itr #0 | performing update\n",
      "2017-08-04 17:01:13.982716 PDT | itr #0 | computing descent direction\n",
      "\u001b[35m=: Compiling function f_grad\u001b[0m\n",
      "\u001b[35mdone in 0.800 seconds\u001b[0m\n",
      "\u001b[35m=: Compiling function f_Hx_plain\u001b[0m\n",
      "\u001b[35mdone in 1.867 seconds\u001b[0m\n",
      "2017-08-04 17:01:16.823981 PDT | itr #0 | descent direction computed\n",
      "\u001b[35m=: Compiling function f_loss_constraint\u001b[0m\n",
      "\u001b[35mdone in 0.408 seconds\u001b[0m\n",
      "2017-08-04 17:01:17.238692 PDT | itr #0 | backtrack iters: 1\n",
      "2017-08-04 17:01:17.239750 PDT | itr #0 | computing loss after\n",
      "2017-08-04 17:01:17.241081 PDT | itr #0 | optimization finished\n",
      "2017-08-04 17:01:17.246652 PDT | itr #0 | saving snapshot...\n",
      "2017-08-04 17:01:17.247778 PDT | itr #0 | saved\n",
      "2017-08-04 17:01:17.249608 PDT | -----------------------  -------------\n",
      "2017-08-04 17:01:17.250832 PDT | Iteration                  0\n",
      "2017-08-04 17:01:17.251864 PDT | AverageDiscountedReturn  -51.994\n",
      "2017-08-04 17:01:17.253052 PDT | AverageReturn            -65.6215\n",
      "2017-08-04 17:01:17.254183 PDT | ExplainedVariance          4.36323e-11\n",
      "2017-08-04 17:01:17.255192 PDT | NumTrajs                  80\n",
      "2017-08-04 17:01:17.256205 PDT | Entropy                    2.83788\n",
      "2017-08-04 17:01:17.257147 PDT | Perplexity                17.0795\n",
      "2017-08-04 17:01:17.258135 PDT | StdReturn                  3.93172\n",
      "2017-08-04 17:01:17.259089 PDT | MaxReturn                -58.4642\n",
      "2017-08-04 17:01:17.260066 PDT | MinReturn                -76.7211\n",
      "2017-08-04 17:01:17.260987 PDT | AveragePolicyStd           1\n",
      "2017-08-04 17:01:17.262023 PDT | LossBefore                -1.02141e-16\n",
      "2017-08-04 17:01:17.263027 PDT | LossAfter                 -0.0110186\n",
      "2017-08-04 17:01:17.263982 PDT | MeanKLBefore               0\n",
      "2017-08-04 17:01:17.264944 PDT | MeanKL                     0.00665569\n",
      "2017-08-04 17:01:17.265926 PDT | dLoss                      0.0110186\n",
      "2017-08-04 17:01:17.266831 PDT | -----------------------  -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0%                          100%\n",
      "[##############################] | ETA: 00:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-08-04 17:01:19.479960 PDT | itr #1 | fitting baseline...\n",
      "2017-08-04 17:01:19.488528 PDT | itr #1 | fitted\n",
      "2017-08-04 17:01:19.494476 PDT | itr #1 | computing loss before\n",
      "2017-08-04 17:01:19.497526 PDT | itr #1 | performing update\n",
      "2017-08-04 17:01:19.498649 PDT | itr #1 | computing descent direction\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Total time elapsed: 00:00:02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-08-04 17:01:19.556396 PDT | itr #1 | descent direction computed\n",
      "2017-08-04 17:01:19.562474 PDT | itr #1 | backtrack iters: 1\n",
      "2017-08-04 17:01:19.563522 PDT | itr #1 | computing loss after\n",
      "2017-08-04 17:01:19.564434 PDT | itr #1 | optimization finished\n",
      "2017-08-04 17:01:19.569043 PDT | itr #1 | saving snapshot...\n",
      "2017-08-04 17:01:19.570025 PDT | itr #1 | saved\n",
      "2017-08-04 17:01:19.571852 PDT | -----------------------  -------------\n",
      "2017-08-04 17:01:19.572833 PDT | Iteration                  1\n",
      "2017-08-04 17:01:19.573860 PDT | AverageDiscountedReturn  -52.1396\n",
      "2017-08-04 17:01:19.574835 PDT | AverageReturn            -65.8196\n",
      "2017-08-04 17:01:19.575769 PDT | ExplainedVariance          0.969595\n",
      "2017-08-04 17:01:19.576680 PDT | NumTrajs                  80\n",
      "2017-08-04 17:01:19.577620 PDT | Entropy                    2.82106\n",
      "2017-08-04 17:01:19.578508 PDT | Perplexity                16.7946\n",
      "2017-08-04 17:01:19.579425 PDT | StdReturn                  4.28591\n",
      "2017-08-04 17:01:19.580319 PDT | MaxReturn                -55.8863\n",
      "2017-08-04 17:01:19.581427 PDT | MinReturn                -73.8861\n",
      "2017-08-04 17:01:19.582400 PDT | AveragePolicyStd           0.991647\n",
      "2017-08-04 17:01:19.583254 PDT | LossBefore                -9.57845e-17\n",
      "2017-08-04 17:01:19.584161 PDT | LossAfter                 -0.0205823\n",
      "2017-08-04 17:01:19.585141 PDT | MeanKLBefore               0\n",
      "2017-08-04 17:01:19.586277 PDT | MeanKL                     0.00681521\n",
      "2017-08-04 17:01:19.587458 PDT | dLoss                      0.0205823\n",
      "2017-08-04 17:01:19.588432 PDT | -----------------------  -------------\n"
     ]
    }
   ],
   "source": [
    "transitions = sample_transitions_rl('Reacher-v1',2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_dim = transitions[\"x\"].shape[1]\n",
    "u_dim = transitions[\"u\"].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 0, shape [None, None, 128]\n"
     ]
    }
   ],
   "source": [
    "run_config = tf.ConfigProto()\n",
    "run_config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config = run_config)\n",
    "\n",
    "pdm = LocallyLinearPDM(sess, x_dim, u_dim,\n",
    "                       hidden_layer_sizes=[128],\n",
    "                       dropout_prob=0.3,\n",
    "                       num_mc_samples=50,\n",
    "                       filename='mujoco_test_ll_2',\n",
    "                       writer_path='tf_logs')\n",
    "pdm.build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "locallylinear_pdm Tensor(\"beta1:0\", shape=(), dtype=float32)\n",
      "Training with 5488 input/target pairs.\n",
      "Epoch: [ 0] [   0/ 548] time: 0.1685, train_loss: 442228.31250000, val_loss: 806876.00000000\n",
      "Saving checkpoint\n",
      "Epoch: [ 0] [  10/ 548] time: 1.5400, train_loss: 394124.06250000, val_loss: 425164.59375000\n",
      "Epoch: [ 0] [  20/ 548] time: 1.8095, train_loss: 156664.10937500, val_loss: 272259.50000000\n",
      "Epoch: [ 0] [  30/ 548] time: 2.0468, train_loss: 249000.53125000, val_loss: 231167.04687500\n",
      "Epoch: [ 0] [  40/ 548] time: 2.2884, train_loss: 308611.96875000, val_loss: 210486.32812500\n",
      "Epoch: [ 0] [  50/ 548] time: 2.5224, train_loss: 383613.84375000, val_loss: 205481.01562500\n",
      "Epoch: [ 0] [  60/ 548] time: 2.7549, train_loss: 324192.71875000, val_loss: 175303.89062500\n",
      "Epoch: [ 0] [  70/ 548] time: 2.9793, train_loss: 132017.50000000, val_loss: 169053.26562500\n",
      "Epoch: [ 0] [  80/ 548] time: 3.2100, train_loss: 509588.50000000, val_loss: 171921.12500000\n",
      "Epoch: [ 0] [  90/ 548] time: 3.4448, train_loss: 506230.68750000, val_loss: 145776.64062500\n",
      "Epoch: [ 0] [ 100/ 548] time: 3.6731, train_loss: 199696.64062500, val_loss: 148947.81250000\n",
      "Epoch: [ 0] [ 110/ 548] time: 3.9009, train_loss: 214888.18750000, val_loss: 144452.35937500\n",
      "Epoch: [ 0] [ 120/ 548] time: 4.1304, train_loss: 51541.95312500, val_loss: 119860.85937500\n",
      "Epoch: [ 0] [ 130/ 548] time: 4.3847, train_loss: 169349.14062500, val_loss: 126181.65625000\n",
      "Epoch: [ 0] [ 140/ 548] time: 4.6578, train_loss: 61501.41015625, val_loss: 118912.56250000\n",
      "Epoch: [ 0] [ 150/ 548] time: 4.9168, train_loss: 102157.35156250, val_loss: 113294.92187500\n",
      "Epoch: [ 0] [ 160/ 548] time: 5.1588, train_loss: 92404.47656250, val_loss: 109107.13281250\n",
      "Epoch: [ 0] [ 170/ 548] time: 5.4094, train_loss: 56047.55859375, val_loss: 111702.01562500\n",
      "Epoch: [ 0] [ 180/ 548] time: 5.6495, train_loss: 164122.10937500, val_loss: 99363.04687500\n",
      "Epoch: [ 0] [ 190/ 548] time: 5.8795, train_loss: 112776.16406250, val_loss: 88863.71875000\n",
      "Epoch: [ 0] [ 200/ 548] time: 6.1063, train_loss: 38007.74609375, val_loss: 88184.00000000\n",
      "Epoch: [ 0] [ 210/ 548] time: 6.3309, train_loss: 37657.04687500, val_loss: 80318.78906250\n",
      "Epoch: [ 0] [ 220/ 548] time: 6.5589, train_loss: 124985.11718750, val_loss: 78134.79687500\n",
      "Epoch: [ 0] [ 230/ 548] time: 6.7860, train_loss: 174275.25000000, val_loss: 77678.78125000\n",
      "Epoch: [ 0] [ 240/ 548] time: 7.0154, train_loss: 50548.06640625, val_loss: 73936.35156250\n",
      "Epoch: [ 0] [ 250/ 548] time: 7.2525, train_loss: 217934.51562500, val_loss: 69679.73437500\n",
      "Epoch: [ 0] [ 260/ 548] time: 7.4882, train_loss: 99810.04687500, val_loss: 63629.16406250\n",
      "Epoch: [ 0] [ 270/ 548] time: 7.7338, train_loss: 59450.91406250, val_loss: 65725.24218750\n",
      "Epoch: [ 0] [ 280/ 548] time: 7.9638, train_loss: 82892.72656250, val_loss: 62891.35156250\n",
      "Epoch: [ 0] [ 290/ 548] time: 8.1924, train_loss: 74319.33593750, val_loss: 61328.04687500\n",
      "Epoch: [ 0] [ 300/ 548] time: 8.4271, train_loss: 59897.88281250, val_loss: 60817.98437500\n",
      "Epoch: [ 0] [ 310/ 548] time: 8.6615, train_loss: 33508.60156250, val_loss: 55032.62500000\n",
      "Epoch: [ 0] [ 320/ 548] time: 8.9097, train_loss: 88063.33593750, val_loss: 57369.67187500\n",
      "Epoch: [ 0] [ 330/ 548] time: 9.1447, train_loss: 73824.89843750, val_loss: 49926.38281250\n",
      "Epoch: [ 0] [ 340/ 548] time: 9.3994, train_loss: 110240.44531250, val_loss: 50236.65625000\n",
      "Epoch: [ 0] [ 350/ 548] time: 9.6349, train_loss: 100606.51562500, val_loss: 39204.95703125\n",
      "Epoch: [ 0] [ 360/ 548] time: 9.8709, train_loss: 30982.37500000, val_loss: 45226.88671875\n",
      "Epoch: [ 0] [ 370/ 548] time: 10.1293, train_loss: 41813.17187500, val_loss: 39980.83984375\n",
      "Epoch: [ 0] [ 380/ 548] time: 10.3993, train_loss: 35354.65625000, val_loss: 36417.41406250\n",
      "Epoch: [ 0] [ 390/ 548] time: 10.6489, train_loss: 69458.48437500, val_loss: 38794.58984375\n",
      "Epoch: [ 0] [ 400/ 548] time: 10.9142, train_loss: 41453.55078125, val_loss: 34932.55468750\n",
      "Epoch: [ 0] [ 410/ 548] time: 11.1786, train_loss: 37689.10937500, val_loss: 35136.01562500\n",
      "Epoch: [ 0] [ 420/ 548] time: 11.4502, train_loss: 48844.11328125, val_loss: 30175.54101562\n",
      "Epoch: [ 0] [ 430/ 548] time: 11.7210, train_loss: 61126.13671875, val_loss: 32099.77929688\n",
      "Epoch: [ 0] [ 440/ 548] time: 11.9785, train_loss: 11118.95898438, val_loss: 30709.24023438\n",
      "Epoch: [ 0] [ 450/ 548] time: 12.2547, train_loss: 55291.45703125, val_loss: 30536.01953125\n",
      "Epoch: [ 0] [ 460/ 548] time: 12.5064, train_loss: 56503.17187500, val_loss: 26851.99218750\n",
      "Epoch: [ 0] [ 470/ 548] time: 12.7458, train_loss: 63771.33203125, val_loss: 29795.84179688\n",
      "Epoch: [ 0] [ 480/ 548] time: 12.9879, train_loss: 79897.25781250, val_loss: 29070.01562500\n",
      "Epoch: [ 0] [ 490/ 548] time: 13.2402, train_loss: 43190.03906250, val_loss: 26130.95117188\n",
      "Epoch: [ 0] [ 500/ 548] time: 13.4813, train_loss: 34327.17968750, val_loss: 26095.78125000\n",
      "Epoch: [ 0] [ 510/ 548] time: 13.7231, train_loss: 6694.19042969, val_loss: 24479.58593750\n",
      "Epoch: [ 0] [ 520/ 548] time: 13.9745, train_loss: 54973.34765625, val_loss: 22440.50195312\n",
      "Epoch: [ 0] [ 530/ 548] time: 14.2297, train_loss: 42030.21484375, val_loss: 22106.25195312\n",
      "Epoch: [ 0] [ 540/ 548] time: 14.4748, train_loss: 49372.81250000, val_loss: 21233.24023438\n",
      "Epoch: [ 1] [   0/ 548] time: 14.6767, train_loss: 29045.67578125, val_loss: 19628.89648438\n",
      "Epoch: [ 1] [  10/ 548] time: 14.9470, train_loss: 84750.03906250, val_loss: 19557.40234375\n",
      "Epoch: [ 1] [  20/ 548] time: 15.2257, train_loss: 14092.19140625, val_loss: 19202.69140625\n",
      "Epoch: [ 1] [  30/ 548] time: 15.5129, train_loss: 38422.05859375, val_loss: 20529.08984375\n",
      "Epoch: [ 1] [  40/ 548] time: 15.7932, train_loss: 33692.26171875, val_loss: 18272.19140625\n",
      "Epoch: [ 1] [  50/ 548] time: 16.0740, train_loss: 16636.94726562, val_loss: 17047.72460938\n",
      "Epoch: [ 1] [  60/ 548] time: 16.3557, train_loss: 32805.78515625, val_loss: 16906.09375000\n",
      "Epoch: [ 1] [  70/ 548] time: 16.6262, train_loss: 30322.11718750, val_loss: 17573.30078125\n",
      "Epoch: [ 1] [  80/ 548] time: 16.9147, train_loss: 18721.47656250, val_loss: 15632.54980469\n",
      "Epoch: [ 1] [  90/ 548] time: 17.2370, train_loss: 20638.69531250, val_loss: 15120.75000000\n",
      "Epoch: [ 1] [ 100/ 548] time: 17.5560, train_loss: 11833.71191406, val_loss: 14933.31445312\n",
      "Epoch: [ 1] [ 110/ 548] time: 17.8652, train_loss: 20128.82226562, val_loss: 14410.71582031\n",
      "Epoch: [ 1] [ 120/ 548] time: 18.1728, train_loss: 59753.64843750, val_loss: 13628.99511719\n",
      "Epoch: [ 1] [ 130/ 548] time: 18.4673, train_loss: 8898.15722656, val_loss: 13364.39648438\n",
      "Epoch: [ 1] [ 140/ 548] time: 18.7323, train_loss: 43473.11328125, val_loss: 13946.29687500\n",
      "Epoch: [ 1] [ 150/ 548] time: 18.9940, train_loss: 10281.23632812, val_loss: 12005.36328125\n",
      "Epoch: [ 1] [ 160/ 548] time: 19.2712, train_loss: 8247.90332031, val_loss: 11901.29199219\n",
      "Epoch: [ 1] [ 170/ 548] time: 19.5403, train_loss: 31203.02539062, val_loss: 11257.00488281\n",
      "Epoch: [ 1] [ 180/ 548] time: 19.8065, train_loss: 39953.73046875, val_loss: 11683.25097656\n",
      "Epoch: [ 1] [ 190/ 548] time: 20.0825, train_loss: 9704.70019531, val_loss: 11423.41308594\n",
      "Epoch: [ 1] [ 200/ 548] time: 20.3522, train_loss: 7957.88525391, val_loss: 10551.70800781\n",
      "Epoch: [ 1] [ 210/ 548] time: 20.6028, train_loss: 14994.36425781, val_loss: 9750.49023438\n",
      "Epoch: [ 1] [ 220/ 548] time: 20.8574, train_loss: 11841.14257812, val_loss: 10062.96386719\n",
      "Epoch: [ 1] [ 230/ 548] time: 21.1311, train_loss: 8291.76074219, val_loss: 9771.04785156\n",
      "Epoch: [ 1] [ 240/ 548] time: 21.4052, train_loss: 17029.89648438, val_loss: 9243.81152344\n",
      "Epoch: [ 1] [ 250/ 548] time: 21.6828, train_loss: 4599.67919922, val_loss: 9407.58398438\n",
      "Epoch: [ 1] [ 260/ 548] time: 21.9689, train_loss: 7244.49902344, val_loss: 8630.48925781\n",
      "Epoch: [ 1] [ 270/ 548] time: 22.2434, train_loss: 13198.72460938, val_loss: 8448.47558594\n",
      "Epoch: [ 1] [ 280/ 548] time: 22.5183, train_loss: 31759.19726562, val_loss: 8453.54394531\n",
      "Epoch: [ 1] [ 290/ 548] time: 22.7937, train_loss: 10415.93457031, val_loss: 7894.97705078\n",
      "Epoch: [ 1] [ 300/ 548] time: 23.0712, train_loss: 13786.62792969, val_loss: 7752.39355469\n",
      "Epoch: [ 1] [ 310/ 548] time: 23.3902, train_loss: 5503.22460938, val_loss: 7037.35400391\n",
      "Epoch: [ 1] [ 320/ 548] time: 23.7205, train_loss: 14760.11523438, val_loss: 6957.41308594\n",
      "Epoch: [ 1] [ 330/ 548] time: 24.0419, train_loss: 8003.74511719, val_loss: 7576.73046875\n",
      "Epoch: [ 1] [ 340/ 548] time: 24.3684, train_loss: 4914.97314453, val_loss: 6541.62353516\n",
      "Epoch: [ 1] [ 350/ 548] time: 24.7596, train_loss: 3458.67138672, val_loss: 6480.24511719\n",
      "Epoch: [ 1] [ 360/ 548] time: 25.1256, train_loss: 14437.56347656, val_loss: 6466.27001953\n",
      "Epoch: [ 1] [ 370/ 548] time: 25.4236, train_loss: 3077.87475586, val_loss: 6843.58740234\n",
      "Epoch: [ 1] [ 380/ 548] time: 25.7465, train_loss: 2625.05444336, val_loss: 6192.23486328\n",
      "Epoch: [ 1] [ 390/ 548] time: 26.0432, train_loss: 3297.30126953, val_loss: 6366.25341797\n",
      "Epoch: [ 1] [ 400/ 548] time: 26.3166, train_loss: 25500.43164062, val_loss: 5827.46484375\n",
      "Epoch: [ 1] [ 410/ 548] time: 26.6015, train_loss: 5858.09960938, val_loss: 5735.33935547\n",
      "Epoch: [ 1] [ 420/ 548] time: 26.8968, train_loss: 4954.18652344, val_loss: 6095.79541016\n",
      "Epoch: [ 1] [ 430/ 548] time: 27.1926, train_loss: 2291.46655273, val_loss: 5562.93701172\n",
      "Epoch: [ 1] [ 440/ 548] time: 27.5088, train_loss: 7940.39550781, val_loss: 5526.30078125\n",
      "Epoch: [ 1] [ 450/ 548] time: 27.8292, train_loss: 9314.69824219, val_loss: 5437.43847656\n",
      "Saving checkpoint\n",
      "Epoch: [ 1] [ 460/ 548] time: 29.4280, train_loss: 10294.57128906, val_loss: 5174.80029297\n",
      "Epoch: [ 1] [ 470/ 548] time: 29.7334, train_loss: 9796.48730469, val_loss: 4935.80078125\n",
      "Epoch: [ 1] [ 480/ 548] time: 30.0746, train_loss: 12416.64453125, val_loss: 5056.90966797\n",
      "Epoch: [ 1] [ 490/ 548] time: 30.3870, train_loss: 10055.32910156, val_loss: 4793.06445312\n",
      "Epoch: [ 1] [ 500/ 548] time: 30.7472, train_loss: 4794.40185547, val_loss: 4740.81250000\n",
      "Epoch: [ 1] [ 510/ 548] time: 31.1293, train_loss: 6055.58691406, val_loss: 4684.69824219\n",
      "Epoch: [ 1] [ 520/ 548] time: 31.4512, train_loss: 11593.64062500, val_loss: 4580.28369141\n",
      "Epoch: [ 1] [ 530/ 548] time: 31.7722, train_loss: 4234.81542969, val_loss: 4948.28564453\n",
      "Epoch: [ 1] [ 540/ 548] time: 32.1223, train_loss: 5747.55615234, val_loss: 4485.49462891\n",
      "Epoch: [ 2] [   0/ 548] time: 32.4213, train_loss: 4081.42529297, val_loss: 4410.95361328\n",
      "Epoch: [ 2] [  10/ 548] time: 32.6991, train_loss: 7637.56054688, val_loss: 4147.83105469\n",
      "Epoch: [ 2] [  20/ 548] time: 33.0100, train_loss: 6945.24316406, val_loss: 4047.57934570\n",
      "Epoch: [ 2] [  30/ 548] time: 33.2876, train_loss: 3468.77148438, val_loss: 3984.35937500\n",
      "Epoch: [ 2] [  40/ 548] time: 33.5557, train_loss: 4459.42285156, val_loss: 3963.22167969\n",
      "Epoch: [ 2] [  50/ 548] time: 33.8762, train_loss: 3768.20971680, val_loss: 3916.34106445\n",
      "Epoch: [ 2] [  60/ 548] time: 34.1995, train_loss: 5738.98925781, val_loss: 3901.84277344\n",
      "Epoch: [ 2] [  70/ 548] time: 34.5280, train_loss: 2222.66210938, val_loss: 3978.94628906\n",
      "Epoch: [ 2] [  80/ 548] time: 34.8787, train_loss: 3869.53930664, val_loss: 3878.50048828\n",
      "Epoch: [ 2] [  90/ 548] time: 35.2245, train_loss: 3216.22216797, val_loss: 3741.58398438\n",
      "Epoch: [ 2] [ 100/ 548] time: 35.5795, train_loss: 3471.00268555, val_loss: 3558.25073242\n",
      "Epoch: [ 2] [ 110/ 548] time: 35.9129, train_loss: 5941.24462891, val_loss: 3504.78198242\n",
      "Epoch: [ 2] [ 120/ 548] time: 36.2575, train_loss: 2053.88598633, val_loss: 3383.06835938\n",
      "Epoch: [ 2] [ 130/ 548] time: 36.6038, train_loss: 2951.65844727, val_loss: 3393.86743164\n",
      "Epoch: [ 2] [ 140/ 548] time: 36.9594, train_loss: 3086.59252930, val_loss: 3353.94628906\n",
      "Epoch: [ 2] [ 150/ 548] time: 37.2851, train_loss: 6102.47753906, val_loss: 3246.51586914\n",
      "Epoch: [ 2] [ 160/ 548] time: 37.6297, train_loss: 1744.67858887, val_loss: 3352.83691406\n",
      "Epoch: [ 2] [ 170/ 548] time: 37.9270, train_loss: 4551.35205078, val_loss: 3106.20727539\n",
      "Epoch: [ 2] [ 180/ 548] time: 38.2023, train_loss: 3619.80590820, val_loss: 3182.20727539\n",
      "Epoch: [ 2] [ 190/ 548] time: 38.4773, train_loss: 3331.22509766, val_loss: 3217.29321289\n",
      "Epoch: [ 2] [ 200/ 548] time: 38.7242, train_loss: 6531.63232422, val_loss: 3230.51757812\n",
      "Epoch: [ 2] [ 210/ 548] time: 38.9933, train_loss: 4246.56103516, val_loss: 2964.96606445\n",
      "Epoch: [ 2] [ 220/ 548] time: 39.2674, train_loss: 2060.31274414, val_loss: 2982.00048828\n",
      "Epoch: [ 2] [ 230/ 548] time: 39.5417, train_loss: 2011.76806641, val_loss: 2882.72558594\n",
      "Epoch: [ 2] [ 240/ 548] time: 39.8139, train_loss: 4886.49072266, val_loss: 2947.60229492\n",
      "Epoch: [ 2] [ 250/ 548] time: 40.0831, train_loss: 4749.78173828, val_loss: 2827.47290039\n",
      "Epoch: [ 2] [ 260/ 548] time: 40.3442, train_loss: 2828.99804688, val_loss: 2958.99780273\n",
      "Epoch: [ 2] [ 270/ 548] time: 40.6085, train_loss: 2743.67846680, val_loss: 2776.05639648\n",
      "Epoch: [ 2] [ 280/ 548] time: 40.8693, train_loss: 1477.91296387, val_loss: 2727.25512695\n",
      "Epoch: [ 2] [ 290/ 548] time: 41.1093, train_loss: 3179.03637695, val_loss: 2750.00048828\n",
      "Epoch: [ 2] [ 300/ 548] time: 41.3700, train_loss: 5160.14892578, val_loss: 2572.34277344\n",
      "Epoch: [ 2] [ 310/ 548] time: 41.6351, train_loss: 2752.62524414, val_loss: 2651.10205078\n",
      "Epoch: [ 2] [ 320/ 548] time: 41.8838, train_loss: 3627.78784180, val_loss: 2706.99707031\n",
      "Epoch: [ 2] [ 330/ 548] time: 42.1455, train_loss: 2413.21533203, val_loss: 2523.14160156\n",
      "Epoch: [ 2] [ 340/ 548] time: 42.4017, train_loss: 2050.97656250, val_loss: 2588.13159180\n",
      "Epoch: [ 2] [ 350/ 548] time: 42.6548, train_loss: 1486.56188965, val_loss: 2596.69506836\n",
      "Epoch: [ 2] [ 360/ 548] time: 42.9047, train_loss: 2156.75952148, val_loss: 2415.32104492\n",
      "Epoch: [ 2] [ 370/ 548] time: 43.1526, train_loss: 4218.45214844, val_loss: 2466.58642578\n",
      "Epoch: [ 2] [ 380/ 548] time: 43.4380, train_loss: 1523.82922363, val_loss: 2368.13891602\n",
      "Epoch: [ 2] [ 390/ 548] time: 43.7357, train_loss: 6757.39404297, val_loss: 2339.10791016\n",
      "Epoch: [ 2] [ 400/ 548] time: 44.0118, train_loss: 3854.51318359, val_loss: 2309.42871094\n",
      "Epoch: [ 2] [ 410/ 548] time: 44.2947, train_loss: 2097.82080078, val_loss: 2322.27490234\n",
      "Epoch: [ 2] [ 420/ 548] time: 44.5950, train_loss: 5033.58203125, val_loss: 2285.27441406\n",
      "Epoch: [ 2] [ 430/ 548] time: 44.8844, train_loss: 2174.01391602, val_loss: 2222.99902344\n",
      "Epoch: [ 2] [ 440/ 548] time: 45.1501, train_loss: 3939.68823242, val_loss: 2208.91088867\n",
      "Epoch: [ 2] [ 450/ 548] time: 45.4166, train_loss: 1599.25598145, val_loss: 2194.99682617\n",
      "Epoch: [ 2] [ 460/ 548] time: 45.6611, train_loss: 2275.60327148, val_loss: 2176.37207031\n",
      "Epoch: [ 2] [ 470/ 548] time: 45.9127, train_loss: 1802.43676758, val_loss: 2141.81201172\n",
      "Epoch: [ 2] [ 480/ 548] time: 46.1563, train_loss: 2593.90551758, val_loss: 2136.34790039\n",
      "Epoch: [ 2] [ 490/ 548] time: 46.4108, train_loss: 1986.37878418, val_loss: 2061.26562500\n",
      "Epoch: [ 2] [ 500/ 548] time: 46.6664, train_loss: 1301.42065430, val_loss: 2041.31970215\n",
      "Epoch: [ 2] [ 510/ 548] time: 46.9226, train_loss: 2381.94702148, val_loss: 2028.66088867\n",
      "Epoch: [ 2] [ 520/ 548] time: 47.1830, train_loss: 4740.80419922, val_loss: 2079.70458984\n",
      "Epoch: [ 2] [ 530/ 548] time: 47.4214, train_loss: 1791.98754883, val_loss: 2015.43701172\n",
      "Epoch: [ 2] [ 540/ 548] time: 47.6587, train_loss: 5898.61914062, val_loss: 1953.55883789\n",
      "Epoch: [ 3] [   0/ 548] time: 47.8522, train_loss: 1849.52783203, val_loss: 1889.92321777\n",
      "Epoch: [ 3] [  10/ 548] time: 48.1133, train_loss: 2817.72119141, val_loss: 1907.35913086\n",
      "Epoch: [ 3] [  20/ 548] time: 48.3823, train_loss: 1595.84680176, val_loss: 1998.77905273\n",
      "Epoch: [ 3] [  30/ 548] time: 48.6509, train_loss: 1900.21984863, val_loss: 1923.80432129\n",
      "Epoch: [ 3] [  40/ 548] time: 48.9201, train_loss: 1590.09863281, val_loss: 1898.50073242\n",
      "Epoch: [ 3] [  50/ 548] time: 49.1938, train_loss: 1950.09936523, val_loss: 1926.94628906\n",
      "Epoch: [ 3] [  60/ 548] time: 49.4651, train_loss: 3320.34960938, val_loss: 1915.00695801\n",
      "Epoch: [ 3] [  70/ 548] time: 49.7304, train_loss: 3026.79150391, val_loss: 1855.62902832\n",
      "Epoch: [ 3] [  80/ 548] time: 50.0094, train_loss: 8594.86816406, val_loss: 1841.43518066\n",
      "Epoch: [ 3] [  90/ 548] time: 50.3209, train_loss: 1202.51135254, val_loss: 1798.14636230\n",
      "Epoch: [ 3] [ 100/ 548] time: 50.6253, train_loss: 2748.89184570, val_loss: 1836.37780762\n",
      "Epoch: [ 3] [ 110/ 548] time: 50.8971, train_loss: 1960.27380371, val_loss: 1795.45837402\n",
      "Epoch: [ 3] [ 120/ 548] time: 51.1512, train_loss: 2380.37939453, val_loss: 1732.37438965\n",
      "Epoch: [ 3] [ 130/ 548] time: 51.3919, train_loss: 1464.74365234, val_loss: 1739.34118652\n",
      "Epoch: [ 3] [ 140/ 548] time: 51.6242, train_loss: 1882.16772461, val_loss: 1738.84680176\n",
      "Epoch: [ 3] [ 150/ 548] time: 51.8731, train_loss: 1695.98999023, val_loss: 1757.41186523\n",
      "Epoch: [ 3] [ 160/ 548] time: 52.1445, train_loss: 1707.31091309, val_loss: 1631.87512207\n",
      "Epoch: [ 3] [ 170/ 548] time: 52.4317, train_loss: 1329.35009766, val_loss: 1645.69470215\n",
      "Epoch: [ 3] [ 180/ 548] time: 52.6805, train_loss: 1795.72949219, val_loss: 1609.72998047\n",
      "Epoch: [ 3] [ 190/ 548] time: 52.9182, train_loss: 2294.00927734, val_loss: 1580.90148926\n",
      "Epoch: [ 3] [ 200/ 548] time: 53.1520, train_loss: 1192.10241699, val_loss: 1603.44982910\n",
      "Epoch: [ 3] [ 210/ 548] time: 53.3882, train_loss: 863.75561523, val_loss: 1637.52148438\n",
      "Epoch: [ 3] [ 220/ 548] time: 53.6204, train_loss: 1022.89562988, val_loss: 1551.47290039\n",
      "Epoch: [ 3] [ 230/ 548] time: 53.8555, train_loss: 1257.64392090, val_loss: 1521.03894043\n",
      "Epoch: [ 3] [ 240/ 548] time: 54.0837, train_loss: 2253.76684570, val_loss: 1526.37084961\n",
      "Epoch: [ 3] [ 250/ 548] time: 54.3159, train_loss: 957.13134766, val_loss: 1510.00549316\n",
      "Epoch: [ 3] [ 260/ 548] time: 54.5510, train_loss: 1835.89270020, val_loss: 1465.88159180\n",
      "Epoch: [ 3] [ 270/ 548] time: 54.8074, train_loss: 1556.10742188, val_loss: 1484.13549805\n",
      "Epoch: [ 3] [ 280/ 548] time: 55.0811, train_loss: 2083.73706055, val_loss: 1494.32421875\n",
      "Epoch: [ 3] [ 290/ 548] time: 55.3417, train_loss: 1276.81567383, val_loss: 1477.00231934\n",
      "Epoch: [ 3] [ 300/ 548] time: 55.6029, train_loss: 932.20556641, val_loss: 1459.48278809\n",
      "Epoch: [ 3] [ 310/ 548] time: 55.8795, train_loss: 1063.53063965, val_loss: 1432.55200195\n",
      "Epoch: [ 3] [ 320/ 548] time: 56.1585, train_loss: 1876.15344238, val_loss: 1454.32397461\n",
      "Epoch: [ 3] [ 330/ 548] time: 56.4645, train_loss: 2612.82397461, val_loss: 1411.43627930\n",
      "Epoch: [ 3] [ 340/ 548] time: 56.7884, train_loss: 1227.80578613, val_loss: 1390.36889648\n",
      "Epoch: [ 3] [ 350/ 548] time: 57.1136, train_loss: 981.24841309, val_loss: 1418.59863281\n",
      "Saving checkpoint\n",
      "Epoch: [ 3] [ 360/ 548] time: 58.7165, train_loss: 1315.60437012, val_loss: 1372.34155273\n",
      "Epoch: [ 3] [ 370/ 548] time: 59.0853, train_loss: 1131.12805176, val_loss: 1376.60339355\n",
      "Epoch: [ 3] [ 380/ 548] time: 59.3893, train_loss: 979.68878174, val_loss: 1363.18005371\n",
      "Epoch: [ 3] [ 390/ 548] time: 59.6752, train_loss: 1052.27453613, val_loss: 1389.70935059\n",
      "Epoch: [ 3] [ 400/ 548] time: 59.9168, train_loss: 2144.84228516, val_loss: 1302.55725098\n",
      "Epoch: [ 3] [ 410/ 548] time: 60.1560, train_loss: 1900.81530762, val_loss: 1340.61682129\n",
      "Epoch: [ 3] [ 420/ 548] time: 60.4045, train_loss: 1183.36950684, val_loss: 1365.31896973\n",
      "Epoch: [ 3] [ 430/ 548] time: 60.6455, train_loss: 1526.12524414, val_loss: 1314.25329590\n",
      "Epoch: [ 3] [ 440/ 548] time: 60.8867, train_loss: 1318.66125488, val_loss: 1312.59863281\n",
      "Epoch: [ 3] [ 450/ 548] time: 61.1394, train_loss: 1789.17663574, val_loss: 1299.32849121\n",
      "Epoch: [ 3] [ 460/ 548] time: 61.3828, train_loss: 2942.78759766, val_loss: 1287.27490234\n",
      "Epoch: [ 3] [ 470/ 548] time: 61.6409, train_loss: 1454.94470215, val_loss: 1280.06848145\n",
      "Epoch: [ 3] [ 480/ 548] time: 61.8753, train_loss: 1693.73974609, val_loss: 1309.08312988\n",
      "Epoch: [ 3] [ 490/ 548] time: 62.1083, train_loss: 2483.21630859, val_loss: 1262.48510742\n",
      "Epoch: [ 3] [ 500/ 548] time: 62.3613, train_loss: 1153.84716797, val_loss: 1277.42968750\n",
      "Epoch: [ 3] [ 510/ 548] time: 62.5961, train_loss: 1238.71337891, val_loss: 1284.27282715\n",
      "Epoch: [ 3] [ 520/ 548] time: 62.8625, train_loss: 939.06665039, val_loss: 1254.44799805\n",
      "Epoch: [ 3] [ 530/ 548] time: 63.1248, train_loss: 1103.34655762, val_loss: 1224.74084473\n",
      "Epoch: [ 3] [ 540/ 548] time: 63.3807, train_loss: 883.00421143, val_loss: 1173.53625488\n",
      "Epoch: [ 4] [   0/ 548] time: 63.5716, train_loss: 1942.16564941, val_loss: 1174.83300781\n",
      "Epoch: [ 4] [  10/ 548] time: 63.8059, train_loss: 1184.33898926, val_loss: 1176.18408203\n",
      "Epoch: [ 4] [  20/ 548] time: 64.0376, train_loss: 1567.31787109, val_loss: 1165.70251465\n",
      "Epoch: [ 4] [  30/ 548] time: 64.2715, train_loss: 856.52410889, val_loss: 1153.07946777\n",
      "Epoch: [ 4] [  40/ 548] time: 64.5125, train_loss: 1059.06042480, val_loss: 1132.29736328\n",
      "Epoch: [ 4] [  50/ 548] time: 64.7469, train_loss: 1024.51745605, val_loss: 1160.98486328\n",
      "Epoch: [ 4] [  60/ 548] time: 64.9764, train_loss: 1159.32568359, val_loss: 1138.49804688\n",
      "Epoch: [ 4] [  70/ 548] time: 65.2040, train_loss: 1116.12280273, val_loss: 1148.50891113\n",
      "Epoch: [ 4] [  80/ 548] time: 65.4996, train_loss: 1038.24182129, val_loss: 1149.10229492\n",
      "Epoch: [ 4] [  90/ 548] time: 65.7592, train_loss: 2550.08715820, val_loss: 1126.51757812\n",
      "Epoch: [ 4] [ 100/ 548] time: 66.0087, train_loss: 2357.47875977, val_loss: 1131.61791992\n",
      "Epoch: [ 4] [ 110/ 548] time: 66.2587, train_loss: 1227.58801270, val_loss: 1087.23022461\n",
      "Epoch: [ 4] [ 120/ 548] time: 66.5206, train_loss: 965.33068848, val_loss: 1061.53881836\n",
      "Epoch: [ 4] [ 130/ 548] time: 66.7832, train_loss: 1208.97045898, val_loss: 1094.80078125\n",
      "Epoch: [ 4] [ 140/ 548] time: 67.0482, train_loss: 946.27484131, val_loss: 1093.78332520\n",
      "Epoch: [ 4] [ 150/ 548] time: 67.3174, train_loss: 882.67352295, val_loss: 1077.96667480\n",
      "Epoch: [ 4] [ 160/ 548] time: 67.5870, train_loss: 909.86492920, val_loss: 1043.09155273\n",
      "Epoch: [ 4] [ 170/ 548] time: 67.8523, train_loss: 2097.24609375, val_loss: 1055.39221191\n",
      "Epoch: [ 4] [ 180/ 548] time: 68.1284, train_loss: 1188.38781738, val_loss: 1058.17211914\n",
      "Epoch: [ 4] [ 190/ 548] time: 68.4149, train_loss: 3282.63256836, val_loss: 1059.00646973\n",
      "Epoch: [ 4] [ 200/ 548] time: 68.6860, train_loss: 1514.87353516, val_loss: 1047.97753906\n",
      "Epoch: [ 4] [ 210/ 548] time: 68.9533, train_loss: 1452.86572266, val_loss: 1046.18725586\n",
      "Epoch: [ 4] [ 220/ 548] time: 69.2078, train_loss: 855.77020264, val_loss: 1042.66223145\n",
      "Epoch: [ 4] [ 230/ 548] time: 69.4506, train_loss: 2085.91162109, val_loss: 1022.44592285\n",
      "Epoch: [ 4] [ 240/ 548] time: 69.6893, train_loss: 1337.03527832, val_loss: 1023.84826660\n",
      "Epoch: [ 4] [ 250/ 548] time: 69.9249, train_loss: 3094.48681641, val_loss: 1020.29193115\n",
      "Epoch: [ 4] [ 260/ 548] time: 70.1574, train_loss: 710.51721191, val_loss: 1027.56604004\n",
      "Epoch: [ 4] [ 270/ 548] time: 70.3948, train_loss: 1072.76770020, val_loss: 1012.82781982\n",
      "Epoch: [ 4] [ 280/ 548] time: 70.6299, train_loss: 1161.75256348, val_loss: 975.44244385\n",
      "Epoch: [ 4] [ 290/ 548] time: 70.8645, train_loss: 2232.49658203, val_loss: 1002.12902832\n",
      "Epoch: [ 4] [ 300/ 548] time: 71.0961, train_loss: 766.82415771, val_loss: 963.36102295\n",
      "Epoch: [ 4] [ 310/ 548] time: 71.3382, train_loss: 1287.37866211, val_loss: 974.93829346\n",
      "Epoch: [ 4] [ 320/ 548] time: 71.5956, train_loss: 794.15692139, val_loss: 948.55273438\n",
      "Epoch: [ 4] [ 330/ 548] time: 71.8325, train_loss: 1277.85632324, val_loss: 959.84143066\n",
      "Epoch: [ 4] [ 340/ 548] time: 72.0925, train_loss: 908.06054688, val_loss: 949.27661133\n",
      "Epoch: [ 4] [ 350/ 548] time: 72.3484, train_loss: 932.34301758, val_loss: 955.35253906\n",
      "Epoch: [ 4] [ 360/ 548] time: 72.6083, train_loss: 620.47491455, val_loss: 936.83087158\n",
      "Epoch: [ 4] [ 370/ 548] time: 72.8572, train_loss: 2456.87377930, val_loss: 925.86273193\n",
      "Epoch: [ 4] [ 380/ 548] time: 73.1048, train_loss: 1331.92504883, val_loss: 945.87774658\n",
      "Epoch: [ 4] [ 390/ 548] time: 73.3743, train_loss: 843.84991455, val_loss: 946.69128418\n",
      "Epoch: [ 4] [ 400/ 548] time: 73.6364, train_loss: 769.09844971, val_loss: 896.01196289\n",
      "Epoch: [ 4] [ 410/ 548] time: 73.8892, train_loss: 1190.80529785, val_loss: 934.83813477\n",
      "Epoch: [ 4] [ 420/ 548] time: 74.1364, train_loss: 1451.64025879, val_loss: 910.60839844\n",
      "Epoch: [ 4] [ 430/ 548] time: 74.3906, train_loss: 1888.99902344, val_loss: 922.50250244\n",
      "Epoch: [ 4] [ 440/ 548] time: 74.6212, train_loss: 805.18933105, val_loss: 892.76116943\n",
      "Epoch: [ 4] [ 450/ 548] time: 74.8747, train_loss: 1077.86889648, val_loss: 870.37493896\n",
      "Epoch: [ 4] [ 460/ 548] time: 75.1711, train_loss: 961.83502197, val_loss: 855.34570312\n",
      "Epoch: [ 4] [ 470/ 548] time: 75.4646, train_loss: 1357.88671875, val_loss: 862.78479004\n",
      "Epoch: [ 4] [ 480/ 548] time: 75.7530, train_loss: 820.06127930, val_loss: 868.99493408\n",
      "Epoch: [ 4] [ 490/ 548] time: 76.0155, train_loss: 883.84155273, val_loss: 854.68243408\n",
      "Epoch: [ 4] [ 500/ 548] time: 76.2853, train_loss: 1003.58044434, val_loss: 841.29351807\n",
      "Epoch: [ 4] [ 510/ 548] time: 76.5597, train_loss: 838.41131592, val_loss: 866.45678711\n",
      "Epoch: [ 4] [ 520/ 548] time: 76.8204, train_loss: 1138.37756348, val_loss: 836.94036865\n",
      "Epoch: [ 4] [ 530/ 548] time: 77.0708, train_loss: 913.79974365, val_loss: 814.15551758\n",
      "Epoch: [ 4] [ 540/ 548] time: 77.3101, train_loss: 856.62548828, val_loss: 807.92926025\n",
      "Epoch: [ 5] [   0/ 548] time: 77.4994, train_loss: 924.34490967, val_loss: 801.55249023\n",
      "Epoch: [ 5] [  10/ 548] time: 77.7332, train_loss: 663.92919922, val_loss: 795.96942139\n",
      "Epoch: [ 5] [  20/ 548] time: 77.9597, train_loss: 646.53979492, val_loss: 782.75146484\n",
      "Epoch: [ 5] [  30/ 548] time: 78.1843, train_loss: 764.22576904, val_loss: 802.62335205\n",
      "Epoch: [ 5] [  40/ 548] time: 78.4120, train_loss: 565.09332275, val_loss: 802.33728027\n",
      "Epoch: [ 5] [  50/ 548] time: 78.6370, train_loss: 692.05767822, val_loss: 794.64068604\n",
      "Epoch: [ 5] [  60/ 548] time: 78.8620, train_loss: 702.65447998, val_loss: 753.11096191\n",
      "Epoch: [ 5] [  70/ 548] time: 79.0915, train_loss: 757.49395752, val_loss: 761.06689453\n",
      "Epoch: [ 5] [  80/ 548] time: 79.3185, train_loss: 839.84222412, val_loss: 774.17919922\n",
      "Epoch: [ 5] [  90/ 548] time: 79.5505, train_loss: 799.56317139, val_loss: 775.31719971\n",
      "Epoch: [ 5] [ 100/ 548] time: 79.7731, train_loss: 740.36248779, val_loss: 767.29327393\n",
      "Epoch: [ 5] [ 110/ 548] time: 79.9974, train_loss: 1684.78173828, val_loss: 745.72607422\n",
      "Epoch: [ 5] [ 120/ 548] time: 80.2235, train_loss: 850.38140869, val_loss: 774.20153809\n",
      "Epoch: [ 5] [ 130/ 548] time: 80.4553, train_loss: 1746.75598145, val_loss: 764.28601074\n",
      "Epoch: [ 5] [ 140/ 548] time: 80.6835, train_loss: 1554.16943359, val_loss: 737.15515137\n",
      "Epoch: [ 5] [ 150/ 548] time: 80.9179, train_loss: 1656.57299805, val_loss: 722.44317627\n",
      "Epoch: [ 5] [ 160/ 548] time: 81.1762, train_loss: 614.56268311, val_loss: 743.37359619\n",
      "Epoch: [ 5] [ 170/ 548] time: 81.4311, train_loss: 544.68060303, val_loss: 712.62152100\n",
      "Epoch: [ 5] [ 180/ 548] time: 81.6945, train_loss: 588.48785400, val_loss: 714.38720703\n",
      "Epoch: [ 5] [ 190/ 548] time: 81.9466, train_loss: 1370.05944824, val_loss: 716.37841797\n",
      "Epoch: [ 5] [ 200/ 548] time: 82.1824, train_loss: 442.14483643, val_loss: 713.19885254\n",
      "Epoch: [ 5] [ 210/ 548] time: 82.4328, train_loss: 578.22015381, val_loss: 709.73724365\n",
      "Epoch: [ 5] [ 220/ 548] time: 82.7050, train_loss: 858.27270508, val_loss: 703.69592285\n",
      "Epoch: [ 5] [ 230/ 548] time: 82.9728, train_loss: 718.13024902, val_loss: 702.47131348\n",
      "Epoch: [ 5] [ 240/ 548] time: 83.2156, train_loss: 843.81805420, val_loss: 687.44250488\n",
      "Epoch: [ 5] [ 250/ 548] time: 83.4534, train_loss: 664.70385742, val_loss: 684.21661377\n",
      "Epoch: [ 5] [ 260/ 548] time: 83.6922, train_loss: 873.42846680, val_loss: 707.86718750\n",
      "Saving checkpoint\n",
      "Epoch: [ 5] [ 270/ 548] time: 84.9955, train_loss: 1030.23083496, val_loss: 694.82611084\n",
      "Epoch: [ 5] [ 280/ 548] time: 85.2727, train_loss: 814.18334961, val_loss: 675.80963135\n",
      "Epoch: [ 5] [ 290/ 548] time: 85.5354, train_loss: 747.22155762, val_loss: 678.82739258\n",
      "Epoch: [ 5] [ 300/ 548] time: 85.7867, train_loss: 796.90936279, val_loss: 681.37292480\n",
      "Epoch: [ 5] [ 310/ 548] time: 86.0333, train_loss: 392.96658325, val_loss: 695.11791992\n",
      "Epoch: [ 5] [ 320/ 548] time: 86.2932, train_loss: 945.73559570, val_loss: 670.28619385\n",
      "Epoch: [ 5] [ 330/ 548] time: 86.5464, train_loss: 741.44250488, val_loss: 628.93157959\n",
      "Epoch: [ 5] [ 340/ 548] time: 86.7794, train_loss: 664.25219727, val_loss: 658.91046143\n",
      "Epoch: [ 5] [ 350/ 548] time: 87.0572, train_loss: 288.58874512, val_loss: 663.31451416\n",
      "Epoch: [ 5] [ 360/ 548] time: 87.3511, train_loss: 434.60317993, val_loss: 629.01440430\n",
      "Epoch: [ 5] [ 370/ 548] time: 87.6089, train_loss: 571.36212158, val_loss: 652.52435303\n",
      "Epoch: [ 5] [ 380/ 548] time: 87.8562, train_loss: 728.31958008, val_loss: 647.54388428\n",
      "Epoch: [ 5] [ 390/ 548] time: 88.0871, train_loss: 945.26824951, val_loss: 657.34899902\n",
      "Epoch: [ 5] [ 400/ 548] time: 88.3107, train_loss: 550.48834229, val_loss: 658.25134277\n",
      "Epoch: [ 5] [ 410/ 548] time: 88.5416, train_loss: 661.17480469, val_loss: 618.84637451\n",
      "Epoch: [ 5] [ 420/ 548] time: 88.7637, train_loss: 800.71765137, val_loss: 634.70379639\n",
      "Epoch: [ 5] [ 430/ 548] time: 88.9921, train_loss: 858.00567627, val_loss: 619.32891846\n",
      "Epoch: [ 5] [ 440/ 548] time: 89.2206, train_loss: 626.27478027, val_loss: 621.33386230\n",
      "Epoch: [ 5] [ 450/ 548] time: 89.4467, train_loss: 1046.79833984, val_loss: 635.90441895\n",
      "Epoch: [ 5] [ 460/ 548] time: 89.6748, train_loss: 613.33416748, val_loss: 619.70172119\n",
      "Epoch: [ 5] [ 470/ 548] time: 89.8987, train_loss: 812.38323975, val_loss: 599.02838135\n",
      "Epoch: [ 5] [ 480/ 548] time: 90.1240, train_loss: 616.51763916, val_loss: 614.93072510\n",
      "Epoch: [ 5] [ 490/ 548] time: 90.3782, train_loss: 671.31243896, val_loss: 598.80493164\n",
      "Epoch: [ 5] [ 500/ 548] time: 90.6321, train_loss: 306.99871826, val_loss: 592.39251709\n",
      "Epoch: [ 5] [ 510/ 548] time: 90.8822, train_loss: 1336.09484863, val_loss: 605.09820557\n",
      "Epoch: [ 5] [ 520/ 548] time: 91.1357, train_loss: 808.38513184, val_loss: 604.27429199\n",
      "Epoch: [ 5] [ 530/ 548] time: 91.4023, train_loss: 390.32745361, val_loss: 593.43670654\n",
      "Epoch: [ 5] [ 540/ 548] time: 91.6916, train_loss: 389.27886963, val_loss: 602.87640381\n",
      "Epoch: [ 6] [   0/ 548] time: 91.9099, train_loss: 804.80487061, val_loss: 586.13818359\n",
      "Epoch: [ 6] [  10/ 548] time: 92.2047, train_loss: 701.92523193, val_loss: 585.97534180\n",
      "Epoch: [ 6] [  20/ 548] time: 92.4591, train_loss: 1217.32727051, val_loss: 596.40692139\n",
      "Epoch: [ 6] [  30/ 548] time: 92.7162, train_loss: 791.12304688, val_loss: 590.56579590\n",
      "Epoch: [ 6] [  40/ 548] time: 92.9889, train_loss: 764.12921143, val_loss: 576.74102783\n",
      "Epoch: [ 6] [  50/ 548] time: 93.2643, train_loss: 865.54827881, val_loss: 595.29534912\n",
      "Epoch: [ 6] [  60/ 548] time: 93.5645, train_loss: 770.79809570, val_loss: 587.16168213\n",
      "Epoch: [ 6] [  70/ 548] time: 93.8577, train_loss: 688.83331299, val_loss: 576.51000977\n",
      "Epoch: [ 6] [  80/ 548] time: 94.1104, train_loss: 782.68066406, val_loss: 578.40777588\n",
      "Epoch: [ 6] [  90/ 548] time: 94.3602, train_loss: 501.39544678, val_loss: 592.15869141\n",
      "Epoch: [ 6] [ 100/ 548] time: 94.6323, train_loss: 719.40216064, val_loss: 568.70562744\n",
      "Epoch: [ 6] [ 110/ 548] time: 94.9003, train_loss: 526.46929932, val_loss: 559.10668945\n",
      "Epoch: [ 6] [ 120/ 548] time: 95.1658, train_loss: 418.33670044, val_loss: 552.89477539\n",
      "Epoch: [ 6] [ 130/ 548] time: 95.4465, train_loss: 340.49847412, val_loss: 533.17053223\n",
      "Epoch: [ 6] [ 140/ 548] time: 95.7049, train_loss: 700.41607666, val_loss: 556.92279053\n",
      "Epoch: [ 6] [ 150/ 548] time: 95.9720, train_loss: 793.53448486, val_loss: 537.78771973\n",
      "Epoch: [ 6] [ 160/ 548] time: 96.2454, train_loss: 463.33706665, val_loss: 544.36358643\n",
      "Epoch: [ 6] [ 170/ 548] time: 96.4963, train_loss: 499.87957764, val_loss: 533.63891602\n",
      "Epoch: [ 6] [ 180/ 548] time: 96.7525, train_loss: 780.94622803, val_loss: 549.76965332\n",
      "Epoch: [ 6] [ 190/ 548] time: 97.0113, train_loss: 1041.89807129, val_loss: 534.66491699\n",
      "Epoch: [ 6] [ 200/ 548] time: 97.2682, train_loss: 337.34420776, val_loss: 532.81762695\n",
      "Epoch: [ 6] [ 210/ 548] time: 97.5328, train_loss: 963.91900635, val_loss: 513.49859619\n",
      "Epoch: [ 6] [ 220/ 548] time: 97.7934, train_loss: 967.88873291, val_loss: 522.87243652\n",
      "Epoch: [ 6] [ 230/ 548] time: 98.0471, train_loss: 1269.72473145, val_loss: 538.02471924\n",
      "Epoch: [ 6] [ 240/ 548] time: 98.3159, train_loss: 524.12188721, val_loss: 535.87475586\n",
      "Epoch: [ 6] [ 250/ 548] time: 98.6630, train_loss: 636.65332031, val_loss: 520.19744873\n",
      "Epoch: [ 6] [ 260/ 548] time: 99.0139, train_loss: 764.62963867, val_loss: 510.39776611\n",
      "Epoch: [ 6] [ 270/ 548] time: 99.3444, train_loss: 980.88787842, val_loss: 505.51675415\n",
      "Epoch: [ 6] [ 280/ 548] time: 99.6982, train_loss: 521.37048340, val_loss: 503.06552124\n",
      "Epoch: [ 6] [ 290/ 548] time: 100.0547, train_loss: 380.78918457, val_loss: 509.67425537\n",
      "Epoch: [ 6] [ 300/ 548] time: 100.3722, train_loss: 443.69198608, val_loss: 521.53570557\n",
      "Epoch: [ 6] [ 310/ 548] time: 100.6344, train_loss: 336.11495972, val_loss: 506.30340576\n",
      "Epoch: [ 6] [ 320/ 548] time: 100.9412, train_loss: 1156.38903809, val_loss: 512.36785889\n",
      "Epoch: [ 6] [ 330/ 548] time: 101.2464, train_loss: 755.75292969, val_loss: 522.25762939\n",
      "Epoch: [ 6] [ 340/ 548] time: 101.5941, train_loss: 522.15832520, val_loss: 512.45220947\n",
      "Epoch: [ 6] [ 350/ 548] time: 101.9173, train_loss: 803.99768066, val_loss: 501.14953613\n",
      "Epoch: [ 6] [ 360/ 548] time: 102.2258, train_loss: 378.40710449, val_loss: 488.25930786\n",
      "Epoch: [ 6] [ 370/ 548] time: 102.5374, train_loss: 543.72393799, val_loss: 492.34222412\n",
      "Epoch: [ 6] [ 380/ 548] time: 102.8611, train_loss: 527.09777832, val_loss: 510.23815918\n",
      "Epoch: [ 6] [ 390/ 548] time: 103.1565, train_loss: 471.48419189, val_loss: 479.67068481\n",
      "Epoch: [ 6] [ 400/ 548] time: 103.4352, train_loss: 2338.97753906, val_loss: 492.62231445\n",
      "Epoch: [ 6] [ 410/ 548] time: 103.6807, train_loss: 835.37835693, val_loss: 481.58264160\n",
      "Epoch: [ 6] [ 420/ 548] time: 103.9203, train_loss: 535.29736328, val_loss: 504.08496094\n",
      "Epoch: [ 6] [ 430/ 548] time: 104.1598, train_loss: 344.01718140, val_loss: 518.37072754\n",
      "Epoch: [ 6] [ 440/ 548] time: 104.3932, train_loss: 432.82479858, val_loss: 498.46255493\n",
      "Epoch: [ 6] [ 450/ 548] time: 104.6492, train_loss: 468.89746094, val_loss: 495.84759521\n",
      "Epoch: [ 6] [ 460/ 548] time: 104.9111, train_loss: 435.88311768, val_loss: 471.00250244\n",
      "Epoch: [ 6] [ 470/ 548] time: 105.1705, train_loss: 630.16033936, val_loss: 479.73742676\n",
      "Epoch: [ 6] [ 480/ 548] time: 105.4375, train_loss: 605.84930420, val_loss: 478.77911377\n",
      "Epoch: [ 6] [ 490/ 548] time: 105.7220, train_loss: 469.10943604, val_loss: 481.87094116\n",
      "Epoch: [ 6] [ 500/ 548] time: 106.0033, train_loss: 645.57983398, val_loss: 475.24664307\n",
      "Epoch: [ 6] [ 510/ 548] time: 106.2673, train_loss: 607.37274170, val_loss: 481.71643066\n",
      "Epoch: [ 6] [ 520/ 548] time: 106.5327, train_loss: 416.89904785, val_loss: 469.33004761\n",
      "Epoch: [ 6] [ 530/ 548] time: 106.7875, train_loss: 600.47125244, val_loss: 463.59216309\n",
      "Epoch: [ 6] [ 540/ 548] time: 107.0394, train_loss: 343.76016235, val_loss: 444.89920044\n",
      "Epoch: [ 7] [   0/ 548] time: 107.2303, train_loss: 274.86196899, val_loss: 473.46182251\n",
      "Epoch: [ 7] [  10/ 548] time: 107.4958, train_loss: 2974.18994141, val_loss: 445.87100220\n",
      "Epoch: [ 7] [  20/ 548] time: 107.7595, train_loss: 298.72763062, val_loss: 446.64721680\n",
      "Epoch: [ 7] [  30/ 548] time: 108.0274, train_loss: 510.62561035, val_loss: 452.37487793\n",
      "Epoch: [ 7] [  40/ 548] time: 108.2837, train_loss: 385.27590942, val_loss: 470.79980469\n",
      "Epoch: [ 7] [  50/ 548] time: 108.5302, train_loss: 569.54864502, val_loss: 459.31115723\n",
      "Epoch: [ 7] [  60/ 548] time: 108.7878, train_loss: 538.42651367, val_loss: 441.97366333\n",
      "Epoch: [ 7] [  70/ 548] time: 109.0657, train_loss: 148.63641357, val_loss: 449.39331055\n",
      "Epoch: [ 7] [  80/ 548] time: 109.3347, train_loss: 819.57043457, val_loss: 452.59167480\n",
      "Epoch: [ 7] [  90/ 548] time: 109.6047, train_loss: 485.82720947, val_loss: 448.96246338\n",
      "Epoch: [ 7] [ 100/ 548] time: 109.8595, train_loss: 320.84210205, val_loss: 434.86801147\n",
      "Epoch: [ 7] [ 110/ 548] time: 110.1096, train_loss: 562.72540283, val_loss: 431.60873413\n",
      "Epoch: [ 7] [ 120/ 548] time: 110.3669, train_loss: 479.84915161, val_loss: 435.74118042\n",
      "Epoch: [ 7] [ 130/ 548] time: 110.6264, train_loss: 544.81115723, val_loss: 407.86901855\n",
      "Epoch: [ 7] [ 140/ 548] time: 110.8812, train_loss: 375.79742432, val_loss: 411.36697388\n",
      "Epoch: [ 7] [ 150/ 548] time: 111.1398, train_loss: 826.60461426, val_loss: 446.85577393\n",
      "Epoch: [ 7] [ 160/ 548] time: 111.4066, train_loss: 447.13742065, val_loss: 435.53326416\n",
      "Saving checkpoint\n",
      "Epoch: [ 7] [ 170/ 548] time: 112.7704, train_loss: 1212.01489258, val_loss: 443.24911499\n",
      "Epoch: [ 7] [ 180/ 548] time: 113.0474, train_loss: 1363.65502930, val_loss: 450.57839966\n",
      "Epoch: [ 7] [ 190/ 548] time: 113.3178, train_loss: 363.74234009, val_loss: 443.19091797\n",
      "Epoch: [ 7] [ 200/ 548] time: 113.5787, train_loss: 722.72839355, val_loss: 437.95361328\n",
      "Epoch: [ 7] [ 210/ 548] time: 113.8359, train_loss: 480.02282715, val_loss: 419.40798950\n",
      "Epoch: [ 7] [ 220/ 548] time: 114.0793, train_loss: 260.06884766, val_loss: 440.28686523\n",
      "Epoch: [ 7] [ 230/ 548] time: 114.3072, train_loss: 541.50122070, val_loss: 423.66491699\n",
      "Epoch: [ 7] [ 240/ 548] time: 114.5668, train_loss: 523.57507324, val_loss: 418.87234497\n",
      "Epoch: [ 7] [ 250/ 548] time: 114.8161, train_loss: 468.18218994, val_loss: 416.64904785\n",
      "Epoch: [ 7] [ 260/ 548] time: 115.0697, train_loss: 522.74279785, val_loss: 403.55554199\n",
      "Epoch: [ 7] [ 270/ 548] time: 115.3244, train_loss: 461.57138062, val_loss: 419.42602539\n",
      "Epoch: [ 7] [ 280/ 548] time: 115.5684, train_loss: 361.27203369, val_loss: 417.50024414\n",
      "Epoch: [ 7] [ 290/ 548] time: 115.8091, train_loss: 908.48010254, val_loss: 413.55828857\n",
      "Epoch: [ 7] [ 300/ 548] time: 116.0518, train_loss: 389.97000122, val_loss: 418.37329102\n",
      "Epoch: [ 7] [ 310/ 548] time: 116.2999, train_loss: 329.02975464, val_loss: 407.44790649\n",
      "Epoch: [ 7] [ 320/ 548] time: 116.5643, train_loss: 410.88494873, val_loss: 405.97753906\n",
      "Epoch: [ 7] [ 330/ 548] time: 116.8221, train_loss: 280.00921631, val_loss: 397.21621704\n",
      "Epoch: [ 7] [ 340/ 548] time: 117.0805, train_loss: 492.13781738, val_loss: 412.62176514\n",
      "Epoch: [ 7] [ 350/ 548] time: 117.3742, train_loss: 257.11096191, val_loss: 404.12692261\n",
      "Epoch: [ 7] [ 360/ 548] time: 117.6797, train_loss: 511.13632202, val_loss: 397.92385864\n",
      "Epoch: [ 7] [ 370/ 548] time: 117.9585, train_loss: 218.32640076, val_loss: 395.33352661\n",
      "Epoch: [ 7] [ 380/ 548] time: 118.2323, train_loss: 406.53442383, val_loss: 397.28793335\n",
      "Epoch: [ 7] [ 390/ 548] time: 118.5475, train_loss: 329.12478638, val_loss: 396.20477295\n",
      "Epoch: [ 7] [ 400/ 548] time: 118.8894, train_loss: 392.64178467, val_loss: 397.03515625\n",
      "Epoch: [ 7] [ 410/ 548] time: 119.2249, train_loss: 436.41403198, val_loss: 403.57916260\n",
      "Epoch: [ 7] [ 420/ 548] time: 119.5399, train_loss: 364.27801514, val_loss: 407.73791504\n",
      "Epoch: [ 7] [ 430/ 548] time: 119.8815, train_loss: 566.50280762, val_loss: 411.08868408\n",
      "Epoch: [ 7] [ 440/ 548] time: 120.2113, train_loss: 365.16729736, val_loss: 399.19305420\n",
      "Epoch: [ 7] [ 450/ 548] time: 120.5509, train_loss: 379.36038208, val_loss: 391.04278564\n",
      "Epoch: [ 7] [ 460/ 548] time: 120.8657, train_loss: 180.00753784, val_loss: 390.78375244\n",
      "Epoch: [ 7] [ 470/ 548] time: 121.1739, train_loss: 411.87051392, val_loss: 404.51889038\n",
      "Epoch: [ 7] [ 480/ 548] time: 121.4587, train_loss: 483.80157471, val_loss: 400.52996826\n",
      "Epoch: [ 7] [ 490/ 548] time: 121.7922, train_loss: 421.15921021, val_loss: 369.79156494\n",
      "Epoch: [ 7] [ 500/ 548] time: 122.1092, train_loss: 254.32044983, val_loss: 370.12625122\n",
      "Epoch: [ 7] [ 510/ 548] time: 122.4205, train_loss: 663.31982422, val_loss: 388.04180908\n",
      "Epoch: [ 7] [ 520/ 548] time: 122.7197, train_loss: 351.07537842, val_loss: 375.07315063\n",
      "Epoch: [ 7] [ 530/ 548] time: 122.9798, train_loss: 445.37094116, val_loss: 358.37973022\n",
      "Epoch: [ 7] [ 540/ 548] time: 123.2695, train_loss: 411.55636597, val_loss: 382.70614624\n",
      "Epoch: [ 8] [   0/ 548] time: 123.4973, train_loss: 1120.37109375, val_loss: 386.41467285\n",
      "Epoch: [ 8] [  10/ 548] time: 123.7677, train_loss: 265.67333984, val_loss: 370.84704590\n",
      "Epoch: [ 8] [  20/ 548] time: 124.0280, train_loss: 459.66653442, val_loss: 399.07107544\n",
      "Epoch: [ 8] [  30/ 548] time: 124.2632, train_loss: 410.78656006, val_loss: 354.03881836\n",
      "Epoch: [ 8] [  40/ 548] time: 124.4956, train_loss: 404.36145020, val_loss: 378.31179810\n",
      "Epoch: [ 8] [  50/ 548] time: 124.7382, train_loss: 273.46859741, val_loss: 385.75692749\n",
      "Epoch: [ 8] [  60/ 548] time: 124.9644, train_loss: 446.56567383, val_loss: 370.61453247\n",
      "Epoch: [ 8] [  70/ 548] time: 125.1905, train_loss: 345.88769531, val_loss: 357.10925293\n",
      "Epoch: [ 8] [  80/ 548] time: 125.4696, train_loss: 208.58195496, val_loss: 368.28039551\n",
      "Epoch: [ 8] [  90/ 548] time: 125.7397, train_loss: 624.41766357, val_loss: 381.19973755\n",
      "Epoch: [ 8] [ 100/ 548] time: 125.9963, train_loss: 650.81353760, val_loss: 366.59573364\n",
      "Epoch: [ 8] [ 110/ 548] time: 126.2524, train_loss: 182.91746521, val_loss: 381.14630127\n",
      "Epoch: [ 8] [ 120/ 548] time: 126.5499, train_loss: 371.54580688, val_loss: 371.29681396\n",
      "Epoch: [ 8] [ 130/ 548] time: 126.9096, train_loss: 301.33349609, val_loss: 377.70962524\n",
      "Epoch: [ 8] [ 140/ 548] time: 127.2265, train_loss: 238.26277161, val_loss: 362.97232056\n",
      "Epoch: [ 8] [ 150/ 548] time: 127.5442, train_loss: 469.81631470, val_loss: 369.54882812\n",
      "Epoch: [ 8] [ 160/ 548] time: 127.8809, train_loss: 422.74276733, val_loss: 348.85723877\n",
      "Epoch: [ 8] [ 170/ 548] time: 128.2005, train_loss: 648.45135498, val_loss: 392.77407837\n",
      "Epoch: [ 8] [ 180/ 548] time: 128.4977, train_loss: 513.64868164, val_loss: 349.05126953\n",
      "Epoch: [ 8] [ 190/ 548] time: 128.8205, train_loss: 581.13360596, val_loss: 352.54614258\n",
      "Epoch: [ 8] [ 200/ 548] time: 129.1508, train_loss: 488.96310425, val_loss: 354.32800293\n",
      "Epoch: [ 8] [ 210/ 548] time: 129.4801, train_loss: 147.52168274, val_loss: 341.52984619\n",
      "Epoch: [ 8] [ 220/ 548] time: 129.8225, train_loss: 377.77474976, val_loss: 354.13973999\n",
      "Epoch: [ 8] [ 230/ 548] time: 130.1259, train_loss: 243.48333740, val_loss: 361.46560669\n",
      "Epoch: [ 8] [ 240/ 548] time: 130.3889, train_loss: 650.47637939, val_loss: 370.09017944\n",
      "Epoch: [ 8] [ 250/ 548] time: 130.6417, train_loss: 307.93640137, val_loss: 351.50115967\n",
      "Epoch: [ 8] [ 260/ 548] time: 130.8755, train_loss: 307.98547363, val_loss: 373.70547485\n",
      "Epoch: [ 8] [ 270/ 548] time: 131.1056, train_loss: 483.06695557, val_loss: 348.80596924\n",
      "Epoch: [ 8] [ 280/ 548] time: 131.3457, train_loss: 265.92214966, val_loss: 343.57928467\n",
      "Epoch: [ 8] [ 290/ 548] time: 131.5739, train_loss: 450.38403320, val_loss: 339.06152344\n",
      "Epoch: [ 8] [ 300/ 548] time: 131.8025, train_loss: 318.62893677, val_loss: 355.18392944\n",
      "Epoch: [ 8] [ 310/ 548] time: 132.0319, train_loss: 669.55499268, val_loss: 350.41845703\n",
      "Epoch: [ 8] [ 320/ 548] time: 132.2554, train_loss: 144.97798157, val_loss: 348.42849731\n",
      "Epoch: [ 8] [ 330/ 548] time: 132.4823, train_loss: 191.78002930, val_loss: 344.93038940\n",
      "Epoch: [ 8] [ 340/ 548] time: 132.7114, train_loss: 363.26544189, val_loss: 364.12490845\n",
      "Epoch: [ 8] [ 350/ 548] time: 132.9445, train_loss: 657.88464355, val_loss: 350.39334106\n",
      "Epoch: [ 8] [ 360/ 548] time: 133.1777, train_loss: 371.95089722, val_loss: 351.18176270\n",
      "Epoch: [ 8] [ 370/ 548] time: 133.4293, train_loss: 393.99798584, val_loss: 349.69696045\n",
      "Epoch: [ 8] [ 380/ 548] time: 133.6725, train_loss: 360.80078125, val_loss: 345.46032715\n",
      "Epoch: [ 8] [ 390/ 548] time: 133.9135, train_loss: 618.56536865, val_loss: 347.15942383\n",
      "Epoch: [ 8] [ 400/ 548] time: 134.1552, train_loss: 364.77163696, val_loss: 349.44619751\n",
      "Epoch: [ 8] [ 410/ 548] time: 134.3985, train_loss: 192.01612854, val_loss: 336.91082764\n",
      "Epoch: [ 8] [ 420/ 548] time: 134.6463, train_loss: 919.60620117, val_loss: 350.36834717\n",
      "Epoch: [ 8] [ 430/ 548] time: 134.9005, train_loss: 409.07806396, val_loss: 355.88067627\n",
      "Epoch: [ 8] [ 440/ 548] time: 135.1548, train_loss: 338.55307007, val_loss: 338.34848022\n",
      "Epoch: [ 8] [ 450/ 548] time: 135.4064, train_loss: 409.99560547, val_loss: 336.26544189\n",
      "Epoch: [ 8] [ 460/ 548] time: 135.6730, train_loss: 757.50970459, val_loss: 327.32617188\n",
      "Epoch: [ 8] [ 470/ 548] time: 135.9496, train_loss: 180.96553040, val_loss: 335.00830078\n",
      "Epoch: [ 8] [ 480/ 548] time: 136.2250, train_loss: 565.51025391, val_loss: 329.59213257\n",
      "Epoch: [ 8] [ 490/ 548] time: 136.5039, train_loss: 286.34982300, val_loss: 330.91082764\n",
      "Epoch: [ 8] [ 500/ 548] time: 136.8580, train_loss: 1192.51110840, val_loss: 340.95510864\n",
      "Epoch: [ 8] [ 510/ 548] time: 137.1337, train_loss: 421.55511475, val_loss: 329.83264160\n",
      "Epoch: [ 8] [ 520/ 548] time: 137.4307, train_loss: 427.75018311, val_loss: 325.33056641\n",
      "Epoch: [ 8] [ 530/ 548] time: 137.6903, train_loss: 308.93652344, val_loss: 318.24224854\n",
      "Epoch: [ 8] [ 540/ 548] time: 137.9457, train_loss: 214.18492126, val_loss: 316.21957397\n",
      "Epoch: [ 9] [   0/ 548] time: 138.1450, train_loss: 380.69891357, val_loss: 315.06588745\n",
      "Epoch: [ 9] [  10/ 548] time: 138.3993, train_loss: 666.48828125, val_loss: 326.49362183\n",
      "Epoch: [ 9] [  20/ 548] time: 138.6412, train_loss: 304.77355957, val_loss: 312.46676636\n",
      "Epoch: [ 9] [  30/ 548] time: 138.9114, train_loss: 419.15380859, val_loss: 297.72253418\n",
      "Epoch: [ 9] [  40/ 548] time: 139.1794, train_loss: 245.23776245, val_loss: 314.20513916\n",
      "Epoch: [ 9] [  50/ 548] time: 139.4408, train_loss: 474.09942627, val_loss: 325.40554810\n",
      "Epoch: [ 9] [  60/ 548] time: 139.7214, train_loss: 172.51684570, val_loss: 302.44747925\n",
      "Saving checkpoint\n",
      "Epoch: [ 9] [  70/ 548] time: 141.0690, train_loss: 373.85748291, val_loss: 319.63629150\n",
      "Epoch: [ 9] [  80/ 548] time: 141.3399, train_loss: 574.60034180, val_loss: 318.15078735\n",
      "Epoch: [ 9] [  90/ 548] time: 141.6148, train_loss: 265.01452637, val_loss: 313.59713745\n",
      "Epoch: [ 9] [ 100/ 548] time: 141.8518, train_loss: 312.60131836, val_loss: 315.69439697\n",
      "Epoch: [ 9] [ 110/ 548] time: 142.1075, train_loss: 385.78915405, val_loss: 304.59799194\n",
      "Epoch: [ 9] [ 120/ 548] time: 142.3748, train_loss: 100.78094482, val_loss: 338.18005371\n",
      "Epoch: [ 9] [ 130/ 548] time: 142.6501, train_loss: 313.92602539, val_loss: 311.95227051\n",
      "Epoch: [ 9] [ 140/ 548] time: 142.9186, train_loss: 290.71215820, val_loss: 309.52478027\n",
      "Epoch: [ 9] [ 150/ 548] time: 143.1499, train_loss: 369.45758057, val_loss: 316.43414307\n",
      "Epoch: [ 9] [ 160/ 548] time: 143.4151, train_loss: 469.72174072, val_loss: 307.93109131\n",
      "Epoch: [ 9] [ 170/ 548] time: 143.6729, train_loss: 186.38037109, val_loss: 316.70883179\n",
      "Epoch: [ 9] [ 180/ 548] time: 143.9110, train_loss: 182.40777588, val_loss: 315.42065430\n",
      "Epoch: [ 9] [ 190/ 548] time: 144.1551, train_loss: 442.10964966, val_loss: 313.70532227\n",
      "Epoch: [ 9] [ 200/ 548] time: 144.4014, train_loss: 302.26135254, val_loss: 301.93627930\n",
      "Epoch: [ 9] [ 210/ 548] time: 144.6409, train_loss: 2310.40600586, val_loss: 316.86041260\n",
      "Epoch: [ 9] [ 220/ 548] time: 144.8774, train_loss: 513.14886475, val_loss: 309.45391846\n",
      "Epoch: [ 9] [ 230/ 548] time: 145.1120, train_loss: 454.35073853, val_loss: 295.77154541\n",
      "Epoch: [ 9] [ 240/ 548] time: 145.3551, train_loss: 632.15454102, val_loss: 291.54714966\n",
      "Epoch: [ 9] [ 250/ 548] time: 145.5891, train_loss: 411.51135254, val_loss: 296.42843628\n",
      "Epoch: [ 9] [ 260/ 548] time: 145.8327, train_loss: 238.70872498, val_loss: 301.14611816\n",
      "Epoch: [ 9] [ 270/ 548] time: 146.0964, train_loss: 474.16842651, val_loss: 308.52062988\n",
      "Epoch: [ 9] [ 280/ 548] time: 146.3435, train_loss: 425.12469482, val_loss: 294.78842163\n",
      "Epoch: [ 9] [ 290/ 548] time: 146.5932, train_loss: 565.08074951, val_loss: 303.40045166\n",
      "Epoch: [ 9] [ 300/ 548] time: 146.8551, train_loss: 194.59753418, val_loss: 305.75305176\n",
      "Epoch: [ 9] [ 310/ 548] time: 147.1144, train_loss: 252.01055908, val_loss: 292.84936523\n",
      "Epoch: [ 9] [ 320/ 548] time: 147.3517, train_loss: 437.08346558, val_loss: 305.03057861\n",
      "Epoch: [ 9] [ 330/ 548] time: 147.5934, train_loss: 206.08721924, val_loss: 303.36221313\n",
      "Epoch: [ 9] [ 340/ 548] time: 147.8373, train_loss: 401.34317017, val_loss: 300.61996460\n",
      "Epoch: [ 9] [ 350/ 548] time: 148.0873, train_loss: 385.27667236, val_loss: 302.36199951\n",
      "Epoch: [ 9] [ 360/ 548] time: 148.3407, train_loss: 239.19084167, val_loss: 302.02944946\n",
      "Epoch: [ 9] [ 370/ 548] time: 148.5944, train_loss: 620.59387207, val_loss: 322.37857056\n",
      "Epoch: [ 9] [ 380/ 548] time: 148.8493, train_loss: 249.43254089, val_loss: 307.27493286\n",
      "Epoch: [ 9] [ 390/ 548] time: 149.1236, train_loss: 170.34533691, val_loss: 300.87854004\n",
      "Epoch: [ 9] [ 400/ 548] time: 149.3718, train_loss: 234.71029663, val_loss: 293.61965942\n",
      "Epoch: [ 9] [ 410/ 548] time: 149.6236, train_loss: 351.08892822, val_loss: 279.50115967\n",
      "Epoch: [ 9] [ 420/ 548] time: 149.8653, train_loss: 382.25573730, val_loss: 292.63766479\n",
      "Epoch: [ 9] [ 430/ 548] time: 150.1210, train_loss: 137.35527039, val_loss: 295.24096680\n",
      "Epoch: [ 9] [ 440/ 548] time: 150.3922, train_loss: 300.25939941, val_loss: 314.34197998\n",
      "Epoch: [ 9] [ 450/ 548] time: 150.6487, train_loss: 295.38131714, val_loss: 278.45480347\n",
      "Epoch: [ 9] [ 460/ 548] time: 150.8857, train_loss: 332.95877075, val_loss: 322.67041016\n",
      "Epoch: [ 9] [ 470/ 548] time: 151.1228, train_loss: 156.36354065, val_loss: 306.99368286\n",
      "Epoch: [ 9] [ 480/ 548] time: 151.3752, train_loss: 281.11108398, val_loss: 276.83999634\n",
      "Epoch: [ 9] [ 490/ 548] time: 151.6454, train_loss: 294.06121826, val_loss: 283.22592163\n",
      "Epoch: [ 9] [ 500/ 548] time: 151.8905, train_loss: 334.07650757, val_loss: 281.34567261\n",
      "Epoch: [ 9] [ 510/ 548] time: 152.1383, train_loss: 217.91925049, val_loss: 284.40341187\n",
      "Epoch: [ 9] [ 520/ 548] time: 152.4363, train_loss: 183.97070312, val_loss: 305.47131348\n",
      "Epoch: [ 9] [ 530/ 548] time: 152.6902, train_loss: 190.04521179, val_loss: 284.65505981\n",
      "Epoch: [ 9] [ 540/ 548] time: 152.9457, train_loss: 349.03057861, val_loss: 288.87878418\n",
      "Epoch: [10] [   0/ 548] time: 153.1365, train_loss: 231.50189209, val_loss: 262.92175293\n",
      "Epoch: [10] [  10/ 548] time: 153.3781, train_loss: 245.12759399, val_loss: 283.02035522\n",
      "Epoch: [10] [  20/ 548] time: 153.6177, train_loss: 280.20895386, val_loss: 262.64337158\n",
      "Epoch: [10] [  30/ 548] time: 153.8694, train_loss: 362.59497070, val_loss: 279.11596680\n",
      "Epoch: [10] [  40/ 548] time: 154.1061, train_loss: 304.15771484, val_loss: 277.08081055\n",
      "Epoch: [10] [  50/ 548] time: 154.3577, train_loss: 358.78274536, val_loss: 295.28955078\n",
      "Epoch: [10] [  60/ 548] time: 154.6258, train_loss: 361.84625244, val_loss: 282.72613525\n",
      "Epoch: [10] [  70/ 548] time: 154.9006, train_loss: 499.38702393, val_loss: 275.40716553\n",
      "Epoch: [10] [  80/ 548] time: 155.1658, train_loss: 216.71095276, val_loss: 299.38818359\n",
      "Epoch: [10] [  90/ 548] time: 155.4819, train_loss: 328.30780029, val_loss: 301.04568481\n",
      "Epoch: [10] [ 100/ 548] time: 155.7400, train_loss: 446.98220825, val_loss: 293.94177246\n",
      "Epoch: [10] [ 110/ 548] time: 156.0108, train_loss: 274.78594971, val_loss: 284.06747437\n",
      "Epoch: [10] [ 120/ 548] time: 156.2755, train_loss: 365.23300171, val_loss: 265.05496216\n",
      "Epoch: [10] [ 130/ 548] time: 156.5171, train_loss: 216.72140503, val_loss: 291.28320312\n",
      "Epoch: [10] [ 140/ 548] time: 156.7762, train_loss: 418.68609619, val_loss: 277.64483643\n",
      "Epoch: [10] [ 150/ 548] time: 157.0402, train_loss: 256.60913086, val_loss: 281.39019775\n",
      "Epoch: [10] [ 160/ 548] time: 157.2862, train_loss: 187.92842102, val_loss: 267.78918457\n",
      "Epoch: [10] [ 170/ 548] time: 157.5313, train_loss: 113.15873718, val_loss: 266.88232422\n",
      "Epoch: [10] [ 180/ 548] time: 157.7933, train_loss: 154.09461975, val_loss: 265.82934570\n",
      "Epoch: [10] [ 190/ 548] time: 158.0344, train_loss: 325.87530518, val_loss: 279.39492798\n",
      "Epoch: [10] [ 200/ 548] time: 158.2953, train_loss: 146.67260742, val_loss: 270.41241455\n",
      "Epoch: [10] [ 210/ 548] time: 158.5389, train_loss: 235.07626343, val_loss: 274.87719727\n",
      "Epoch: [10] [ 220/ 548] time: 158.8012, train_loss: 213.40655518, val_loss: 269.05023193\n",
      "Epoch: [10] [ 230/ 548] time: 159.0719, train_loss: 224.65615845, val_loss: 262.28616333\n",
      "Epoch: [10] [ 240/ 548] time: 159.3826, train_loss: 1192.47692871, val_loss: 260.56878662\n",
      "Epoch: [10] [ 250/ 548] time: 159.6838, train_loss: 244.61865234, val_loss: 261.65585327\n",
      "Epoch: [10] [ 260/ 548] time: 159.9837, train_loss: 232.21757507, val_loss: 262.44335938\n",
      "Epoch: [10] [ 270/ 548] time: 160.2852, train_loss: 237.78642273, val_loss: 269.96630859\n",
      "Epoch: [10] [ 280/ 548] time: 160.6077, train_loss: 497.01135254, val_loss: 305.73272705\n",
      "Epoch: [10] [ 290/ 548] time: 160.9393, train_loss: 392.69824219, val_loss: 304.03640747\n",
      "Epoch: [10] [ 300/ 548] time: 161.3438, train_loss: 408.08688354, val_loss: 267.61938477\n",
      "Epoch: [10] [ 310/ 548] time: 161.7322, train_loss: 571.67431641, val_loss: 261.24096680\n",
      "Epoch: [10] [ 320/ 548] time: 162.1233, train_loss: 304.30679321, val_loss: 259.26620483\n",
      "Epoch: [10] [ 330/ 548] time: 162.4926, train_loss: 366.23403931, val_loss: 274.93173218\n",
      "Epoch: [10] [ 340/ 548] time: 162.8964, train_loss: 536.82922363, val_loss: 268.92248535\n",
      "Epoch: [10] [ 350/ 548] time: 163.2334, train_loss: 304.23477173, val_loss: 271.06997681\n",
      "Epoch: [10] [ 360/ 548] time: 163.5591, train_loss: 209.47575378, val_loss: 263.29281616\n",
      "Epoch: [10] [ 370/ 548] time: 163.9092, train_loss: 265.69070435, val_loss: 269.18164062\n",
      "Epoch: [10] [ 380/ 548] time: 164.2317, train_loss: 252.19546509, val_loss: 292.48049927\n",
      "Epoch: [10] [ 390/ 548] time: 164.5450, train_loss: 401.04721069, val_loss: 254.61975098\n",
      "Epoch: [10] [ 400/ 548] time: 164.9002, train_loss: 186.65992737, val_loss: 257.10119629\n",
      "Epoch: [10] [ 410/ 548] time: 165.2371, train_loss: 402.80230713, val_loss: 286.89709473\n",
      "Epoch: [10] [ 420/ 548] time: 165.5829, train_loss: 184.69577026, val_loss: 254.29940796\n",
      "Epoch: [10] [ 430/ 548] time: 165.9356, train_loss: 360.46548462, val_loss: 252.63444519\n",
      "Epoch: [10] [ 440/ 548] time: 166.2805, train_loss: 323.51373291, val_loss: 263.55230713\n",
      "Epoch: [10] [ 450/ 548] time: 166.5835, train_loss: 1186.55383301, val_loss: 233.65444946\n",
      "Epoch: [10] [ 460/ 548] time: 166.9025, train_loss: 209.43655396, val_loss: 246.27543640\n",
      "Epoch: [10] [ 470/ 548] time: 167.2222, train_loss: 297.34570312, val_loss: 253.84243774\n",
      "Epoch: [10] [ 480/ 548] time: 167.5352, train_loss: 142.09231567, val_loss: 240.47357178\n",
      "Epoch: [10] [ 490/ 548] time: 167.8783, train_loss: 209.20272827, val_loss: 240.38720703\n",
      "Epoch: [10] [ 500/ 548] time: 168.2168, train_loss: 181.67498779, val_loss: 234.51203918\n",
      "Epoch: [10] [ 510/ 548] time: 168.5342, train_loss: 168.03753662, val_loss: 243.89562988\n",
      "Epoch: [10] [ 520/ 548] time: 168.8755, train_loss: 719.37951660, val_loss: 240.34628296\n",
      "Saving checkpoint\n",
      "Epoch: [10] [ 530/ 548] time: 170.3238, train_loss: 384.59936523, val_loss: 245.76692200\n",
      "Epoch: [10] [ 540/ 548] time: 170.6020, train_loss: 194.62974548, val_loss: 231.07127380\n",
      "Epoch: [11] [   0/ 548] time: 170.8179, train_loss: 289.76214600, val_loss: 234.87686157\n",
      "Epoch: [11] [  10/ 548] time: 171.0622, train_loss: 121.26062012, val_loss: 241.30775452\n",
      "Epoch: [11] [  20/ 548] time: 171.3227, train_loss: 166.79684448, val_loss: 236.85049438\n",
      "Epoch: [11] [  30/ 548] time: 171.5709, train_loss: 141.94281006, val_loss: 242.16184998\n",
      "Epoch: [11] [  40/ 548] time: 171.8266, train_loss: 156.80892944, val_loss: 224.67070007\n",
      "Epoch: [11] [  50/ 548] time: 172.1522, train_loss: 213.04895020, val_loss: 247.06803894\n",
      "Epoch: [11] [  60/ 548] time: 172.4533, train_loss: 228.10466003, val_loss: 248.08158875\n",
      "Epoch: [11] [  70/ 548] time: 172.7384, train_loss: 355.41641235, val_loss: 239.95510864\n",
      "Epoch: [11] [  80/ 548] time: 173.0300, train_loss: 647.20806885, val_loss: 237.69844055\n",
      "Epoch: [11] [  90/ 548] time: 173.2992, train_loss: 229.98953247, val_loss: 260.41723633\n",
      "Epoch: [11] [ 100/ 548] time: 173.5614, train_loss: 308.03744507, val_loss: 277.30529785\n",
      "Epoch: [11] [ 110/ 548] time: 173.8388, train_loss: 157.87197876, val_loss: 272.85809326\n",
      "Epoch: [11] [ 120/ 548] time: 174.1116, train_loss: 159.94187927, val_loss: 258.92233276\n",
      "Epoch: [11] [ 130/ 548] time: 174.4098, train_loss: 197.12561035, val_loss: 250.61804199\n",
      "Epoch: [11] [ 140/ 548] time: 174.6928, train_loss: 46.71137238, val_loss: 255.03704834\n",
      "Epoch: [11] [ 150/ 548] time: 174.9595, train_loss: 201.73941040, val_loss: 258.85394287\n",
      "Epoch: [11] [ 160/ 548] time: 175.2262, train_loss: 192.86375427, val_loss: 257.17504883\n",
      "Epoch: [11] [ 170/ 548] time: 175.4978, train_loss: 375.40728760, val_loss: 241.45536804\n",
      "Epoch: [11] [ 180/ 548] time: 175.7652, train_loss: 231.38644409, val_loss: 241.01986694\n",
      "Epoch: [11] [ 190/ 548] time: 176.0484, train_loss: 231.02841187, val_loss: 231.28102112\n",
      "Epoch: [11] [ 200/ 548] time: 176.3291, train_loss: 277.37286377, val_loss: 225.34515381\n",
      "Epoch: [11] [ 210/ 548] time: 176.6219, train_loss: 307.20306396, val_loss: 239.68267822\n",
      "Epoch: [11] [ 220/ 548] time: 176.9051, train_loss: 400.31887817, val_loss: 244.75115967\n",
      "Epoch: [11] [ 230/ 548] time: 177.1785, train_loss: 240.41290283, val_loss: 235.61495972\n",
      "Epoch: [11] [ 240/ 548] time: 177.4658, train_loss: 316.43746948, val_loss: 242.90158081\n",
      "Epoch: [11] [ 250/ 548] time: 177.7658, train_loss: 154.70361328, val_loss: 238.02044678\n",
      "Epoch: [11] [ 260/ 548] time: 178.0452, train_loss: 259.94616699, val_loss: 235.35690308\n",
      "Epoch: [11] [ 270/ 548] time: 178.3187, train_loss: 277.84558105, val_loss: 232.09072876\n",
      "Epoch: [11] [ 280/ 548] time: 178.6055, train_loss: 173.79180908, val_loss: 228.28129578\n",
      "Epoch: [11] [ 290/ 548] time: 178.8641, train_loss: 305.08734131, val_loss: 233.38281250\n",
      "Epoch: [11] [ 300/ 548] time: 179.1300, train_loss: 412.91702271, val_loss: 219.35418701\n",
      "Epoch: [11] [ 310/ 548] time: 179.3837, train_loss: 1005.27081299, val_loss: 247.77174377\n",
      "Epoch: [11] [ 320/ 548] time: 179.6478, train_loss: 464.47018433, val_loss: 213.35815430\n",
      "Epoch: [11] [ 330/ 548] time: 179.9127, train_loss: 829.99468994, val_loss: 211.82165527\n",
      "Epoch: [11] [ 340/ 548] time: 180.2053, train_loss: 141.33831787, val_loss: 218.46298218\n",
      "Epoch: [11] [ 350/ 548] time: 180.4942, train_loss: 1476.97717285, val_loss: 240.11460876\n",
      "Epoch: [11] [ 360/ 548] time: 180.7745, train_loss: 314.70397949, val_loss: 239.11805725\n",
      "Epoch: [11] [ 370/ 548] time: 181.0581, train_loss: 505.61679077, val_loss: 216.19169617\n",
      "Epoch: [11] [ 380/ 548] time: 181.3087, train_loss: 289.62521362, val_loss: 210.13220215\n",
      "Epoch: [11] [ 390/ 548] time: 181.5512, train_loss: 884.78411865, val_loss: 228.91189575\n",
      "Epoch: [11] [ 400/ 548] time: 181.7867, train_loss: 807.85858154, val_loss: 258.63873291\n",
      "Epoch: [11] [ 410/ 548] time: 182.0329, train_loss: 1209.71704102, val_loss: 258.28900146\n",
      "Epoch: [11] [ 420/ 548] time: 182.2927, train_loss: 212.27088928, val_loss: 234.46751404\n",
      "Epoch: [11] [ 430/ 548] time: 182.5358, train_loss: 202.90054321, val_loss: 232.87629700\n",
      "Epoch: [11] [ 440/ 548] time: 182.7795, train_loss: 254.66299438, val_loss: 228.47236633\n",
      "Epoch: [11] [ 450/ 548] time: 183.0254, train_loss: 469.15979004, val_loss: 228.19435120\n",
      "Epoch: [11] [ 460/ 548] time: 183.2583, train_loss: 214.40425110, val_loss: 226.01379395\n",
      "Epoch: [11] [ 470/ 548] time: 183.4994, train_loss: 315.37680054, val_loss: 216.37426758\n",
      "Epoch: [11] [ 480/ 548] time: 183.7689, train_loss: 156.05354309, val_loss: 211.17585754\n",
      "Epoch: [11] [ 490/ 548] time: 184.0327, train_loss: 98.54420471, val_loss: 208.94158936\n",
      "Epoch: [11] [ 500/ 548] time: 184.2960, train_loss: 162.42080688, val_loss: 223.38003540\n",
      "Epoch: [11] [ 510/ 548] time: 184.5736, train_loss: 234.20053101, val_loss: 211.13226318\n",
      "Epoch: [11] [ 520/ 548] time: 184.8450, train_loss: 126.89402771, val_loss: 221.99026489\n",
      "Epoch: [11] [ 530/ 548] time: 185.1165, train_loss: 363.67498779, val_loss: 215.73641968\n",
      "Epoch: [11] [ 540/ 548] time: 185.4144, train_loss: 216.57794189, val_loss: 236.54234314\n",
      "Epoch: [12] [   0/ 548] time: 185.6523, train_loss: 163.40475464, val_loss: 211.03808594\n",
      "Epoch: [12] [  10/ 548] time: 185.9072, train_loss: 205.77198792, val_loss: 217.89135742\n",
      "Epoch: [12] [  20/ 548] time: 186.1719, train_loss: 331.21704102, val_loss: 215.19532776\n",
      "Epoch: [12] [  30/ 548] time: 186.4509, train_loss: 187.36630249, val_loss: 216.65206909\n",
      "Epoch: [12] [  40/ 548] time: 186.7426, train_loss: 125.31147766, val_loss: 213.48188782\n",
      "Epoch: [12] [  50/ 548] time: 187.0249, train_loss: 431.49417114, val_loss: 196.57977295\n",
      "Epoch: [12] [  60/ 548] time: 187.3018, train_loss: 385.02185059, val_loss: 215.71643066\n",
      "Epoch: [12] [  70/ 548] time: 187.5531, train_loss: 285.25549316, val_loss: 214.67698669\n",
      "Epoch: [12] [  80/ 548] time: 187.8043, train_loss: 121.75045776, val_loss: 208.11273193\n",
      "Epoch: [12] [  90/ 548] time: 188.0427, train_loss: 129.63276672, val_loss: 220.58506775\n",
      "Epoch: [12] [ 100/ 548] time: 188.2849, train_loss: 529.60827637, val_loss: 204.87728882\n",
      "Epoch: [12] [ 110/ 548] time: 188.5171, train_loss: 234.10165405, val_loss: 206.88812256\n",
      "Epoch: [12] [ 120/ 548] time: 188.7566, train_loss: 170.73452759, val_loss: 225.50210571\n",
      "Epoch: [12] [ 130/ 548] time: 188.9980, train_loss: 572.04528809, val_loss: 222.98580933\n",
      "Epoch: [12] [ 140/ 548] time: 189.2405, train_loss: 336.68847656, val_loss: 201.29071045\n",
      "Epoch: [12] [ 150/ 548] time: 189.4773, train_loss: 178.91055298, val_loss: 211.86882019\n",
      "Epoch: [12] [ 160/ 548] time: 189.7164, train_loss: 172.39715576, val_loss: 212.38351440\n",
      "Epoch: [12] [ 170/ 548] time: 189.9595, train_loss: 4228.99169922, val_loss: 201.02478027\n",
      "Epoch: [12] [ 180/ 548] time: 190.1965, train_loss: 64.58245087, val_loss: 236.84695435\n",
      "Epoch: [12] [ 190/ 548] time: 190.4309, train_loss: 236.79867554, val_loss: 232.96505737\n",
      "Epoch: [12] [ 200/ 548] time: 190.6629, train_loss: 373.60861206, val_loss: 224.26651001\n",
      "Epoch: [12] [ 210/ 548] time: 190.8956, train_loss: 203.74603271, val_loss: 238.89340210\n",
      "Epoch: [12] [ 220/ 548] time: 191.1366, train_loss: 314.46783447, val_loss: 227.88427734\n",
      "Epoch: [12] [ 230/ 548] time: 191.3763, train_loss: 82.65081024, val_loss: 221.56059265\n",
      "Epoch: [12] [ 240/ 548] time: 191.6164, train_loss: 396.65917969, val_loss: 206.25640869\n",
      "Epoch: [12] [ 250/ 548] time: 191.8563, train_loss: 263.54376221, val_loss: 214.45628357\n",
      "Epoch: [12] [ 260/ 548] time: 192.0952, train_loss: 293.01339722, val_loss: 203.76074219\n",
      "Epoch: [12] [ 270/ 548] time: 192.3440, train_loss: 139.44548035, val_loss: 208.05474854\n",
      "Epoch: [12] [ 280/ 548] time: 192.6059, train_loss: 93.85563660, val_loss: 213.20915222\n",
      "Epoch: [12] [ 290/ 548] time: 192.8771, train_loss: 258.93502808, val_loss: 183.17364502\n",
      "Epoch: [12] [ 300/ 548] time: 193.1479, train_loss: 322.75790405, val_loss: 193.14083862\n",
      "Epoch: [12] [ 310/ 548] time: 193.3924, train_loss: 206.53691101, val_loss: 232.88018799\n",
      "Epoch: [12] [ 320/ 548] time: 193.6281, train_loss: 259.10110474, val_loss: 223.29304504\n",
      "Epoch: [12] [ 330/ 548] time: 193.8698, train_loss: 152.36270142, val_loss: 205.16424561\n",
      "Epoch: [12] [ 340/ 548] time: 194.1041, train_loss: 244.01818848, val_loss: 217.05657959\n",
      "Epoch: [12] [ 350/ 548] time: 194.3414, train_loss: 593.45367432, val_loss: 194.06501770\n",
      "Epoch: [12] [ 360/ 548] time: 194.5792, train_loss: 237.72865295, val_loss: 189.28047180\n",
      "Epoch: [12] [ 370/ 548] time: 194.8154, train_loss: 38.50584793, val_loss: 189.04362488\n",
      "Epoch: [12] [ 380/ 548] time: 195.0509, train_loss: 350.54113770, val_loss: 209.34545898\n",
      "Epoch: [12] [ 390/ 548] time: 195.2896, train_loss: 1812.69958496, val_loss: 203.61355591\n",
      "Epoch: [12] [ 400/ 548] time: 195.5287, train_loss: 103.81156921, val_loss: 200.11895752\n",
      "Epoch: [12] [ 410/ 548] time: 195.7741, train_loss: 263.30801392, val_loss: 211.11007690\n",
      "Epoch: [12] [ 420/ 548] time: 196.0182, train_loss: 146.82104492, val_loss: 229.23754883\n",
      "Saving checkpoint\n",
      "Epoch: [12] [ 430/ 548] time: 197.3210, train_loss: 175.55488586, val_loss: 219.84898376\n",
      "Epoch: [12] [ 440/ 548] time: 197.6219, train_loss: 309.41921997, val_loss: 221.46606445\n",
      "Epoch: [12] [ 450/ 548] time: 197.9065, train_loss: 109.88681030, val_loss: 192.41485596\n",
      "Epoch: [12] [ 460/ 548] time: 198.1709, train_loss: 336.81762695, val_loss: 196.39294434\n",
      "Epoch: [12] [ 470/ 548] time: 198.4582, train_loss: 91.32624817, val_loss: 196.92343140\n",
      "Epoch: [12] [ 480/ 548] time: 198.7598, train_loss: 76.54066467, val_loss: 225.17572021\n",
      "Epoch: [12] [ 490/ 548] time: 199.0558, train_loss: 250.99327087, val_loss: 214.04315186\n",
      "Epoch: [12] [ 500/ 548] time: 199.3405, train_loss: 71.90419006, val_loss: 197.07617188\n",
      "Epoch: [12] [ 510/ 548] time: 199.6332, train_loss: 701.87438965, val_loss: 187.82545471\n",
      "Epoch: [12] [ 520/ 548] time: 199.8969, train_loss: 82.74291992, val_loss: 214.87974548\n",
      "Epoch: [12] [ 530/ 548] time: 200.1709, train_loss: 128.79394531, val_loss: 245.00598145\n",
      "Epoch: [12] [ 540/ 548] time: 200.4496, train_loss: 89.83249664, val_loss: 201.25875854\n",
      "Epoch: [13] [   0/ 548] time: 200.7189, train_loss: 94.85791016, val_loss: 200.44679260\n",
      "Epoch: [13] [  10/ 548] time: 201.0379, train_loss: 662.44494629, val_loss: 197.01560974\n",
      "Epoch: [13] [  20/ 548] time: 201.3668, train_loss: 234.73287964, val_loss: 210.70423889\n",
      "Epoch: [13] [  30/ 548] time: 201.6874, train_loss: 228.96859741, val_loss: 198.26809692\n",
      "Epoch: [13] [  40/ 548] time: 201.9956, train_loss: 201.54322815, val_loss: 197.22349548\n",
      "Epoch: [13] [  50/ 548] time: 202.3053, train_loss: 248.87303162, val_loss: 206.07879639\n",
      "Epoch: [13] [  60/ 548] time: 202.6050, train_loss: 153.38792419, val_loss: 203.10494995\n",
      "Epoch: [13] [  70/ 548] time: 202.9658, train_loss: 229.69569397, val_loss: 202.60292053\n",
      "Epoch: [13] [  80/ 548] time: 203.2865, train_loss: 95.43619537, val_loss: 197.36785889\n",
      "Epoch: [13] [  90/ 548] time: 203.5884, train_loss: 234.01766968, val_loss: 205.85559082\n",
      "Epoch: [13] [ 100/ 548] time: 203.8677, train_loss: 307.88421631, val_loss: 198.41212463\n",
      "Epoch: [13] [ 110/ 548] time: 204.1580, train_loss: 82.71287537, val_loss: 200.80560303\n",
      "Epoch: [13] [ 120/ 548] time: 204.4476, train_loss: 206.43574524, val_loss: 191.80212402\n",
      "Epoch: [13] [ 130/ 548] time: 204.7343, train_loss: 489.79263306, val_loss: 188.24305725\n",
      "Epoch: [13] [ 140/ 548] time: 205.0869, train_loss: 60.60794067, val_loss: 197.02012634\n",
      "Epoch: [13] [ 150/ 548] time: 205.4562, train_loss: 270.50723267, val_loss: 183.04756165\n",
      "Epoch: [13] [ 160/ 548] time: 205.8032, train_loss: 255.94351196, val_loss: 182.19741821\n",
      "Epoch: [13] [ 170/ 548] time: 206.1273, train_loss: 577.17504883, val_loss: 185.03027344\n",
      "Epoch: [13] [ 180/ 548] time: 206.4228, train_loss: 136.40699768, val_loss: 187.33258057\n",
      "Epoch: [13] [ 190/ 548] time: 206.6760, train_loss: 150.37237549, val_loss: 175.09024048\n",
      "Epoch: [13] [ 200/ 548] time: 206.9288, train_loss: 356.48199463, val_loss: 175.41885376\n",
      "Epoch: [13] [ 210/ 548] time: 207.1731, train_loss: 401.53002930, val_loss: 195.27142334\n",
      "Epoch: [13] [ 220/ 548] time: 207.4449, train_loss: 256.50015259, val_loss: 189.39001465\n",
      "Epoch: [13] [ 230/ 548] time: 207.6904, train_loss: 136.51959229, val_loss: 182.60812378\n",
      "Epoch: [13] [ 240/ 548] time: 207.9269, train_loss: 319.87771606, val_loss: 183.52244568\n",
      "Epoch: [13] [ 250/ 548] time: 208.1627, train_loss: 117.17211914, val_loss: 182.83386230\n",
      "Epoch: [13] [ 260/ 548] time: 208.4009, train_loss: 349.84777832, val_loss: 185.83116150\n",
      "Epoch: [13] [ 270/ 548] time: 208.6359, train_loss: 94.48943329, val_loss: 175.07853699\n",
      "Epoch: [13] [ 280/ 548] time: 208.8791, train_loss: 160.91793823, val_loss: 176.32385254\n",
      "Epoch: [13] [ 290/ 548] time: 209.1110, train_loss: 398.28430176, val_loss: 176.67729187\n",
      "Epoch: [13] [ 300/ 548] time: 209.3505, train_loss: 240.97593689, val_loss: 186.10243225\n",
      "Epoch: [13] [ 310/ 548] time: 209.5846, train_loss: 138.52658081, val_loss: 200.24053955\n",
      "Epoch: [13] [ 320/ 548] time: 209.8220, train_loss: 286.57571411, val_loss: 180.60247803\n",
      "Epoch: [13] [ 330/ 548] time: 210.0608, train_loss: 303.27377319, val_loss: 184.07510376\n",
      "Epoch: [13] [ 340/ 548] time: 210.2960, train_loss: 292.19235229, val_loss: 238.49337769\n",
      "Epoch: [13] [ 350/ 548] time: 210.5376, train_loss: 168.33981323, val_loss: 203.08309937\n",
      "Epoch: [13] [ 360/ 548] time: 210.7736, train_loss: 66.68131256, val_loss: 195.22189331\n",
      "Epoch: [13] [ 370/ 548] time: 211.0122, train_loss: 175.68501282, val_loss: 180.34158325\n",
      "Epoch: [13] [ 380/ 548] time: 211.2522, train_loss: 155.91590881, val_loss: 189.42773438\n",
      "Epoch: [13] [ 390/ 548] time: 211.5242, train_loss: 338.43835449, val_loss: 189.72434998\n",
      "Epoch: [13] [ 400/ 548] time: 211.8096, train_loss: 262.53890991, val_loss: 179.89129639\n",
      "Epoch: [13] [ 410/ 548] time: 212.0744, train_loss: 479.08212280, val_loss: 180.14393616\n",
      "Epoch: [13] [ 420/ 548] time: 212.3748, train_loss: 173.27372742, val_loss: 177.40180969\n",
      "Epoch: [13] [ 430/ 548] time: 212.6310, train_loss: 306.82165527, val_loss: 176.80642700\n",
      "Epoch: [13] [ 440/ 548] time: 212.8687, train_loss: 147.61090088, val_loss: 164.93974304\n",
      "Epoch: [13] [ 450/ 548] time: 213.1064, train_loss: 404.42932129, val_loss: 188.71917725\n",
      "Epoch: [13] [ 460/ 548] time: 213.3598, train_loss: 152.83384705, val_loss: 182.48716736\n",
      "Epoch: [13] [ 470/ 548] time: 213.6215, train_loss: 389.30023193, val_loss: 176.92105103\n",
      "Epoch: [13] [ 480/ 548] time: 213.8921, train_loss: 411.38247681, val_loss: 175.57308960\n",
      "Epoch: [13] [ 490/ 548] time: 214.1457, train_loss: 249.63046265, val_loss: 172.92926025\n",
      "Epoch: [13] [ 500/ 548] time: 214.4265, train_loss: 341.86718750, val_loss: 161.16360474\n",
      "Epoch: [13] [ 510/ 548] time: 214.6713, train_loss: 149.28424072, val_loss: 187.66976929\n",
      "Epoch: [13] [ 520/ 548] time: 214.9197, train_loss: 229.37739563, val_loss: 170.16044617\n",
      "Epoch: [13] [ 530/ 548] time: 215.1678, train_loss: 240.72792053, val_loss: 173.06668091\n",
      "Epoch: [13] [ 540/ 548] time: 215.4764, train_loss: 127.22022247, val_loss: 153.80801392\n",
      "Epoch: [14] [   0/ 548] time: 215.6966, train_loss: 284.90274048, val_loss: 177.82464600\n",
      "Epoch: [14] [  10/ 548] time: 215.9381, train_loss: 255.36253357, val_loss: 200.50479126\n",
      "Epoch: [14] [  20/ 548] time: 216.1829, train_loss: 235.03817749, val_loss: 178.40054321\n",
      "Epoch: [14] [  30/ 548] time: 216.4211, train_loss: 236.94334412, val_loss: 182.83721924\n",
      "Epoch: [14] [  40/ 548] time: 216.6615, train_loss: 228.08287048, val_loss: 174.27725220\n",
      "Epoch: [14] [  50/ 548] time: 216.8988, train_loss: 73.06831360, val_loss: 177.09594727\n",
      "Epoch: [14] [  60/ 548] time: 217.1440, train_loss: 256.67858887, val_loss: 185.78677368\n",
      "Epoch: [14] [  70/ 548] time: 217.4113, train_loss: 221.69030762, val_loss: 181.23822021\n",
      "Epoch: [14] [  80/ 548] time: 217.6693, train_loss: 487.53350830, val_loss: 173.21324158\n",
      "Epoch: [14] [  90/ 548] time: 217.9360, train_loss: 75.42710876, val_loss: 163.99966431\n",
      "Epoch: [14] [ 100/ 548] time: 218.2093, train_loss: 290.15359497, val_loss: 167.74610901\n",
      "Epoch: [14] [ 110/ 548] time: 218.4901, train_loss: 156.99496460, val_loss: 168.81196594\n",
      "Epoch: [14] [ 120/ 548] time: 218.7718, train_loss: 128.78063965, val_loss: 159.51614380\n",
      "Epoch: [14] [ 130/ 548] time: 219.0374, train_loss: 137.91488647, val_loss: 165.85186768\n",
      "Epoch: [14] [ 140/ 548] time: 219.3104, train_loss: 42.57760620, val_loss: 174.47608948\n",
      "Epoch: [14] [ 150/ 548] time: 219.5630, train_loss: 105.90995789, val_loss: 174.06291199\n",
      "Epoch: [14] [ 160/ 548] time: 219.8345, train_loss: 31.54957581, val_loss: 175.68203735\n",
      "Epoch: [14] [ 170/ 548] time: 220.1049, train_loss: 58.67459106, val_loss: 165.09552002\n",
      "Epoch: [14] [ 180/ 548] time: 220.3532, train_loss: 94.91754150, val_loss: 165.74020386\n",
      "Epoch: [14] [ 190/ 548] time: 220.6266, train_loss: 104.72991943, val_loss: 168.29219055\n",
      "Epoch: [14] [ 200/ 548] time: 220.8871, train_loss: 141.67195129, val_loss: 169.91511536\n",
      "Epoch: [14] [ 210/ 548] time: 221.1358, train_loss: 180.69512939, val_loss: 154.00869751\n",
      "Epoch: [14] [ 220/ 548] time: 221.3968, train_loss: 152.77960205, val_loss: 160.69400024\n",
      "Epoch: [14] [ 230/ 548] time: 221.6447, train_loss: 89.61846161, val_loss: 156.52844238\n",
      "Epoch: [14] [ 240/ 548] time: 221.8892, train_loss: 215.27044678, val_loss: 151.56866455\n",
      "Epoch: [14] [ 250/ 548] time: 222.1220, train_loss: 118.43411255, val_loss: 159.62957764\n",
      "Epoch: [14] [ 260/ 548] time: 222.3538, train_loss: 171.83628845, val_loss: 157.13679504\n",
      "Epoch: [14] [ 270/ 548] time: 222.6130, train_loss: 242.19097900, val_loss: 153.56658936\n",
      "Epoch: [14] [ 280/ 548] time: 222.8743, train_loss: 367.44931030, val_loss: 150.81594849\n",
      "Epoch: [14] [ 290/ 548] time: 223.1431, train_loss: 173.50401306, val_loss: 144.71722412\n",
      "Epoch: [14] [ 300/ 548] time: 223.3954, train_loss: 293.25036621, val_loss: 151.47329712\n",
      "Epoch: [14] [ 310/ 548] time: 223.6455, train_loss: 85.16505432, val_loss: 151.48620605\n",
      "Epoch: [14] [ 320/ 548] time: 223.9351, train_loss: 127.01483154, val_loss: 142.71415710\n",
      "Saving checkpoint\n",
      "Epoch: [14] [ 330/ 548] time: 225.2950, train_loss: 97.51190186, val_loss: 159.40943909\n",
      "Epoch: [14] [ 340/ 548] time: 225.5545, train_loss: 337.75048828, val_loss: 164.73272705\n",
      "Epoch: [14] [ 350/ 548] time: 225.8145, train_loss: 250.05926514, val_loss: 150.50939941\n",
      "Epoch: [14] [ 360/ 548] time: 226.0446, train_loss: 51.58869553, val_loss: 156.14978027\n",
      "Epoch: [14] [ 370/ 548] time: 226.2797, train_loss: 149.25311279, val_loss: 151.09469604\n",
      "Epoch: [14] [ 380/ 548] time: 226.5088, train_loss: 207.69831848, val_loss: 166.88760376\n",
      "Epoch: [14] [ 390/ 548] time: 226.7338, train_loss: 218.50079346, val_loss: 152.14578247\n",
      "Epoch: [14] [ 400/ 548] time: 226.9648, train_loss: 44.69292831, val_loss: 146.81488037\n",
      "Epoch: [14] [ 410/ 548] time: 227.2003, train_loss: 135.73567200, val_loss: 152.47540283\n",
      "Epoch: [14] [ 420/ 548] time: 227.4271, train_loss: 918.94488525, val_loss: 157.40998840\n",
      "Epoch: [14] [ 430/ 548] time: 227.6587, train_loss: 124.07234192, val_loss: 156.22583008\n",
      "Epoch: [14] [ 440/ 548] time: 227.8956, train_loss: 832.78186035, val_loss: 159.87298584\n",
      "Epoch: [14] [ 450/ 548] time: 228.1303, train_loss: 168.47930908, val_loss: 146.26139832\n",
      "Epoch: [14] [ 460/ 548] time: 228.3775, train_loss: 209.50433350, val_loss: 165.79690552\n",
      "Epoch: [14] [ 470/ 548] time: 228.6191, train_loss: 155.59640503, val_loss: 157.76611328\n",
      "Epoch: [14] [ 480/ 548] time: 228.8694, train_loss: 746.63446045, val_loss: 194.87231445\n",
      "Epoch: [14] [ 490/ 548] time: 229.1164, train_loss: 78.45926666, val_loss: 206.91687012\n",
      "Epoch: [14] [ 500/ 548] time: 229.3653, train_loss: 495.14627075, val_loss: 171.72412109\n",
      "Epoch: [14] [ 510/ 548] time: 229.6247, train_loss: 286.79449463, val_loss: 164.35211182\n",
      "Epoch: [14] [ 520/ 548] time: 229.9046, train_loss: 183.77287292, val_loss: 155.05172729\n",
      "Epoch: [14] [ 530/ 548] time: 230.1631, train_loss: 481.79174805, val_loss: 152.42100525\n",
      "Epoch: [14] [ 540/ 548] time: 230.4326, train_loss: 190.68995667, val_loss: 161.02058411\n",
      "Epoch: [15] [   0/ 548] time: 230.6315, train_loss: 153.06112671, val_loss: 148.76217651\n",
      "Epoch: [15] [  10/ 548] time: 230.8715, train_loss: 80.29603577, val_loss: 148.61123657\n",
      "Epoch: [15] [  20/ 548] time: 231.1094, train_loss: 135.63540649, val_loss: 154.19064331\n",
      "Epoch: [15] [  30/ 548] time: 231.3431, train_loss: 125.38772583, val_loss: 154.56771851\n",
      "Epoch: [15] [  40/ 548] time: 231.5789, train_loss: 103.36134338, val_loss: 149.81158447\n",
      "Epoch: [15] [  50/ 548] time: 231.8198, train_loss: 100.22679901, val_loss: 150.88095093\n",
      "Epoch: [15] [  60/ 548] time: 232.0564, train_loss: 87.17609406, val_loss: 146.31581116\n",
      "Epoch: [15] [  70/ 548] time: 232.2949, train_loss: 41.36415100, val_loss: 144.22659302\n",
      "Epoch: [15] [  80/ 548] time: 232.5373, train_loss: 82.79995728, val_loss: 137.63195801\n",
      "Epoch: [15] [  90/ 548] time: 232.7771, train_loss: 940.68359375, val_loss: 149.09735107\n",
      "Epoch: [15] [ 100/ 548] time: 233.0164, train_loss: 747.34197998, val_loss: 146.55715942\n",
      "Epoch: [15] [ 110/ 548] time: 233.2512, train_loss: 146.74157715, val_loss: 148.53118896\n",
      "Epoch: [15] [ 120/ 548] time: 233.4898, train_loss: 27.85418701, val_loss: 145.64025879\n",
      "Epoch: [15] [ 130/ 548] time: 233.7269, train_loss: 186.78520203, val_loss: 140.64672852\n",
      "Epoch: [15] [ 140/ 548] time: 233.9583, train_loss: 304.83218384, val_loss: 149.77206421\n",
      "Epoch: [15] [ 150/ 548] time: 234.1895, train_loss: 98.41970062, val_loss: 151.56137085\n",
      "Epoch: [15] [ 160/ 548] time: 234.4188, train_loss: 35.99855804, val_loss: 145.46319580\n",
      "Epoch: [15] [ 170/ 548] time: 234.6499, train_loss: 139.75906372, val_loss: 148.69772339\n",
      "Epoch: [15] [ 180/ 548] time: 234.8819, train_loss: 87.08566284, val_loss: 170.28244019\n",
      "Epoch: [15] [ 190/ 548] time: 235.1207, train_loss: 50.85291290, val_loss: 157.33822632\n",
      "Epoch: [15] [ 200/ 548] time: 235.3637, train_loss: 185.13903809, val_loss: 147.27629089\n",
      "Epoch: [15] [ 210/ 548] time: 235.6172, train_loss: 403.70294189, val_loss: 152.45446777\n",
      "Epoch: [15] [ 220/ 548] time: 235.8840, train_loss: 140.15945435, val_loss: 176.72491455\n",
      "Epoch: [15] [ 230/ 548] time: 236.1456, train_loss: 75.71939087, val_loss: 170.65545654\n",
      "Epoch: [15] [ 240/ 548] time: 236.4212, train_loss: 175.87020874, val_loss: 153.05737305\n",
      "Epoch: [15] [ 250/ 548] time: 236.6942, train_loss: 144.09698486, val_loss: 163.21363831\n",
      "Epoch: [15] [ 260/ 548] time: 236.9373, train_loss: 63.53455353, val_loss: 173.62847900\n",
      "Epoch: [15] [ 270/ 548] time: 237.1859, train_loss: 604.94323730, val_loss: 158.49185181\n",
      "Epoch: [15] [ 280/ 548] time: 237.4302, train_loss: 54.11210632, val_loss: 154.87167358\n",
      "Epoch: [15] [ 290/ 548] time: 237.6666, train_loss: 179.18527222, val_loss: 154.11096191\n",
      "Epoch: [15] [ 300/ 548] time: 237.9047, train_loss: 236.22427368, val_loss: 143.62005615\n",
      "Epoch: [15] [ 310/ 548] time: 238.1392, train_loss: 167.17654419, val_loss: 135.76617432\n",
      "Epoch: [15] [ 320/ 548] time: 238.3734, train_loss: 146.52139282, val_loss: 140.62570190\n",
      "Epoch: [15] [ 330/ 548] time: 238.6028, train_loss: 277.45147705, val_loss: 142.24661255\n",
      "Epoch: [15] [ 340/ 548] time: 238.8328, train_loss: 107.68176270, val_loss: 138.89041138\n",
      "Epoch: [15] [ 350/ 548] time: 239.0676, train_loss: 281.28622437, val_loss: 156.44311523\n",
      "Epoch: [15] [ 360/ 548] time: 239.2994, train_loss: 175.83114624, val_loss: 147.48104858\n",
      "Epoch: [15] [ 370/ 548] time: 239.5287, train_loss: 124.93521118, val_loss: 134.93270874\n",
      "Epoch: [15] [ 380/ 548] time: 239.7628, train_loss: 243.04154968, val_loss: 139.18258667\n",
      "Epoch: [15] [ 390/ 548] time: 239.9978, train_loss: 61.52699280, val_loss: 134.11547852\n",
      "Epoch: [15] [ 400/ 548] time: 240.2324, train_loss: 127.87490082, val_loss: 128.70895386\n",
      "Epoch: [15] [ 410/ 548] time: 240.4713, train_loss: 57.56470490, val_loss: 128.80329895\n",
      "Epoch: [15] [ 420/ 548] time: 240.7086, train_loss: 181.66978455, val_loss: 122.09066772\n",
      "Epoch: [15] [ 430/ 548] time: 240.9456, train_loss: 68.73257446, val_loss: 124.75544739\n",
      "Epoch: [15] [ 440/ 548] time: 241.1798, train_loss: 117.77701569, val_loss: 123.85266113\n",
      "Epoch: [15] [ 450/ 548] time: 241.4155, train_loss: 230.36309814, val_loss: 128.24624634\n",
      "Epoch: [15] [ 460/ 548] time: 241.6541, train_loss: 151.45584106, val_loss: 139.74043274\n",
      "Epoch: [15] [ 470/ 548] time: 241.9158, train_loss: 76.25270081, val_loss: 128.48837280\n",
      "Epoch: [15] [ 480/ 548] time: 242.2071, train_loss: 15.25381851, val_loss: 129.52557373\n",
      "Epoch: [15] [ 490/ 548] time: 242.4761, train_loss: 310.08975220, val_loss: 124.75816345\n",
      "Epoch: [15] [ 500/ 548] time: 242.7411, train_loss: 101.25444794, val_loss: 118.86877441\n",
      "Epoch: [15] [ 510/ 548] time: 243.0006, train_loss: 82.05754089, val_loss: 120.79935455\n",
      "Epoch: [15] [ 520/ 548] time: 243.2454, train_loss: 87.21390533, val_loss: 118.20404053\n",
      "Epoch: [15] [ 530/ 548] time: 243.4814, train_loss: 72.19885254, val_loss: 126.08026886\n",
      "Epoch: [15] [ 540/ 548] time: 243.7184, train_loss: 104.93198395, val_loss: 141.91424561\n",
      "Epoch: [16] [   0/ 548] time: 243.9136, train_loss: 249.18452454, val_loss: 132.17335510\n",
      "Epoch: [16] [  10/ 548] time: 244.1520, train_loss: 150.86503601, val_loss: 129.66821289\n",
      "Epoch: [16] [  20/ 548] time: 244.3886, train_loss: 101.87597656, val_loss: 126.29351807\n",
      "Epoch: [16] [  30/ 548] time: 244.6283, train_loss: 98.94487000, val_loss: 134.84808350\n",
      "Epoch: [16] [  40/ 548] time: 244.8698, train_loss: 26.50009155, val_loss: 134.56869507\n",
      "Epoch: [16] [  50/ 548] time: 245.1093, train_loss: 27.21411133, val_loss: 137.56474304\n",
      "Epoch: [16] [  60/ 548] time: 245.3616, train_loss: 104.07463837, val_loss: 129.87438965\n",
      "Epoch: [16] [  70/ 548] time: 245.6272, train_loss: 81.90171814, val_loss: 123.32196808\n",
      "Epoch: [16] [  80/ 548] time: 245.8607, train_loss: 80.76467896, val_loss: 126.28221130\n",
      "Epoch: [16] [  90/ 548] time: 246.1185, train_loss: 39.61794281, val_loss: 129.04638672\n",
      "Epoch: [16] [ 100/ 548] time: 246.3845, train_loss: 144.81639099, val_loss: 137.79803467\n",
      "Epoch: [16] [ 110/ 548] time: 246.6533, train_loss: 437.13558960, val_loss: 143.61764526\n",
      "Epoch: [16] [ 120/ 548] time: 246.9092, train_loss: 252.99623108, val_loss: 151.71214294\n",
      "Epoch: [16] [ 130/ 548] time: 247.1628, train_loss: 22.72292709, val_loss: 127.19269562\n",
      "Epoch: [16] [ 140/ 548] time: 247.4053, train_loss: 114.95091248, val_loss: 122.44804382\n",
      "Epoch: [16] [ 150/ 548] time: 247.6526, train_loss: 608.99383545, val_loss: 117.21013641\n",
      "Epoch: [16] [ 160/ 548] time: 247.9040, train_loss: 432.89099121, val_loss: 122.69323730\n",
      "Epoch: [16] [ 170/ 548] time: 248.1906, train_loss: 82.59883881, val_loss: 126.01606750\n",
      "Epoch: [16] [ 180/ 548] time: 248.4879, train_loss: 149.60893250, val_loss: 123.23628235\n",
      "Epoch: [16] [ 190/ 548] time: 248.7553, train_loss: 79.30407715, val_loss: 121.53020477\n",
      "Epoch: [16] [ 200/ 548] time: 249.0486, train_loss: 93.92105103, val_loss: 120.58960724\n",
      "Epoch: [16] [ 210/ 548] time: 249.3238, train_loss: 64.28631592, val_loss: 119.04109192\n",
      "Epoch: [16] [ 220/ 548] time: 249.5973, train_loss: 183.82730103, val_loss: 118.35423279\n",
      "Epoch: [16] [ 230/ 548] time: 249.8674, train_loss: 132.50289917, val_loss: 130.25485229\n",
      "Saving checkpoint\n",
      "Epoch: [16] [ 240/ 548] time: 251.2231, train_loss: 63.27323914, val_loss: 121.14382172\n",
      "Epoch: [16] [ 250/ 548] time: 251.5247, train_loss: 93.34804535, val_loss: 118.52210236\n",
      "Epoch: [16] [ 260/ 548] time: 251.7858, train_loss: 111.43296814, val_loss: 120.02180481\n",
      "Epoch: [16] [ 270/ 548] time: 252.0454, train_loss: 235.61611938, val_loss: 124.53659058\n",
      "Epoch: [16] [ 280/ 548] time: 252.3130, train_loss: 126.29008484, val_loss: 125.33115387\n",
      "Epoch: [16] [ 290/ 548] time: 252.6024, train_loss: 169.17993164, val_loss: 116.30130768\n",
      "Epoch: [16] [ 300/ 548] time: 252.8767, train_loss: 37.78421783, val_loss: 110.17263794\n",
      "Epoch: [16] [ 310/ 548] time: 253.1519, train_loss: 155.21105957, val_loss: 124.07879639\n",
      "Epoch: [16] [ 320/ 548] time: 253.5336, train_loss: 113.14859009, val_loss: 146.28002930\n",
      "Epoch: [16] [ 330/ 548] time: 253.8456, train_loss: 113.62829590, val_loss: 144.30712891\n",
      "Epoch: [16] [ 340/ 548] time: 254.1373, train_loss: 225.08985901, val_loss: 140.72079468\n",
      "Epoch: [16] [ 350/ 548] time: 254.4620, train_loss: 114.24988556, val_loss: 140.08413696\n",
      "Epoch: [16] [ 360/ 548] time: 254.7748, train_loss: 107.59584808, val_loss: 132.28010559\n",
      "Epoch: [16] [ 370/ 548] time: 255.0842, train_loss: 71.37326050, val_loss: 122.06755829\n",
      "Epoch: [16] [ 380/ 548] time: 255.3749, train_loss: 97.13024139, val_loss: 131.20529175\n",
      "Epoch: [16] [ 390/ 548] time: 255.6578, train_loss: 207.99871826, val_loss: 130.77502441\n",
      "Epoch: [16] [ 400/ 548] time: 255.9295, train_loss: 136.70045471, val_loss: 125.91668701\n",
      "Epoch: [16] [ 410/ 548] time: 256.2185, train_loss: 130.02954102, val_loss: 112.98886108\n",
      "Epoch: [16] [ 420/ 548] time: 256.5070, train_loss: 214.39836121, val_loss: 112.22506714\n",
      "Epoch: [16] [ 430/ 548] time: 256.8104, train_loss: 132.04852295, val_loss: 114.87586975\n",
      "Epoch: [16] [ 440/ 548] time: 257.0923, train_loss: 75.92323303, val_loss: 109.97756958\n",
      "Epoch: [16] [ 450/ 548] time: 257.3603, train_loss: 107.83489990, val_loss: 110.78619385\n",
      "Epoch: [16] [ 460/ 548] time: 257.7300, train_loss: 429.27209473, val_loss: 139.25146484\n",
      "Epoch: [16] [ 470/ 548] time: 258.0941, train_loss: 84.66678619, val_loss: 111.86410522\n",
      "Epoch: [16] [ 480/ 548] time: 258.4185, train_loss: 218.96456909, val_loss: 118.27780151\n",
      "Epoch: [16] [ 490/ 548] time: 258.6934, train_loss: 103.08455658, val_loss: 116.98599243\n",
      "Epoch: [16] [ 500/ 548] time: 258.9721, train_loss: 80.25483704, val_loss: 116.90509796\n",
      "Epoch: [16] [ 510/ 548] time: 259.2517, train_loss: 303.54879761, val_loss: 119.49052429\n",
      "Epoch: [16] [ 520/ 548] time: 259.5647, train_loss: 150.50054932, val_loss: 112.99225616\n",
      "Epoch: [16] [ 530/ 548] time: 259.9355, train_loss: 241.04083252, val_loss: 116.02349854\n",
      "Epoch: [16] [ 540/ 548] time: 260.2692, train_loss: 146.49911499, val_loss: 118.13639832\n",
      "Epoch: [17] [   0/ 548] time: 260.5202, train_loss: 187.60627747, val_loss: 106.90917969\n",
      "Epoch: [17] [  10/ 548] time: 260.8685, train_loss: 1434.06286621, val_loss: 107.95195007\n",
      "Epoch: [17] [  20/ 548] time: 261.1956, train_loss: 89.81033325, val_loss: 108.82797241\n",
      "Epoch: [17] [  30/ 548] time: 261.5065, train_loss: 181.77238464, val_loss: 116.18990326\n",
      "Epoch: [17] [  40/ 548] time: 261.8244, train_loss: 203.91436768, val_loss: 109.60758972\n",
      "Epoch: [17] [  50/ 548] time: 262.1758, train_loss: 76.77545166, val_loss: 110.25851440\n",
      "Epoch: [17] [  60/ 548] time: 262.4649, train_loss: 73.41854858, val_loss: 128.07788086\n",
      "Epoch: [17] [  70/ 548] time: 262.7486, train_loss: 293.33862305, val_loss: 110.38234711\n",
      "Epoch: [17] [  80/ 548] time: 263.0089, train_loss: 67.12171173, val_loss: 119.81087494\n",
      "Epoch: [17] [  90/ 548] time: 263.2510, train_loss: 1457.00463867, val_loss: 102.43852997\n",
      "Epoch: [17] [ 100/ 548] time: 263.4939, train_loss: 699.04400635, val_loss: 99.64246368\n",
      "Epoch: [17] [ 110/ 548] time: 263.7413, train_loss: 61.32383347, val_loss: 109.32284546\n",
      "Epoch: [17] [ 120/ 548] time: 263.9967, train_loss: 109.99278259, val_loss: 108.68750000\n",
      "Epoch: [17] [ 130/ 548] time: 264.2656, train_loss: 95.08322144, val_loss: 144.47334290\n",
      "Epoch: [17] [ 140/ 548] time: 264.5203, train_loss: 213.19226074, val_loss: 133.19955444\n",
      "Epoch: [17] [ 150/ 548] time: 264.7766, train_loss: 97.31914520, val_loss: 119.76405334\n",
      "Epoch: [17] [ 160/ 548] time: 265.0279, train_loss: 116.02040863, val_loss: 104.36654663\n",
      "Epoch: [17] [ 170/ 548] time: 265.2998, train_loss: 60.71332550, val_loss: 103.38481140\n",
      "Epoch: [17] [ 180/ 548] time: 265.5623, train_loss: 40.71646881, val_loss: 95.44245148\n",
      "Epoch: [17] [ 190/ 548] time: 265.8201, train_loss: 111.13997650, val_loss: 97.90708923\n",
      "Epoch: [17] [ 200/ 548] time: 266.0555, train_loss: 30.30258942, val_loss: 94.71311951\n",
      "Epoch: [17] [ 210/ 548] time: 266.2943, train_loss: 27.48749542, val_loss: 91.44932556\n",
      "Epoch: [17] [ 220/ 548] time: 266.5281, train_loss: 6.34363556, val_loss: 95.27931213\n",
      "Epoch: [17] [ 230/ 548] time: 266.7662, train_loss: 239.66189575, val_loss: 101.23724365\n",
      "Epoch: [17] [ 240/ 548] time: 267.0162, train_loss: 47.11277390, val_loss: 97.67853546\n",
      "Epoch: [17] [ 250/ 548] time: 267.2644, train_loss: 170.75425720, val_loss: 131.57749939\n",
      "Epoch: [17] [ 260/ 548] time: 267.5372, train_loss: 101.84214783, val_loss: 121.88400269\n",
      "Epoch: [17] [ 270/ 548] time: 267.8449, train_loss: 90.89025879, val_loss: 104.85041809\n",
      "Epoch: [17] [ 280/ 548] time: 268.1361, train_loss: 87.24717712, val_loss: 98.66183472\n",
      "Epoch: [17] [ 290/ 548] time: 268.4257, train_loss: 66.83232880, val_loss: 91.66203308\n",
      "Epoch: [17] [ 300/ 548] time: 268.6769, train_loss: 25.67042160, val_loss: 91.68002319\n",
      "Epoch: [17] [ 310/ 548] time: 268.9329, train_loss: 135.89477539, val_loss: 94.75907898\n",
      "Epoch: [17] [ 320/ 548] time: 269.1881, train_loss: 722.66632080, val_loss: 90.49421692\n",
      "Epoch: [17] [ 330/ 548] time: 269.4314, train_loss: 79.97283936, val_loss: 92.66470337\n",
      "Epoch: [17] [ 340/ 548] time: 269.6727, train_loss: 133.25198364, val_loss: 89.19461823\n",
      "Epoch: [17] [ 350/ 548] time: 269.9263, train_loss: 624.15991211, val_loss: 94.59443665\n",
      "Epoch: [17] [ 360/ 548] time: 270.1754, train_loss: 200.38757324, val_loss: 91.11071777\n",
      "Epoch: [17] [ 370/ 548] time: 270.4070, train_loss: 132.39538574, val_loss: 91.28734589\n",
      "Epoch: [17] [ 380/ 548] time: 270.6454, train_loss: 118.39184570, val_loss: 89.60433960\n",
      "Epoch: [17] [ 390/ 548] time: 270.8784, train_loss: 39.90068817, val_loss: 86.87435913\n",
      "Epoch: [17] [ 400/ 548] time: 271.1083, train_loss: 117.23954773, val_loss: 98.55419922\n",
      "Epoch: [17] [ 410/ 548] time: 271.3462, train_loss: 145.00039673, val_loss: 124.93812561\n",
      "Epoch: [17] [ 420/ 548] time: 271.6021, train_loss: 100.71800995, val_loss: 114.39393616\n",
      "Epoch: [17] [ 430/ 548] time: 271.8605, train_loss: 60.38171005, val_loss: 100.69218445\n",
      "Epoch: [17] [ 440/ 548] time: 272.0971, train_loss: 111.47678375, val_loss: 113.86093140\n",
      "Epoch: [17] [ 450/ 548] time: 272.3504, train_loss: 179.93965149, val_loss: 112.14459229\n",
      "Epoch: [17] [ 460/ 548] time: 272.5941, train_loss: 78.69084167, val_loss: 109.22399902\n",
      "Epoch: [17] [ 470/ 548] time: 272.8345, train_loss: 109.10726166, val_loss: 102.08481598\n",
      "Epoch: [17] [ 480/ 548] time: 273.0851, train_loss: 111.93293762, val_loss: 98.52856445\n",
      "Epoch: [17] [ 490/ 548] time: 273.3226, train_loss: 123.86594391, val_loss: 97.54576874\n",
      "Epoch: [17] [ 500/ 548] time: 273.5683, train_loss: 63.77758789, val_loss: 89.34049988\n",
      "Epoch: [17] [ 510/ 548] time: 273.8376, train_loss: 155.39425659, val_loss: 89.10897827\n",
      "Epoch: [17] [ 520/ 548] time: 274.1204, train_loss: 155.04995728, val_loss: 88.54745483\n",
      "Epoch: [17] [ 530/ 548] time: 274.3918, train_loss: 63.55519104, val_loss: 89.03804779\n",
      "Epoch: [17] [ 540/ 548] time: 274.6431, train_loss: 286.52532959, val_loss: 85.21786499\n",
      "Epoch: [18] [   0/ 548] time: 274.8439, train_loss: 30.47144318, val_loss: 87.05709839\n",
      "Epoch: [18] [  10/ 548] time: 275.0999, train_loss: 42.78932190, val_loss: 110.49317932\n",
      "Epoch: [18] [  20/ 548] time: 275.3671, train_loss: 106.23609924, val_loss: 95.71232605\n",
      "Epoch: [18] [  30/ 548] time: 275.6460, train_loss: 66.47598267, val_loss: 101.22277832\n",
      "Epoch: [18] [  40/ 548] time: 275.8889, train_loss: 37.63503265, val_loss: 110.74690247\n",
      "Epoch: [18] [  50/ 548] time: 276.1318, train_loss: 37.89253235, val_loss: 93.86653137\n",
      "Epoch: [18] [  60/ 548] time: 276.3770, train_loss: 147.71519470, val_loss: 92.04826355\n",
      "Epoch: [18] [  70/ 548] time: 276.6182, train_loss: 17.06664276, val_loss: 90.87148285\n",
      "Epoch: [18] [  80/ 548] time: 276.8570, train_loss: 87.39351654, val_loss: 84.83540344\n",
      "Epoch: [18] [  90/ 548] time: 277.1100, train_loss: 136.84921265, val_loss: 89.58843994\n",
      "Epoch: [18] [ 100/ 548] time: 277.3451, train_loss: 51.81525421, val_loss: 95.02409363\n",
      "Epoch: [18] [ 110/ 548] time: 277.5783, train_loss: 65.84486389, val_loss: 98.86467743\n",
      "Epoch: [18] [ 120/ 548] time: 277.8253, train_loss: 480.91925049, val_loss: 82.72409058\n",
      "Epoch: [18] [ 130/ 548] time: 278.0598, train_loss: 237.67660522, val_loss: 92.61544800\n",
      "Saving checkpoint\n",
      "Epoch: [18] [ 140/ 548] time: 279.3603, train_loss: 11.89074707, val_loss: 101.69004822\n",
      "Epoch: [18] [ 150/ 548] time: 279.6158, train_loss: 240.20901489, val_loss: 171.86572266\n",
      "Epoch: [18] [ 160/ 548] time: 279.9084, train_loss: 60.82878113, val_loss: 102.01882935\n",
      "Epoch: [18] [ 170/ 548] time: 280.2044, train_loss: 140.07907104, val_loss: 102.34214783\n",
      "Epoch: [18] [ 180/ 548] time: 280.4965, train_loss: 239.32150269, val_loss: 84.75321960\n",
      "Epoch: [18] [ 190/ 548] time: 280.8111, train_loss: 635.80682373, val_loss: 83.02543640\n",
      "Epoch: [18] [ 200/ 548] time: 281.1223, train_loss: 461.37371826, val_loss: 76.80935669\n",
      "Epoch: [18] [ 210/ 548] time: 281.3985, train_loss: 24.13542175, val_loss: 70.43859100\n",
      "Epoch: [18] [ 220/ 548] time: 281.6527, train_loss: 89.68301392, val_loss: 74.62773132\n",
      "Epoch: [18] [ 230/ 548] time: 281.9088, train_loss: 177.38055420, val_loss: 80.95043182\n",
      "Epoch: [18] [ 240/ 548] time: 282.1500, train_loss: 104.03475952, val_loss: 79.44885254\n",
      "Epoch: [18] [ 250/ 548] time: 282.4118, train_loss: 133.56579590, val_loss: 83.29273224\n",
      "Epoch: [18] [ 260/ 548] time: 282.6783, train_loss: 98.17344666, val_loss: 87.88397217\n",
      "Epoch: [18] [ 270/ 548] time: 282.9415, train_loss: 16.38098907, val_loss: 83.51992798\n",
      "Epoch: [18] [ 280/ 548] time: 283.2004, train_loss: 94.76763916, val_loss: 77.47221375\n",
      "Epoch: [18] [ 290/ 548] time: 283.4608, train_loss: 102.42170715, val_loss: 78.63626099\n",
      "Epoch: [18] [ 300/ 548] time: 283.7484, train_loss: 26.40967941, val_loss: 80.04866028\n",
      "Epoch: [18] [ 310/ 548] time: 284.0231, train_loss: 10.54067993, val_loss: 82.13555908\n",
      "Epoch: [18] [ 320/ 548] time: 284.2771, train_loss: 112.38127136, val_loss: 78.34429932\n",
      "Epoch: [18] [ 330/ 548] time: 284.5285, train_loss: 55.31291199, val_loss: 80.94963074\n",
      "Epoch: [18] [ 340/ 548] time: 284.8009, train_loss: 44.80183792, val_loss: 88.47009277\n",
      "Epoch: [18] [ 350/ 548] time: 285.0665, train_loss: 65.80673981, val_loss: 90.00722504\n",
      "Epoch: [18] [ 360/ 548] time: 285.3562, train_loss: 180.57858276, val_loss: 97.36724854\n",
      "Epoch: [18] [ 370/ 548] time: 285.6709, train_loss: 241.13137817, val_loss: 87.04610443\n",
      "Epoch: [18] [ 380/ 548] time: 286.0596, train_loss: 55.30254364, val_loss: 82.06429291\n",
      "Epoch: [18] [ 390/ 548] time: 286.4334, train_loss: 160.61886597, val_loss: 78.44741058\n",
      "Epoch: [18] [ 400/ 548] time: 286.7774, train_loss: 283.74700928, val_loss: 75.61300659\n",
      "Epoch: [18] [ 410/ 548] time: 287.1108, train_loss: 16.22687149, val_loss: 76.05416107\n",
      "Epoch: [18] [ 420/ 548] time: 287.5073, train_loss: 76.48667908, val_loss: 87.77752686\n",
      "Epoch: [18] [ 430/ 548] time: 287.8085, train_loss: 21.92494202, val_loss: 72.63419342\n",
      "Epoch: [18] [ 440/ 548] time: 288.0730, train_loss: 23.53551483, val_loss: 78.97683716\n",
      "Epoch: [18] [ 450/ 548] time: 288.3177, train_loss: 113.10874939, val_loss: 71.55014801\n",
      "Epoch: [18] [ 460/ 548] time: 288.5660, train_loss: 31.94555664, val_loss: 69.67226410\n",
      "Epoch: [18] [ 470/ 548] time: 288.8047, train_loss: 54.66262436, val_loss: 71.86441040\n",
      "Epoch: [18] [ 480/ 548] time: 289.0433, train_loss: 118.68145752, val_loss: 73.96406555\n",
      "Epoch: [18] [ 490/ 548] time: 289.2804, train_loss: 239.98573303, val_loss: 73.06207275\n",
      "Epoch: [18] [ 500/ 548] time: 289.5202, train_loss: 72.57157135, val_loss: 73.88362122\n",
      "Epoch: [18] [ 510/ 548] time: 289.7551, train_loss: 15.17873001, val_loss: 69.17321777\n",
      "Epoch: [18] [ 520/ 548] time: 289.9941, train_loss: 100.90249634, val_loss: 70.14561462\n",
      "Epoch: [18] [ 530/ 548] time: 290.2274, train_loss: 11.05213165, val_loss: 66.58657837\n",
      "Epoch: [18] [ 540/ 548] time: 290.4619, train_loss: 28.24707413, val_loss: 66.36218262\n",
      "Epoch: [19] [   0/ 548] time: 290.6527, train_loss: 18.90675735, val_loss: 65.68948364\n",
      "Epoch: [19] [  10/ 548] time: 290.9151, train_loss: 36.95757294, val_loss: 77.00033569\n",
      "Epoch: [19] [  20/ 548] time: 291.1586, train_loss: 129.36734009, val_loss: 93.87340546\n",
      "Epoch: [19] [  30/ 548] time: 291.3915, train_loss: 2.92962265, val_loss: 79.97317505\n",
      "Epoch: [19] [  40/ 548] time: 291.6279, train_loss: 16.43875122, val_loss: 73.06808472\n",
      "Epoch: [19] [  50/ 548] time: 291.8974, train_loss: 87.95689392, val_loss: 81.66896057\n",
      "Epoch: [19] [  60/ 548] time: 292.2041, train_loss: 43.12807846, val_loss: 67.32278442\n",
      "Epoch: [19] [  70/ 548] time: 292.4911, train_loss: 95.76274109, val_loss: 63.71222687\n",
      "Epoch: [19] [  80/ 548] time: 292.7631, train_loss: 68.53249359, val_loss: 65.52160645\n",
      "Epoch: [19] [  90/ 548] time: 293.0393, train_loss: 106.39434052, val_loss: 74.27833557\n",
      "Epoch: [19] [ 100/ 548] time: 293.3199, train_loss: 133.74455261, val_loss: 73.06576538\n",
      "Epoch: [19] [ 110/ 548] time: 293.6050, train_loss: 187.84649658, val_loss: 68.38967133\n",
      "Epoch: [19] [ 120/ 548] time: 293.9032, train_loss: 49.19756317, val_loss: 69.01657867\n",
      "Epoch: [19] [ 130/ 548] time: 294.1598, train_loss: 42.13188934, val_loss: 78.25142670\n",
      "Epoch: [19] [ 140/ 548] time: 294.4147, train_loss: 51.28653717, val_loss: 80.99577332\n",
      "Epoch: [19] [ 150/ 548] time: 294.6575, train_loss: 66.07399750, val_loss: 74.69886017\n",
      "Epoch: [19] [ 160/ 548] time: 294.8967, train_loss: 22.30691910, val_loss: 73.55033875\n",
      "Epoch: [19] [ 170/ 548] time: 295.1391, train_loss: 375.59100342, val_loss: 69.93334961\n",
      "Epoch: [19] [ 180/ 548] time: 295.3940, train_loss: 287.00927734, val_loss: 67.27713013\n",
      "Epoch: [19] [ 190/ 548] time: 295.6493, train_loss: 25.11511993, val_loss: 70.59807587\n",
      "Epoch: [19] [ 200/ 548] time: 295.8947, train_loss: 75.69374847, val_loss: 70.76309967\n",
      "Epoch: [19] [ 210/ 548] time: 296.1317, train_loss: 51.94452667, val_loss: 63.69534302\n",
      "Epoch: [19] [ 220/ 548] time: 296.3846, train_loss: 43.51991272, val_loss: 69.49563599\n",
      "Epoch: [19] [ 230/ 548] time: 296.6328, train_loss: 71.51419067, val_loss: 62.02707291\n",
      "Epoch: [19] [ 240/ 548] time: 296.8730, train_loss: 10.14424133, val_loss: 74.12738037\n",
      "Epoch: [19] [ 250/ 548] time: 297.1100, train_loss: 41.84394836, val_loss: 116.67642212\n",
      "Epoch: [19] [ 260/ 548] time: 297.3478, train_loss: 52.25700378, val_loss: 90.11158752\n",
      "Epoch: [19] [ 270/ 548] time: 297.6159, train_loss: 35.89656067, val_loss: 77.30961609\n",
      "Epoch: [19] [ 280/ 548] time: 297.8662, train_loss: 88.44332886, val_loss: 69.72492981\n",
      "Epoch: [19] [ 290/ 548] time: 298.1055, train_loss: 58.18128967, val_loss: 65.02204132\n",
      "Epoch: [19] [ 300/ 548] time: 298.3466, train_loss: 154.57122803, val_loss: 60.50325775\n",
      "Epoch: [19] [ 310/ 548] time: 298.5855, train_loss: 1.73827744, val_loss: 62.69177246\n",
      "Epoch: [19] [ 320/ 548] time: 298.8281, train_loss: 46.09522247, val_loss: 58.99874115\n",
      "Epoch: [19] [ 330/ 548] time: 299.0913, train_loss: 26.31459808, val_loss: 55.81183243\n",
      "Epoch: [19] [ 340/ 548] time: 299.3570, train_loss: 48.05344009, val_loss: 55.55230713\n",
      "Epoch: [19] [ 350/ 548] time: 299.6272, train_loss: 58.87646103, val_loss: 61.40588760\n",
      "Epoch: [19] [ 360/ 548] time: 299.8995, train_loss: 138.55593872, val_loss: 57.57502747\n",
      "Epoch: [19] [ 370/ 548] time: 300.1472, train_loss: 19.05258179, val_loss: 63.63436890\n",
      "Epoch: [19] [ 380/ 548] time: 300.3924, train_loss: 134.34625244, val_loss: 80.91537476\n",
      "Epoch: [19] [ 390/ 548] time: 300.6350, train_loss: 210.44436646, val_loss: 70.68931580\n",
      "Epoch: [19] [ 400/ 548] time: 300.8831, train_loss: 44.53441238, val_loss: 65.06790924\n",
      "Epoch: [19] [ 410/ 548] time: 301.1272, train_loss: 8.70470047, val_loss: 65.59742737\n",
      "Epoch: [19] [ 420/ 548] time: 301.3672, train_loss: 136.13758850, val_loss: 62.23954010\n",
      "Epoch: [19] [ 430/ 548] time: 301.6376, train_loss: 49.56092072, val_loss: 54.38909912\n",
      "Epoch: [19] [ 440/ 548] time: 301.8972, train_loss: 24.59492493, val_loss: 52.53712082\n",
      "Epoch: [19] [ 450/ 548] time: 302.1467, train_loss: 28.66058350, val_loss: 52.71003723\n",
      "Epoch: [19] [ 460/ 548] time: 302.3987, train_loss: 39.53025436, val_loss: 58.08891296\n",
      "Epoch: [19] [ 470/ 548] time: 302.6466, train_loss: 12.22841644, val_loss: 54.83931732\n",
      "Epoch: [19] [ 480/ 548] time: 302.8904, train_loss: -1.47249985, val_loss: 53.14771652\n",
      "Epoch: [19] [ 490/ 548] time: 303.1284, train_loss: 48.57119751, val_loss: 54.12386703\n",
      "Epoch: [19] [ 500/ 548] time: 303.3666, train_loss: 45.97749329, val_loss: 52.27069092\n",
      "Epoch: [19] [ 510/ 548] time: 303.5991, train_loss: 121.99839783, val_loss: 53.86289597\n",
      "Epoch: [19] [ 520/ 548] time: 303.8526, train_loss: 20.48040771, val_loss: 54.31525040\n",
      "Epoch: [19] [ 530/ 548] time: 304.0943, train_loss: 50.83789062, val_loss: 59.23558044\n",
      "Epoch: [19] [ 540/ 548] time: 304.3327, train_loss: 232.39794922, val_loss: 54.74869537\n",
      "Epoch: [20] [   0/ 548] time: 304.5267, train_loss: 38.22038269, val_loss: 49.75904846\n",
      "Epoch: [20] [  10/ 548] time: 304.7650, train_loss: 138.29356384, val_loss: 48.19599152\n",
      "Epoch: [20] [  20/ 548] time: 305.0243, train_loss: 319.83602905, val_loss: 48.23954773\n",
      "Epoch: [20] [  30/ 548] time: 305.2803, train_loss: 0.95363617, val_loss: 50.89031601\n",
      "Epoch: [20] [  40/ 548] time: 305.5859, train_loss: 60.01319122, val_loss: 50.62425995\n",
      "Saving checkpoint\n",
      "Epoch: [20] [  50/ 548] time: 306.9710, train_loss: 185.83413696, val_loss: 50.61779785\n",
      "Epoch: [20] [  60/ 548] time: 307.2242, train_loss: 53.53572083, val_loss: 52.94832993\n",
      "Epoch: [20] [  70/ 548] time: 307.4656, train_loss: 257.59652710, val_loss: 47.42814636\n",
      "Epoch: [20] [  80/ 548] time: 307.6937, train_loss: 66.51981354, val_loss: 54.38283539\n",
      "Epoch: [20] [  90/ 548] time: 307.9470, train_loss: 4.57324219, val_loss: 58.00992966\n",
      "Epoch: [20] [ 100/ 548] time: 308.1897, train_loss: 94.70829773, val_loss: 52.64965057\n",
      "Epoch: [20] [ 110/ 548] time: 308.4281, train_loss: 305.99307251, val_loss: 52.12384033\n",
      "Epoch: [20] [ 120/ 548] time: 308.6557, train_loss: 135.83518982, val_loss: 54.29626465\n",
      "Epoch: [20] [ 130/ 548] time: 308.8805, train_loss: 25.14500809, val_loss: 64.44430542\n",
      "Epoch: [20] [ 140/ 548] time: 309.1261, train_loss: 71.70101929, val_loss: 69.41281128\n",
      "Epoch: [20] [ 150/ 548] time: 309.3745, train_loss: 76.77162170, val_loss: 66.16889191\n",
      "Epoch: [20] [ 160/ 548] time: 309.6445, train_loss: 33.01884842, val_loss: 62.46989441\n",
      "Epoch: [20] [ 170/ 548] time: 309.9156, train_loss: 63.53345490, val_loss: 56.86874390\n",
      "Epoch: [20] [ 180/ 548] time: 310.1892, train_loss: 62.10538101, val_loss: 53.19598389\n",
      "Epoch: [20] [ 190/ 548] time: 310.4538, train_loss: 296.22601318, val_loss: 47.72860336\n",
      "Epoch: [20] [ 200/ 548] time: 310.7104, train_loss: 41.57886505, val_loss: 45.64727402\n",
      "Epoch: [20] [ 210/ 548] time: 310.9767, train_loss: 106.53785706, val_loss: 46.09860992\n",
      "Epoch: [20] [ 220/ 548] time: 311.2541, train_loss: 200.96876526, val_loss: 46.50197601\n",
      "Epoch: [20] [ 230/ 548] time: 311.5584, train_loss: 526.07324219, val_loss: 49.13562012\n",
      "Epoch: [20] [ 240/ 548] time: 311.8679, train_loss: 22.09448624, val_loss: 57.01545715\n",
      "Epoch: [20] [ 250/ 548] time: 312.1569, train_loss: 41.03401184, val_loss: 52.07685852\n",
      "Epoch: [20] [ 260/ 548] time: 312.4410, train_loss: 101.07612610, val_loss: 52.66031647\n",
      "Epoch: [20] [ 270/ 548] time: 312.7265, train_loss: 256.43835449, val_loss: 51.40646362\n",
      "Epoch: [20] [ 280/ 548] time: 313.0053, train_loss: 27.13393402, val_loss: 55.54876709\n",
      "Epoch: [20] [ 290/ 548] time: 313.2862, train_loss: -4.50302505, val_loss: 57.30390930\n",
      "Epoch: [20] [ 300/ 548] time: 313.5676, train_loss: 42.18585968, val_loss: 56.01477814\n",
      "Epoch: [20] [ 310/ 548] time: 313.8384, train_loss: 60.96907043, val_loss: 52.55538940\n",
      "Epoch: [20] [ 320/ 548] time: 314.1212, train_loss: 49.59248734, val_loss: 51.36210632\n",
      "Epoch: [20] [ 330/ 548] time: 314.3899, train_loss: 36.00835419, val_loss: 47.15862274\n",
      "Epoch: [20] [ 340/ 548] time: 314.6309, train_loss: 74.33810425, val_loss: 47.03305054\n",
      "Epoch: [20] [ 350/ 548] time: 314.8906, train_loss: 162.78456116, val_loss: 50.36566925\n",
      "Epoch: [20] [ 360/ 548] time: 315.1504, train_loss: 23.80924225, val_loss: 51.96826172\n",
      "Epoch: [20] [ 370/ 548] time: 315.3976, train_loss: 27.18651199, val_loss: 50.79311371\n",
      "Epoch: [20] [ 380/ 548] time: 315.6506, train_loss: 38.30548096, val_loss: 52.65747070\n",
      "Epoch: [20] [ 390/ 548] time: 315.9151, train_loss: 74.17192078, val_loss: 50.25125885\n",
      "Epoch: [20] [ 400/ 548] time: 316.1592, train_loss: 64.88167572, val_loss: 42.37826538\n",
      "Epoch: [20] [ 410/ 548] time: 316.4135, train_loss: 17.46281052, val_loss: 48.49953079\n",
      "Epoch: [20] [ 420/ 548] time: 316.6719, train_loss: 113.14041138, val_loss: 43.50930023\n",
      "Epoch: [20] [ 430/ 548] time: 316.9383, train_loss: 12.40814972, val_loss: 43.33395386\n",
      "Epoch: [20] [ 440/ 548] time: 317.2096, train_loss: 47.69766998, val_loss: 42.11050797\n",
      "Epoch: [20] [ 450/ 548] time: 317.4859, train_loss: 9.33085251, val_loss: 44.31678009\n",
      "Epoch: [20] [ 460/ 548] time: 317.7635, train_loss: 483.42169189, val_loss: 46.02738190\n",
      "Epoch: [20] [ 470/ 548] time: 318.0466, train_loss: 30.97836304, val_loss: 41.86573792\n",
      "Epoch: [20] [ 480/ 548] time: 318.2953, train_loss: 36.68492126, val_loss: 45.71876526\n",
      "Epoch: [20] [ 490/ 548] time: 318.5407, train_loss: 31.15723801, val_loss: 46.84464645\n",
      "Epoch: [20] [ 500/ 548] time: 318.7922, train_loss: 510.11013794, val_loss: 41.12373352\n",
      "Epoch: [20] [ 510/ 548] time: 319.0598, train_loss: 55.98053360, val_loss: 39.49759674\n",
      "Epoch: [20] [ 520/ 548] time: 319.3371, train_loss: 40.67544174, val_loss: 39.23735428\n",
      "Epoch: [20] [ 530/ 548] time: 319.6016, train_loss: 42.28659821, val_loss: 37.82864380\n",
      "Epoch: [20] [ 540/ 548] time: 319.8811, train_loss: -12.39361572, val_loss: 36.62440872\n",
      "Epoch: [21] [   0/ 548] time: 320.1004, train_loss: 17.07723999, val_loss: 36.16576385\n",
      "Epoch: [21] [  10/ 548] time: 320.3837, train_loss: 345.86499023, val_loss: 34.19231796\n",
      "Epoch: [21] [  20/ 548] time: 320.6853, train_loss: 34.93991089, val_loss: 38.20660400\n",
      "Epoch: [21] [  30/ 548] time: 320.9609, train_loss: 1182.24023438, val_loss: 47.39448547\n",
      "Epoch: [21] [  40/ 548] time: 321.2488, train_loss: 72.62375641, val_loss: 47.95724106\n",
      "Epoch: [21] [  50/ 548] time: 321.5354, train_loss: 2.83642197, val_loss: 50.30580139\n",
      "Epoch: [21] [  60/ 548] time: 321.8229, train_loss: 93.47668457, val_loss: 48.89028931\n",
      "Epoch: [21] [  70/ 548] time: 322.1057, train_loss: 75.39283752, val_loss: 37.18329239\n",
      "Epoch: [21] [  80/ 548] time: 322.3867, train_loss: 26.94110107, val_loss: 40.85537720\n",
      "Epoch: [21] [  90/ 548] time: 322.6684, train_loss: 2.32261658, val_loss: 45.04220581\n",
      "Epoch: [21] [ 100/ 548] time: 322.9505, train_loss: 37.01233673, val_loss: 37.90618134\n",
      "Epoch: [21] [ 110/ 548] time: 323.2949, train_loss: 66.24896240, val_loss: 60.33692551\n",
      "Epoch: [21] [ 120/ 548] time: 323.6260, train_loss: 147.76934814, val_loss: 69.72069550\n",
      "Epoch: [21] [ 130/ 548] time: 323.9470, train_loss: 5.31098557, val_loss: 49.77538681\n",
      "Epoch: [21] [ 140/ 548] time: 324.2591, train_loss: 80.01589966, val_loss: 36.97259903\n",
      "Epoch: [21] [ 150/ 548] time: 324.5977, train_loss: 25.85968018, val_loss: 38.26512146\n",
      "Epoch: [21] [ 160/ 548] time: 324.8990, train_loss: 65.59221649, val_loss: 34.91226959\n",
      "Epoch: [21] [ 170/ 548] time: 325.1961, train_loss: 9.06645966, val_loss: 33.68958282\n",
      "Epoch: [21] [ 180/ 548] time: 325.4878, train_loss: 71.14749146, val_loss: 30.19277191\n",
      "Epoch: [21] [ 190/ 548] time: 325.7794, train_loss: -5.31977463, val_loss: 35.00816727\n",
      "Epoch: [21] [ 200/ 548] time: 326.0617, train_loss: -19.51576614, val_loss: 35.81272125\n",
      "Epoch: [21] [ 210/ 548] time: 326.3496, train_loss: 40.03236389, val_loss: 38.55828094\n",
      "Epoch: [21] [ 220/ 548] time: 326.6093, train_loss: 37.36838913, val_loss: 39.29928589\n",
      "Epoch: [21] [ 230/ 548] time: 326.8993, train_loss: -9.24297333, val_loss: 34.00148010\n",
      "Epoch: [21] [ 240/ 548] time: 327.1575, train_loss: 61.80778122, val_loss: 31.06302643\n",
      "Epoch: [21] [ 250/ 548] time: 327.4214, train_loss: 347.20870972, val_loss: 33.75171661\n",
      "Epoch: [21] [ 260/ 548] time: 327.6838, train_loss: 10.35907745, val_loss: 30.55110931\n",
      "Epoch: [21] [ 270/ 548] time: 327.9366, train_loss: 80.09332275, val_loss: 36.43008804\n",
      "Epoch: [21] [ 280/ 548] time: 328.1924, train_loss: 189.16647339, val_loss: 30.89645386\n",
      "Epoch: [21] [ 290/ 548] time: 328.4731, train_loss: 96.51228333, val_loss: 30.13051605\n",
      "Epoch: [21] [ 300/ 548] time: 328.7256, train_loss: 24.58409119, val_loss: 31.49451447\n",
      "Epoch: [21] [ 310/ 548] time: 328.9938, train_loss: 170.71719360, val_loss: 30.74971390\n",
      "Epoch: [21] [ 320/ 548] time: 329.2768, train_loss: 44.87921524, val_loss: 25.84164429\n",
      "Epoch: [21] [ 330/ 548] time: 329.5491, train_loss: 19.51461792, val_loss: 31.18270493\n",
      "Epoch: [21] [ 340/ 548] time: 329.8494, train_loss: -0.62069702, val_loss: 27.74961090\n",
      "Epoch: [21] [ 350/ 548] time: 330.1701, train_loss: 5.08985519, val_loss: 26.86155701\n",
      "Epoch: [21] [ 360/ 548] time: 330.4842, train_loss: 21.88522339, val_loss: 28.10454941\n",
      "Epoch: [21] [ 370/ 548] time: 330.7856, train_loss: 49.32571793, val_loss: 28.58959198\n",
      "Epoch: [21] [ 380/ 548] time: 331.0726, train_loss: 27.02929688, val_loss: 38.31157684\n",
      "Epoch: [21] [ 390/ 548] time: 331.3831, train_loss: 18.90985489, val_loss: 36.19333649\n",
      "Epoch: [21] [ 400/ 548] time: 331.7022, train_loss: 13.15617752, val_loss: 34.67338562\n",
      "Epoch: [21] [ 410/ 548] time: 332.0090, train_loss: 4.54278946, val_loss: 29.76028824\n",
      "Epoch: [21] [ 420/ 548] time: 332.3105, train_loss: 10.67446518, val_loss: 26.28445435\n",
      "Epoch: [21] [ 430/ 548] time: 332.6035, train_loss: 25.19925308, val_loss: 26.64225006\n",
      "Epoch: [21] [ 440/ 548] time: 332.8901, train_loss: -23.84578323, val_loss: 24.85985565\n",
      "Epoch: [21] [ 450/ 548] time: 333.1806, train_loss: 57.97179794, val_loss: 31.02261353\n",
      "Epoch: [21] [ 460/ 548] time: 333.4612, train_loss: 43.56528473, val_loss: 28.57135010\n",
      "Epoch: [21] [ 470/ 548] time: 333.7315, train_loss: 122.03642273, val_loss: 40.38368988\n",
      "Epoch: [21] [ 480/ 548] time: 334.0080, train_loss: 10.78992081, val_loss: 38.27675247\n",
      "Epoch: [21] [ 490/ 548] time: 334.2742, train_loss: 28.87348938, val_loss: 35.37284088\n",
      "Saving checkpoint\n",
      "Epoch: [21] [ 500/ 548] time: 335.6565, train_loss: 21.24841309, val_loss: 39.72324371\n",
      "Epoch: [21] [ 510/ 548] time: 335.9241, train_loss: 72.24659729, val_loss: 42.75452423\n",
      "Epoch: [21] [ 520/ 548] time: 336.2197, train_loss: -7.31008148, val_loss: 36.43607330\n",
      "Epoch: [21] [ 530/ 548] time: 336.4918, train_loss: 107.03819275, val_loss: 37.16760254\n",
      "Epoch: [21] [ 540/ 548] time: 336.7756, train_loss: 197.17636108, val_loss: 42.91851044\n",
      "Epoch: [22] [   0/ 548] time: 336.9945, train_loss: 1.34325409, val_loss: 37.70243454\n",
      "Epoch: [22] [  10/ 548] time: 337.2543, train_loss: 59.58607483, val_loss: 28.69500732\n",
      "Epoch: [22] [  20/ 548] time: 337.5050, train_loss: 13.53388596, val_loss: 30.75473022\n",
      "Epoch: [22] [  30/ 548] time: 337.7608, train_loss: -3.68865967, val_loss: 24.86130905\n",
      "Epoch: [22] [  40/ 548] time: 338.0262, train_loss: 28.31114960, val_loss: 25.31815338\n",
      "Epoch: [22] [  50/ 548] time: 338.2844, train_loss: -9.30603409, val_loss: 29.31146240\n",
      "Epoch: [22] [  60/ 548] time: 338.5477, train_loss: 27.74423218, val_loss: 23.31005859\n",
      "Epoch: [22] [  70/ 548] time: 338.7956, train_loss: 41.25706482, val_loss: 27.64824295\n",
      "Epoch: [22] [  80/ 548] time: 339.0461, train_loss: 100.53131104, val_loss: 29.01198578\n",
      "Epoch: [22] [  90/ 548] time: 339.2982, train_loss: 62.46894836, val_loss: 28.99192429\n",
      "Epoch: [22] [ 100/ 548] time: 339.5329, train_loss: -9.38619232, val_loss: 26.57303619\n",
      "Epoch: [22] [ 110/ 548] time: 339.7647, train_loss: 26.70786285, val_loss: 32.83623123\n",
      "Epoch: [22] [ 120/ 548] time: 340.0002, train_loss: 57.52375793, val_loss: 26.81726074\n",
      "Epoch: [22] [ 130/ 548] time: 340.2327, train_loss: 85.83522034, val_loss: 26.22856522\n",
      "Epoch: [22] [ 140/ 548] time: 340.4813, train_loss: 45.17116928, val_loss: 24.93295288\n",
      "Epoch: [22] [ 150/ 548] time: 340.7361, train_loss: 153.03634644, val_loss: 25.36817932\n",
      "Epoch: [22] [ 160/ 548] time: 340.9980, train_loss: 363.29028320, val_loss: 34.32630539\n",
      "Epoch: [22] [ 170/ 548] time: 341.2744, train_loss: -16.74441528, val_loss: 25.07809448\n",
      "Epoch: [22] [ 180/ 548] time: 341.5339, train_loss: 9.50767136, val_loss: 21.74131012\n",
      "Epoch: [22] [ 190/ 548] time: 341.7781, train_loss: 57.07012939, val_loss: 20.89916229\n",
      "Epoch: [22] [ 200/ 548] time: 342.0514, train_loss: 18.64648438, val_loss: 23.36842346\n",
      "Epoch: [22] [ 210/ 548] time: 342.3180, train_loss: 47.40534973, val_loss: 23.18360901\n",
      "Epoch: [22] [ 220/ 548] time: 342.5910, train_loss: 94.07733154, val_loss: 22.55201721\n",
      "Epoch: [22] [ 230/ 548] time: 342.8626, train_loss: 99.05421448, val_loss: 22.90947723\n",
      "Epoch: [22] [ 240/ 548] time: 343.1078, train_loss: 34.97615433, val_loss: 25.02623749\n",
      "Epoch: [22] [ 250/ 548] time: 343.3442, train_loss: -0.73178864, val_loss: 26.67452621\n",
      "Epoch: [22] [ 260/ 548] time: 343.5827, train_loss: 9.14106369, val_loss: 26.66697311\n",
      "Epoch: [22] [ 270/ 548] time: 343.8185, train_loss: 93.47384644, val_loss: 23.90737152\n",
      "Epoch: [22] [ 280/ 548] time: 344.0576, train_loss: 55.45056534, val_loss: 22.00995636\n",
      "Epoch: [22] [ 290/ 548] time: 344.2987, train_loss: 15.66583633, val_loss: 28.12833405\n",
      "Epoch: [22] [ 300/ 548] time: 344.5397, train_loss: 30.79033279, val_loss: 29.29912949\n",
      "Epoch: [22] [ 310/ 548] time: 344.8005, train_loss: 66.62551117, val_loss: 26.32872009\n",
      "Epoch: [22] [ 320/ 548] time: 345.0751, train_loss: -5.54066849, val_loss: 20.94099808\n",
      "Epoch: [22] [ 330/ 548] time: 345.3314, train_loss: 46.08217621, val_loss: 19.96588898\n",
      "Epoch: [22] [ 340/ 548] time: 345.5940, train_loss: 6.54602051, val_loss: 17.53438568\n",
      "Epoch: [22] [ 350/ 548] time: 345.8616, train_loss: 164.98997498, val_loss: 17.73741913\n",
      "Epoch: [22] [ 360/ 548] time: 346.1346, train_loss: -8.73619461, val_loss: 17.01466370\n",
      "Epoch: [22] [ 370/ 548] time: 346.4278, train_loss: 30.68788147, val_loss: 19.65377045\n",
      "Epoch: [22] [ 380/ 548] time: 346.7339, train_loss: 21.28436279, val_loss: 16.68236160\n",
      "Epoch: [22] [ 390/ 548] time: 347.0130, train_loss: 52.30315018, val_loss: 40.28505325\n",
      "Epoch: [22] [ 400/ 548] time: 347.2995, train_loss: 7.82071304, val_loss: 48.54582214\n",
      "Epoch: [22] [ 410/ 548] time: 347.6118, train_loss: -10.34397125, val_loss: 38.59062195\n",
      "Epoch: [22] [ 420/ 548] time: 347.9043, train_loss: 103.73037720, val_loss: 26.80052185\n",
      "Epoch: [22] [ 430/ 548] time: 348.2181, train_loss: 12.75544357, val_loss: 22.80875397\n",
      "Epoch: [22] [ 440/ 548] time: 348.5372, train_loss: 2.70366669, val_loss: 17.79480743\n",
      "Epoch: [22] [ 450/ 548] time: 348.9296, train_loss: -9.29307175, val_loss: 14.83584213\n",
      "Epoch: [22] [ 460/ 548] time: 349.2922, train_loss: -14.59949493, val_loss: 23.09179688\n",
      "Epoch: [22] [ 470/ 548] time: 349.5910, train_loss: 9.96643448, val_loss: 28.87989426\n",
      "Epoch: [22] [ 480/ 548] time: 349.8856, train_loss: 2.54441452, val_loss: 22.23171234\n",
      "Epoch: [22] [ 490/ 548] time: 350.2057, train_loss: 153.64996338, val_loss: 28.44888306\n",
      "Epoch: [22] [ 500/ 548] time: 350.4895, train_loss: 87.46754456, val_loss: 34.26308823\n",
      "Epoch: [22] [ 510/ 548] time: 350.7708, train_loss: 634.92901611, val_loss: 44.96606064\n",
      "Epoch: [22] [ 520/ 548] time: 351.0491, train_loss: 22.60317230, val_loss: 43.22591400\n",
      "Epoch: [22] [ 530/ 548] time: 351.3219, train_loss: 385.37860107, val_loss: 28.59743118\n",
      "Epoch: [22] [ 540/ 548] time: 351.6019, train_loss: 139.32583618, val_loss: 24.64373016\n",
      "Epoch: [23] [   0/ 548] time: 351.8361, train_loss: 31.18697739, val_loss: 24.52023315\n",
      "Epoch: [23] [  10/ 548] time: 352.1424, train_loss: 238.91705322, val_loss: 21.80360031\n",
      "Epoch: [23] [  20/ 548] time: 352.4114, train_loss: 14.05555344, val_loss: 20.31376648\n",
      "Epoch: [23] [  30/ 548] time: 352.6769, train_loss: 4.69024658, val_loss: 23.47102737\n",
      "Epoch: [23] [  40/ 548] time: 352.9460, train_loss: 38.32003403, val_loss: 20.23164749\n",
      "Epoch: [23] [  50/ 548] time: 353.2130, train_loss: 23.81464386, val_loss: 38.16262054\n",
      "Epoch: [23] [  60/ 548] time: 353.4891, train_loss: 12.67129517, val_loss: 37.85825348\n",
      "Epoch: [23] [  70/ 548] time: 353.7581, train_loss: 16.40285110, val_loss: 27.69094849\n",
      "Epoch: [23] [  80/ 548] time: 354.0241, train_loss: -2.19964981, val_loss: 21.90280914\n",
      "Epoch: [23] [  90/ 548] time: 354.2948, train_loss: -19.27987671, val_loss: 19.50979614\n",
      "Epoch: [23] [ 100/ 548] time: 354.5964, train_loss: -4.25237274, val_loss: 15.77089310\n",
      "Epoch: [23] [ 110/ 548] time: 354.8920, train_loss: 80.74523926, val_loss: 15.72695541\n",
      "Epoch: [23] [ 120/ 548] time: 355.1845, train_loss: 18.59492493, val_loss: 13.96154785\n",
      "Epoch: [23] [ 130/ 548] time: 355.4871, train_loss: 224.77584839, val_loss: 16.07863617\n",
      "Epoch: [23] [ 140/ 548] time: 355.7749, train_loss: 28.80014038, val_loss: 14.91265106\n",
      "Epoch: [23] [ 150/ 548] time: 356.0594, train_loss: 4.04724503, val_loss: 18.26050568\n",
      "Epoch: [23] [ 160/ 548] time: 356.3690, train_loss: 3.13563919, val_loss: 15.63243103\n",
      "Epoch: [23] [ 170/ 548] time: 356.6512, train_loss: 44.48728561, val_loss: 19.53051758\n",
      "Epoch: [23] [ 180/ 548] time: 356.9179, train_loss: -6.00164795, val_loss: 24.38131332\n",
      "Epoch: [23] [ 190/ 548] time: 357.1916, train_loss: 25.07268906, val_loss: 23.67470551\n",
      "Epoch: [23] [ 200/ 548] time: 357.4593, train_loss: 656.41888428, val_loss: 19.51896667\n",
      "Epoch: [23] [ 210/ 548] time: 357.7212, train_loss: 21.36178589, val_loss: 24.74876404\n",
      "Epoch: [23] [ 220/ 548] time: 357.9949, train_loss: -16.51726913, val_loss: 22.12790680\n",
      "Epoch: [23] [ 230/ 548] time: 358.2548, train_loss: 17.15570831, val_loss: 19.58426666\n",
      "Epoch: [23] [ 240/ 548] time: 358.5222, train_loss: 22.49736404, val_loss: 17.01014709\n",
      "Epoch: [23] [ 250/ 548] time: 358.7784, train_loss: -19.24058533, val_loss: 15.00080490\n",
      "Epoch: [23] [ 260/ 548] time: 359.0351, train_loss: 14.91528702, val_loss: 16.36036301\n",
      "Epoch: [23] [ 270/ 548] time: 359.2879, train_loss: 34.52665710, val_loss: 17.04280472\n",
      "Epoch: [23] [ 280/ 548] time: 359.5368, train_loss: 64.05404663, val_loss: 13.81375885\n",
      "Epoch: [23] [ 290/ 548] time: 359.7829, train_loss: 59.81105423, val_loss: 19.34824371\n",
      "Epoch: [23] [ 300/ 548] time: 360.0276, train_loss: 64.74562073, val_loss: 15.90760803\n",
      "Epoch: [23] [ 310/ 548] time: 360.2784, train_loss: 115.16855621, val_loss: 9.83348465\n",
      "Epoch: [23] [ 320/ 548] time: 360.5227, train_loss: 59.97322464, val_loss: 10.58764648\n",
      "Epoch: [23] [ 330/ 548] time: 360.7727, train_loss: 10.04823303, val_loss: 15.25178528\n",
      "Epoch: [23] [ 340/ 548] time: 361.0356, train_loss: 15.34821320, val_loss: 11.94882584\n",
      "Epoch: [23] [ 350/ 548] time: 361.2994, train_loss: 3.57743073, val_loss: 10.89694214\n",
      "Epoch: [23] [ 360/ 548] time: 361.5704, train_loss: -15.56922150, val_loss: 11.58995819\n",
      "Epoch: [23] [ 370/ 548] time: 361.8306, train_loss: 11.23452377, val_loss: 10.35769272\n",
      "Epoch: [23] [ 380/ 548] time: 362.0726, train_loss: 138.47010803, val_loss: 17.58145905\n",
      "Epoch: [23] [ 390/ 548] time: 362.3384, train_loss: 3.06249619, val_loss: 16.58112717\n",
      "Saving checkpoint\n",
      "Epoch: [23] [ 400/ 548] time: 363.6843, train_loss: -10.38849640, val_loss: 11.14668274\n",
      "Epoch: [23] [ 410/ 548] time: 363.9517, train_loss: -5.57507706, val_loss: 8.27900696\n",
      "Epoch: [23] [ 420/ 548] time: 364.2229, train_loss: -1.26782608, val_loss: 8.53851318\n",
      "Epoch: [23] [ 430/ 548] time: 364.4763, train_loss: -6.91315842, val_loss: 10.16367340\n",
      "Epoch: [23] [ 440/ 548] time: 364.7274, train_loss: 28.31697083, val_loss: 8.55112457\n",
      "Epoch: [23] [ 450/ 548] time: 364.9745, train_loss: -2.06785202, val_loss: 8.98570251\n",
      "Epoch: [23] [ 460/ 548] time: 365.2161, train_loss: 26.72670746, val_loss: 9.25683975\n",
      "Epoch: [23] [ 470/ 548] time: 365.4904, train_loss: -24.00764656, val_loss: 8.10812759\n",
      "Epoch: [23] [ 480/ 548] time: 365.7294, train_loss: -3.84752655, val_loss: 9.15602112\n",
      "Epoch: [23] [ 490/ 548] time: 365.9647, train_loss: 30.92069244, val_loss: 11.76005173\n",
      "Epoch: [23] [ 500/ 548] time: 366.2027, train_loss: 4.81330490, val_loss: 5.11587906\n",
      "Epoch: [23] [ 510/ 548] time: 366.4363, train_loss: 10.54574966, val_loss: 5.61650467\n",
      "Epoch: [23] [ 520/ 548] time: 366.6816, train_loss: -14.49560165, val_loss: 9.30934143\n",
      "Epoch: [23] [ 530/ 548] time: 366.9344, train_loss: -24.61405563, val_loss: 6.97387314\n",
      "Epoch: [23] [ 540/ 548] time: 367.2043, train_loss: 197.27081299, val_loss: 7.05645752\n",
      "Epoch: [24] [   0/ 548] time: 367.4147, train_loss: 26.51847076, val_loss: 6.36237717\n",
      "Epoch: [24] [  10/ 548] time: 367.6726, train_loss: 16.41644669, val_loss: 4.49613190\n",
      "Epoch: [24] [  20/ 548] time: 367.9204, train_loss: 1.20347977, val_loss: 2.95172119\n",
      "Epoch: [24] [  30/ 548] time: 368.1598, train_loss: 40.94651794, val_loss: 3.57314301\n",
      "Epoch: [24] [  40/ 548] time: 368.4156, train_loss: -16.74127579, val_loss: 7.31770706\n",
      "Epoch: [24] [  50/ 548] time: 368.6963, train_loss: -2.82953262, val_loss: 10.06333542\n",
      "Epoch: [24] [  60/ 548] time: 368.9471, train_loss: -12.63687897, val_loss: 6.42338943\n",
      "Epoch: [24] [  70/ 548] time: 369.2112, train_loss: 51.79126358, val_loss: 5.12537384\n",
      "Epoch: [24] [  80/ 548] time: 369.4670, train_loss: 83.52847290, val_loss: 5.51983643\n",
      "Epoch: [24] [  90/ 548] time: 369.7125, train_loss: -7.96169281, val_loss: 6.28695679\n",
      "Epoch: [24] [ 100/ 548] time: 369.9632, train_loss: 46.53182983, val_loss: 9.37354660\n",
      "Epoch: [24] [ 110/ 548] time: 370.2090, train_loss: -5.38570023, val_loss: 6.97620010\n",
      "Epoch: [24] [ 120/ 548] time: 370.4427, train_loss: 24.74497986, val_loss: 8.08615494\n",
      "Epoch: [24] [ 130/ 548] time: 370.6839, train_loss: 71.71377563, val_loss: 6.92244339\n",
      "Epoch: [24] [ 140/ 548] time: 370.9233, train_loss: 1.43202972, val_loss: 6.40939331\n",
      "Epoch: [24] [ 150/ 548] time: 371.1606, train_loss: 12.62356186, val_loss: 5.02754211\n",
      "Epoch: [24] [ 160/ 548] time: 371.3986, train_loss: -9.28985596, val_loss: 20.76874924\n",
      "Epoch: [24] [ 170/ 548] time: 371.6399, train_loss: 9.92199707, val_loss: 17.69332123\n",
      "Epoch: [24] [ 180/ 548] time: 371.8778, train_loss: -5.22878647, val_loss: 8.90043640\n",
      "Epoch: [24] [ 190/ 548] time: 372.1150, train_loss: -24.64050484, val_loss: 11.09356689\n",
      "Epoch: [24] [ 200/ 548] time: 372.3522, train_loss: -1.92684937, val_loss: 9.98680115\n",
      "Epoch: [24] [ 210/ 548] time: 372.5884, train_loss: -15.34916687, val_loss: 10.87432098\n",
      "Epoch: [24] [ 220/ 548] time: 372.8473, train_loss: 319.20785522, val_loss: 7.07396317\n",
      "Epoch: [24] [ 230/ 548] time: 373.1147, train_loss: 24.66247940, val_loss: 7.02534103\n",
      "Epoch: [24] [ 240/ 548] time: 373.3893, train_loss: 37.50951767, val_loss: 8.21490097\n",
      "Epoch: [24] [ 250/ 548] time: 373.6642, train_loss: 296.82186890, val_loss: 11.83509064\n",
      "Epoch: [24] [ 260/ 548] time: 373.9137, train_loss: 17.74425507, val_loss: 10.91334152\n",
      "Epoch: [24] [ 270/ 548] time: 374.1640, train_loss: 2.68631363, val_loss: 5.65669250\n",
      "Epoch: [24] [ 280/ 548] time: 374.4149, train_loss: 0.64060974, val_loss: 5.39315796\n",
      "Epoch: [24] [ 290/ 548] time: 374.6626, train_loss: -1.83527374, val_loss: 4.84519577\n",
      "Epoch: [24] [ 300/ 548] time: 374.9110, train_loss: 7.83507538, val_loss: 10.12001038\n",
      "Epoch: [24] [ 310/ 548] time: 375.1627, train_loss: 16.76311874, val_loss: 4.64672852\n",
      "Epoch: [24] [ 320/ 548] time: 375.4106, train_loss: 1.51515961, val_loss: 11.04441833\n",
      "Epoch: [24] [ 330/ 548] time: 375.6614, train_loss: 19.15911102, val_loss: 5.93892670\n",
      "Epoch: [24] [ 340/ 548] time: 375.8993, train_loss: 2.94762802, val_loss: -0.75312042\n",
      "Epoch: [24] [ 350/ 548] time: 376.1394, train_loss: -29.27638626, val_loss: 2.14118576\n",
      "Epoch: [24] [ 360/ 548] time: 376.3767, train_loss: -1.27497482, val_loss: 4.08668137\n",
      "Epoch: [24] [ 370/ 548] time: 376.6142, train_loss: -9.27252197, val_loss: 2.73732376\n",
      "Epoch: [24] [ 380/ 548] time: 376.8568, train_loss: 13.75230408, val_loss: 0.78413010\n",
      "Epoch: [24] [ 390/ 548] time: 377.0994, train_loss: 37.41041183, val_loss: 0.68531036\n",
      "Epoch: [24] [ 400/ 548] time: 377.3356, train_loss: 102.28321075, val_loss: 4.02468491\n",
      "Epoch: [24] [ 410/ 548] time: 377.5695, train_loss: 23.97052383, val_loss: 4.14160538\n",
      "Epoch: [24] [ 420/ 548] time: 377.8051, train_loss: 8.85638428, val_loss: 2.28264999\n",
      "Epoch: [24] [ 430/ 548] time: 378.0485, train_loss: 4.82091904, val_loss: 1.04025650\n",
      "Epoch: [24] [ 440/ 548] time: 378.2897, train_loss: -21.88469887, val_loss: 1.90319061\n",
      "Epoch: [24] [ 450/ 548] time: 378.5269, train_loss: -18.53718567, val_loss: -0.28093338\n",
      "Epoch: [24] [ 460/ 548] time: 378.7651, train_loss: -9.78961563, val_loss: 5.23798370\n",
      "Epoch: [24] [ 470/ 548] time: 379.0246, train_loss: 28.10529327, val_loss: 9.29393005\n",
      "Epoch: [24] [ 480/ 548] time: 379.2998, train_loss: -4.62100983, val_loss: 5.38051987\n",
      "Epoch: [24] [ 490/ 548] time: 379.5740, train_loss: 15.63837433, val_loss: 4.53171158\n",
      "Epoch: [24] [ 500/ 548] time: 379.8330, train_loss: 16.14522552, val_loss: 2.96176147\n",
      "Epoch: [24] [ 510/ 548] time: 380.0788, train_loss: -0.99692917, val_loss: 2.92768860\n",
      "Epoch: [24] [ 520/ 548] time: 380.3450, train_loss: 83.84432220, val_loss: 1.18330765\n",
      "Epoch: [24] [ 530/ 548] time: 380.6172, train_loss: 29.01163483, val_loss: -0.55725479\n",
      "Epoch: [24] [ 540/ 548] time: 380.8780, train_loss: -23.35644722, val_loss: -0.83730316\n",
      "Epoch: [25] [   0/ 548] time: 381.0931, train_loss: 117.82099915, val_loss: -0.28868103\n",
      "Epoch: [25] [  10/ 548] time: 381.3827, train_loss: 42.08108521, val_loss: 6.79595947\n",
      "Epoch: [25] [  20/ 548] time: 381.6618, train_loss: 24.08081436, val_loss: 8.72065735\n",
      "Epoch: [25] [  30/ 548] time: 381.9635, train_loss: -1.89770889, val_loss: 8.31056976\n",
      "Epoch: [25] [  40/ 548] time: 382.2536, train_loss: 42.22754669, val_loss: 0.58510208\n",
      "Epoch: [25] [  50/ 548] time: 382.5436, train_loss: -14.32863235, val_loss: -0.21170807\n",
      "Epoch: [25] [  60/ 548] time: 382.8662, train_loss: -18.26032639, val_loss: -1.03773880\n",
      "Epoch: [25] [  70/ 548] time: 383.2135, train_loss: 35.78346252, val_loss: -2.15143585\n",
      "Epoch: [25] [  80/ 548] time: 383.5294, train_loss: -0.74656677, val_loss: -2.01478195\n",
      "Epoch: [25] [  90/ 548] time: 383.8190, train_loss: -16.66139603, val_loss: -0.23485184\n",
      "Epoch: [25] [ 100/ 548] time: 384.1198, train_loss: 501.84426880, val_loss: 0.07029343\n",
      "Epoch: [25] [ 110/ 548] time: 384.4810, train_loss: -15.09151840, val_loss: 3.65314865\n",
      "Epoch: [25] [ 120/ 548] time: 384.7782, train_loss: 10.36528778, val_loss: 1.58091354\n",
      "Epoch: [25] [ 130/ 548] time: 385.0813, train_loss: -6.09518433, val_loss: 1.94121170\n",
      "Epoch: [25] [ 140/ 548] time: 385.4072, train_loss: 20.65153503, val_loss: 3.99285507\n",
      "Epoch: [25] [ 150/ 548] time: 385.7127, train_loss: -23.29257202, val_loss: -0.69004440\n",
      "Epoch: [25] [ 160/ 548] time: 386.0198, train_loss: 58.92040253, val_loss: 0.97692108\n",
      "Epoch: [25] [ 170/ 548] time: 386.3180, train_loss: 24.64627838, val_loss: 11.27672577\n",
      "Epoch: [25] [ 180/ 548] time: 386.6229, train_loss: -21.32582664, val_loss: 6.03040695\n",
      "Epoch: [25] [ 190/ 548] time: 386.9147, train_loss: -1.98994064, val_loss: 3.76448822\n",
      "Epoch: [25] [ 200/ 548] time: 387.2068, train_loss: 43.01465607, val_loss: 1.03426743\n",
      "Epoch: [25] [ 210/ 548] time: 387.5158, train_loss: 17.98335266, val_loss: 0.38991165\n",
      "Epoch: [25] [ 220/ 548] time: 387.8361, train_loss: 15.07603455, val_loss: -3.01220322\n",
      "Epoch: [25] [ 230/ 548] time: 388.1240, train_loss: 7.70116806, val_loss: -0.18169022\n",
      "Epoch: [25] [ 240/ 548] time: 388.3908, train_loss: -20.46904755, val_loss: 0.61973190\n",
      "Epoch: [25] [ 250/ 548] time: 388.6769, train_loss: 38.16102600, val_loss: -1.26006317\n",
      "Epoch: [25] [ 260/ 548] time: 388.9449, train_loss: 23.54762650, val_loss: -5.05415726\n",
      "Epoch: [25] [ 270/ 548] time: 389.2081, train_loss: -0.50311661, val_loss: -4.26492310\n",
      "Epoch: [25] [ 280/ 548] time: 389.4910, train_loss: 133.99974060, val_loss: -6.27225113\n",
      "Epoch: [25] [ 290/ 548] time: 389.7714, train_loss: -15.19669724, val_loss: -4.06017303\n",
      "Epoch: [25] [ 300/ 548] time: 390.0544, train_loss: 23.28173065, val_loss: -4.93601990\n",
      "Saving checkpoint\n",
      "Epoch: [25] [ 310/ 548] time: 391.6089, train_loss: -3.74111938, val_loss: -5.99813461\n",
      "Epoch: [25] [ 320/ 548] time: 391.9246, train_loss: 1.80110550, val_loss: -6.54314041\n",
      "Epoch: [25] [ 330/ 548] time: 392.2106, train_loss: -21.21230507, val_loss: 0.78610992\n",
      "Epoch: [25] [ 340/ 548] time: 392.4629, train_loss: -9.62423706, val_loss: 2.91450500\n",
      "Epoch: [25] [ 350/ 548] time: 392.7016, train_loss: -22.74050140, val_loss: -3.50943375\n",
      "Epoch: [25] [ 360/ 548] time: 392.9549, train_loss: -16.55956650, val_loss: -7.96817780\n",
      "Epoch: [25] [ 370/ 548] time: 393.2170, train_loss: 23.56099319, val_loss: -4.83934784\n",
      "Epoch: [25] [ 380/ 548] time: 393.5273, train_loss: 92.68984985, val_loss: -4.17871475\n",
      "Epoch: [25] [ 390/ 548] time: 393.7647, train_loss: 29.99651337, val_loss: -6.80129242\n",
      "Epoch: [25] [ 400/ 548] time: 394.0068, train_loss: -25.68669701, val_loss: -7.02140045\n",
      "Epoch: [25] [ 410/ 548] time: 394.2795, train_loss: 175.80839539, val_loss: -6.31018066\n",
      "Epoch: [25] [ 420/ 548] time: 394.5257, train_loss: -31.72765350, val_loss: -3.50479889\n",
      "Epoch: [25] [ 430/ 548] time: 394.7762, train_loss: -18.63672256, val_loss: -1.69327545\n",
      "Epoch: [25] [ 440/ 548] time: 395.0239, train_loss: -31.99764442, val_loss: -1.58292770\n",
      "Epoch: [25] [ 450/ 548] time: 395.3029, train_loss: -4.13176727, val_loss: -3.42457962\n",
      "Epoch: [25] [ 460/ 548] time: 395.6497, train_loss: 702.23065186, val_loss: -4.78192902\n",
      "Epoch: [25] [ 470/ 548] time: 395.9391, train_loss: -15.66174698, val_loss: -7.03415298\n",
      "Epoch: [25] [ 480/ 548] time: 396.2295, train_loss: 21.96672058, val_loss: -7.45944977\n",
      "Epoch: [25] [ 490/ 548] time: 396.5156, train_loss: -24.07296562, val_loss: -6.33906555\n",
      "Epoch: [25] [ 500/ 548] time: 396.8367, train_loss: 28.23616791, val_loss: -7.10113525\n",
      "Epoch: [25] [ 510/ 548] time: 397.1802, train_loss: 22.14957428, val_loss: -4.91788483\n",
      "Epoch: [25] [ 520/ 548] time: 397.5367, train_loss: 18.41732407, val_loss: -3.71615601\n",
      "Epoch: [25] [ 530/ 548] time: 397.8522, train_loss: 104.73815155, val_loss: -2.84193039\n",
      "Epoch: [25] [ 540/ 548] time: 398.1704, train_loss: 119.59901428, val_loss: -2.28990555\n",
      "Epoch: [26] [   0/ 548] time: 398.4306, train_loss: -31.19800377, val_loss: -1.90999603\n",
      "Epoch: [26] [  10/ 548] time: 398.7454, train_loss: -22.23367310, val_loss: -3.83745956\n",
      "Epoch: [26] [  20/ 548] time: 399.0314, train_loss: 4.17446518, val_loss: -5.06323242\n",
      "Epoch: [26] [  30/ 548] time: 399.3023, train_loss: -17.18427277, val_loss: -5.17522049\n",
      "Epoch: [26] [  40/ 548] time: 399.5810, train_loss: -6.07251358, val_loss: -7.05955505\n",
      "Epoch: [26] [  50/ 548] time: 399.9009, train_loss: 37.25083923, val_loss: -7.74489975\n",
      "Epoch: [26] [  60/ 548] time: 400.1816, train_loss: -10.62285233, val_loss: 1.66816711\n",
      "Epoch: [26] [  70/ 548] time: 400.4597, train_loss: -12.41009140, val_loss: -8.36132050\n",
      "Epoch: [26] [  80/ 548] time: 400.7726, train_loss: -22.26608658, val_loss: -6.17370224\n",
      "Epoch: [26] [  90/ 548] time: 401.0487, train_loss: 203.14205933, val_loss: -2.35934067\n",
      "Epoch: [26] [ 100/ 548] time: 401.3191, train_loss: 27.45346069, val_loss: -1.45831680\n",
      "Epoch: [26] [ 110/ 548] time: 401.5874, train_loss: -25.58092117, val_loss: -6.78662109\n",
      "Epoch: [26] [ 120/ 548] time: 401.8571, train_loss: -10.58157349, val_loss: -6.05389786\n",
      "Epoch: [26] [ 130/ 548] time: 402.1376, train_loss: -32.73794556, val_loss: -4.62787628\n",
      "Epoch: [26] [ 140/ 548] time: 402.4252, train_loss: -23.60925484, val_loss: -8.49013519\n",
      "Epoch: [26] [ 150/ 548] time: 402.6947, train_loss: 1.25113297, val_loss: -8.45195770\n",
      "Epoch: [26] [ 160/ 548] time: 402.9738, train_loss: 5.46171570, val_loss: -3.44538498\n",
      "Epoch: [26] [ 170/ 548] time: 403.2553, train_loss: -17.60523605, val_loss: -4.31108856\n",
      "Epoch: [26] [ 180/ 548] time: 403.5568, train_loss: -23.11836052, val_loss: -4.50759125\n",
      "Epoch: [26] [ 190/ 548] time: 403.8511, train_loss: -32.18129349, val_loss: -7.62260056\n",
      "Epoch: [26] [ 200/ 548] time: 404.1350, train_loss: 15.57954407, val_loss: -7.39709854\n",
      "Epoch: [26] [ 210/ 548] time: 404.4213, train_loss: -5.48685074, val_loss: -7.22348404\n",
      "Epoch: [26] [ 220/ 548] time: 404.7011, train_loss: -23.99451065, val_loss: -7.27962875\n",
      "Epoch: [26] [ 230/ 548] time: 404.9631, train_loss: 15.41432953, val_loss: -9.70112991\n",
      "Epoch: [26] [ 240/ 548] time: 405.2094, train_loss: 37.57369232, val_loss: -7.94197464\n",
      "Epoch: [26] [ 250/ 548] time: 405.4599, train_loss: -15.31516647, val_loss: -9.14086533\n",
      "Epoch: [26] [ 260/ 548] time: 405.7300, train_loss: -3.54299164, val_loss: -6.72600555\n",
      "Epoch: [26] [ 270/ 548] time: 405.9774, train_loss: -26.46622849, val_loss: -6.29875183\n",
      "Epoch: [26] [ 280/ 548] time: 406.2320, train_loss: 35.63518524, val_loss: -5.51332092\n",
      "Epoch: [26] [ 290/ 548] time: 406.4765, train_loss: -10.41055679, val_loss: -6.38485336\n",
      "Epoch: [26] [ 300/ 548] time: 406.7198, train_loss: 381.72540283, val_loss: -6.54165268\n",
      "Epoch: [26] [ 310/ 548] time: 406.9598, train_loss: -14.29281998, val_loss: -9.49890900\n",
      "Epoch: [26] [ 320/ 548] time: 407.2037, train_loss: 143.76858521, val_loss: -6.86109543\n",
      "Epoch: [26] [ 330/ 548] time: 407.4426, train_loss: 34.38251114, val_loss: -2.70826340\n",
      "Epoch: [26] [ 340/ 548] time: 407.6772, train_loss: -4.84928513, val_loss: -5.00530243\n",
      "Epoch: [26] [ 350/ 548] time: 407.9152, train_loss: -10.12245941, val_loss: -6.59498596\n",
      "Epoch: [26] [ 360/ 548] time: 408.1490, train_loss: 166.47070312, val_loss: -5.77695084\n",
      "Epoch: [26] [ 370/ 548] time: 408.3877, train_loss: 57.68464279, val_loss: -8.39401245\n",
      "Epoch: [26] [ 380/ 548] time: 408.6199, train_loss: -4.24259186, val_loss: -9.29424286\n",
      "Epoch: [26] [ 390/ 548] time: 408.8543, train_loss: -15.30301666, val_loss: 3.04019165\n",
      "Epoch: [26] [ 400/ 548] time: 409.0891, train_loss: 2.68112946, val_loss: 12.74074173\n",
      "Epoch: [26] [ 410/ 548] time: 409.3352, train_loss: 211.77976990, val_loss: 6.83513641\n",
      "Epoch: [26] [ 420/ 548] time: 409.5843, train_loss: 35.58404541, val_loss: 0.00198746\n",
      "Epoch: [26] [ 430/ 548] time: 409.8557, train_loss: -8.34668732, val_loss: -5.06687164\n",
      "Epoch: [26] [ 440/ 548] time: 410.1449, train_loss: 3.15777588, val_loss: -3.83364487\n",
      "Epoch: [26] [ 450/ 548] time: 410.4183, train_loss: -14.16755676, val_loss: -4.46834946\n",
      "Epoch: [26] [ 460/ 548] time: 410.6995, train_loss: 283.29504395, val_loss: -9.13497925\n",
      "Epoch: [26] [ 470/ 548] time: 410.9452, train_loss: -30.65035057, val_loss: -9.91427231\n",
      "Epoch: [26] [ 480/ 548] time: 411.1803, train_loss: -4.22194672, val_loss: -11.07876205\n",
      "Epoch: [26] [ 490/ 548] time: 411.4214, train_loss: -7.58748627, val_loss: -11.08546829\n",
      "Epoch: [26] [ 500/ 548] time: 411.6547, train_loss: -6.33729935, val_loss: -8.82687378\n",
      "Epoch: [26] [ 510/ 548] time: 411.9098, train_loss: -10.26285934, val_loss: -7.52617264\n",
      "Epoch: [26] [ 520/ 548] time: 412.2087, train_loss: -4.55339050, val_loss: -9.69107819\n",
      "Epoch: [26] [ 530/ 548] time: 412.4877, train_loss: 25.60221863, val_loss: -7.45642471\n",
      "Epoch: [26] [ 540/ 548] time: 412.7424, train_loss: -7.15411758, val_loss: -10.32440948\n",
      "Epoch: [27] [   0/ 548] time: 412.9462, train_loss: -9.61251068, val_loss: -7.95590210\n",
      "Epoch: [27] [  10/ 548] time: 413.1976, train_loss: 77.64183044, val_loss: -9.14730835\n",
      "Epoch: [27] [  20/ 548] time: 413.4572, train_loss: -15.31368256, val_loss: -9.50195694\n",
      "Epoch: [27] [  30/ 548] time: 413.7071, train_loss: 15.12960815, val_loss: -10.71097946\n",
      "Epoch: [27] [  40/ 548] time: 413.9634, train_loss: -8.37930298, val_loss: -12.64477921\n",
      "Epoch: [27] [  50/ 548] time: 414.2187, train_loss: 3.22379303, val_loss: -12.88290024\n",
      "Epoch: [27] [  60/ 548] time: 414.4730, train_loss: -23.45932007, val_loss: -12.31419754\n",
      "Epoch: [27] [  70/ 548] time: 414.7275, train_loss: -20.29383469, val_loss: -6.75845337\n",
      "Epoch: [27] [  80/ 548] time: 414.9829, train_loss: 2.36654663, val_loss: -4.16902542\n",
      "Epoch: [27] [  90/ 548] time: 415.2419, train_loss: -12.65893555, val_loss: -6.60138702\n",
      "Epoch: [27] [ 100/ 548] time: 415.4795, train_loss: -22.39866257, val_loss: -7.01594162\n",
      "Epoch: [27] [ 110/ 548] time: 415.7473, train_loss: -3.11922073, val_loss: -9.99500275\n",
      "Epoch: [27] [ 120/ 548] time: 416.0026, train_loss: -5.84046173, val_loss: -11.85474777\n",
      "Epoch: [27] [ 130/ 548] time: 416.2720, train_loss: -15.37847519, val_loss: -12.83722687\n",
      "Epoch: [27] [ 140/ 548] time: 416.5483, train_loss: -32.97317505, val_loss: -10.04710007\n",
      "Epoch: [27] [ 150/ 548] time: 416.8226, train_loss: 25.91636276, val_loss: -12.09809113\n",
      "Epoch: [27] [ 160/ 548] time: 417.0800, train_loss: -25.42373848, val_loss: -11.68821335\n",
      "Epoch: [27] [ 170/ 548] time: 417.3249, train_loss: 419.68032837, val_loss: -13.13376999\n",
      "Epoch: [27] [ 180/ 548] time: 417.5726, train_loss: -15.62009811, val_loss: -15.43992615\n",
      "Epoch: [27] [ 190/ 548] time: 417.8140, train_loss: 5.37928772, val_loss: -11.79778671\n",
      "Epoch: [27] [ 200/ 548] time: 418.0579, train_loss: -5.49304962, val_loss: -14.13425827\n",
      "Saving checkpoint\n",
      "Epoch: [27] [ 210/ 548] time: 419.3461, train_loss: -6.65176392, val_loss: -13.34217072\n",
      "Epoch: [27] [ 220/ 548] time: 419.5981, train_loss: -12.56426239, val_loss: -11.12296677\n",
      "Epoch: [27] [ 230/ 548] time: 419.8497, train_loss: 2.02522278, val_loss: -11.53512192\n",
      "Epoch: [27] [ 240/ 548] time: 420.0850, train_loss: -1.61249924, val_loss: -11.81120682\n",
      "Epoch: [27] [ 250/ 548] time: 420.3227, train_loss: 77.64955139, val_loss: -14.23768616\n",
      "Epoch: [27] [ 260/ 548] time: 420.5588, train_loss: 9.55908203, val_loss: -12.46451569\n",
      "Epoch: [27] [ 270/ 548] time: 420.8105, train_loss: 156.20213318, val_loss: -12.92745209\n",
      "Epoch: [27] [ 280/ 548] time: 421.0397, train_loss: 72.56150818, val_loss: -14.74794006\n",
      "Epoch: [27] [ 290/ 548] time: 421.2770, train_loss: -29.53450584, val_loss: -8.91020584\n",
      "Epoch: [27] [ 300/ 548] time: 421.5173, train_loss: 54.88729858, val_loss: -0.90781403\n",
      "Epoch: [27] [ 310/ 548] time: 421.7490, train_loss: -3.07559204, val_loss: -4.06488037\n",
      "Epoch: [27] [ 320/ 548] time: 421.9975, train_loss: 1.62112427, val_loss: -10.42684174\n",
      "Epoch: [27] [ 330/ 548] time: 422.2885, train_loss: 54.87201691, val_loss: -13.98269272\n",
      "Epoch: [27] [ 340/ 548] time: 422.5497, train_loss: -20.74930000, val_loss: -17.04307938\n",
      "Epoch: [27] [ 350/ 548] time: 422.8144, train_loss: -28.85768509, val_loss: -12.38291931\n",
      "Epoch: [27] [ 360/ 548] time: 423.0547, train_loss: 47.35906982, val_loss: -10.70208740\n",
      "Epoch: [27] [ 370/ 548] time: 423.2908, train_loss: -13.60686493, val_loss: -2.63223648\n",
      "Epoch: [27] [ 380/ 548] time: 423.5217, train_loss: -8.26373672, val_loss: -5.98744202\n",
      "Epoch: [27] [ 390/ 548] time: 423.7569, train_loss: 20.59913635, val_loss: -11.27600861\n",
      "Epoch: [27] [ 400/ 548] time: 423.9908, train_loss: -24.50201416, val_loss: -14.56658173\n",
      "Epoch: [27] [ 410/ 548] time: 424.2209, train_loss: 11.32111740, val_loss: -16.37941360\n",
      "Epoch: [27] [ 420/ 548] time: 424.4564, train_loss: 76.45730591, val_loss: -14.58666611\n",
      "Epoch: [27] [ 430/ 548] time: 424.6911, train_loss: -28.29532433, val_loss: -16.59123611\n",
      "Epoch: [27] [ 440/ 548] time: 424.9264, train_loss: -27.00292778, val_loss: -15.81162643\n",
      "Epoch: [27] [ 450/ 548] time: 425.1715, train_loss: -9.29476547, val_loss: -16.62004471\n",
      "Epoch: [27] [ 460/ 548] time: 425.4443, train_loss: -19.12175560, val_loss: 3.25255585\n",
      "Epoch: [27] [ 470/ 548] time: 425.7203, train_loss: 47.95230865, val_loss: 2.05637741\n",
      "Epoch: [27] [ 480/ 548] time: 425.9670, train_loss: -17.42655182, val_loss: -9.40364456\n",
      "Epoch: [27] [ 490/ 548] time: 426.2088, train_loss: -1.59456253, val_loss: -7.68719864\n",
      "Epoch: [27] [ 500/ 548] time: 426.4572, train_loss: 85.53775024, val_loss: -9.15678406\n",
      "Epoch: [27] [ 510/ 548] time: 426.7005, train_loss: -13.81710434, val_loss: -12.12345123\n",
      "Epoch: [27] [ 520/ 548] time: 426.9413, train_loss: -14.57194138, val_loss: -14.97071457\n",
      "Epoch: [27] [ 530/ 548] time: 427.1835, train_loss: 2.33613205, val_loss: -13.70840836\n",
      "Epoch: [27] [ 540/ 548] time: 427.4291, train_loss: -38.27719116, val_loss: -14.90135574\n",
      "Epoch: [28] [   0/ 548] time: 427.6242, train_loss: -29.04961205, val_loss: -15.97364807\n",
      "Epoch: [28] [  10/ 548] time: 427.8905, train_loss: 0.05867004, val_loss: -15.71642685\n",
      "Epoch: [28] [  20/ 548] time: 428.1636, train_loss: -21.86983490, val_loss: -17.47970581\n",
      "Epoch: [28] [  30/ 548] time: 428.4388, train_loss: -18.07172012, val_loss: -15.52160645\n",
      "Epoch: [28] [  40/ 548] time: 428.7096, train_loss: -28.36114883, val_loss: -14.58241272\n",
      "Epoch: [28] [  50/ 548] time: 428.9744, train_loss: 67.18470764, val_loss: -14.44485092\n",
      "Epoch: [28] [  60/ 548] time: 429.2224, train_loss: -23.41509628, val_loss: -16.09624863\n",
      "Epoch: [28] [  70/ 548] time: 429.4744, train_loss: 24.70618439, val_loss: -15.74718475\n",
      "Epoch: [28] [  80/ 548] time: 429.7225, train_loss: -24.64581871, val_loss: -18.54831505\n",
      "Epoch: [28] [  90/ 548] time: 429.9724, train_loss: 4.19814682, val_loss: -19.84045410\n",
      "Epoch: [28] [ 100/ 548] time: 430.2222, train_loss: -16.09670258, val_loss: -18.09393692\n",
      "Epoch: [28] [ 110/ 548] time: 430.4700, train_loss: 2.14608002, val_loss: -16.79485703\n",
      "Epoch: [28] [ 120/ 548] time: 430.7233, train_loss: -33.35436249, val_loss: -19.00582695\n",
      "Epoch: [28] [ 130/ 548] time: 430.9599, train_loss: 36.78444290, val_loss: -18.43429947\n",
      "Epoch: [28] [ 140/ 548] time: 431.1934, train_loss: -4.41938019, val_loss: -19.30192566\n",
      "Epoch: [28] [ 150/ 548] time: 431.4306, train_loss: 4.58192062, val_loss: -19.92692757\n",
      "Epoch: [28] [ 160/ 548] time: 431.6690, train_loss: -6.48161316, val_loss: -19.26679230\n",
      "Epoch: [28] [ 170/ 548] time: 431.9036, train_loss: -23.49264145, val_loss: -19.10465431\n",
      "Epoch: [28] [ 180/ 548] time: 432.1426, train_loss: -1.07996368, val_loss: -21.13841248\n",
      "Epoch: [28] [ 190/ 548] time: 432.3885, train_loss: -29.60917664, val_loss: -18.89455795\n",
      "Epoch: [28] [ 200/ 548] time: 432.6316, train_loss: -27.73739052, val_loss: -18.17805481\n",
      "Epoch: [28] [ 210/ 548] time: 432.8772, train_loss: -30.23302841, val_loss: -13.64620209\n",
      "Epoch: [28] [ 220/ 548] time: 433.1222, train_loss: 86.98407745, val_loss: -14.69049072\n",
      "Epoch: [28] [ 230/ 548] time: 433.3679, train_loss: -17.51402283, val_loss: -8.63284683\n",
      "Epoch: [28] [ 240/ 548] time: 433.6110, train_loss: -29.84888458, val_loss: -8.39746094\n",
      "Epoch: [28] [ 250/ 548] time: 433.8516, train_loss: 5.56119156, val_loss: -12.34992599\n",
      "Epoch: [28] [ 260/ 548] time: 434.0941, train_loss: -25.63186455, val_loss: -13.75230026\n",
      "Epoch: [28] [ 270/ 548] time: 434.3795, train_loss: -6.76947784, val_loss: -14.70907211\n",
      "Epoch: [28] [ 280/ 548] time: 434.6465, train_loss: 0.18408585, val_loss: -17.44525146\n",
      "Epoch: [28] [ 290/ 548] time: 434.9130, train_loss: -23.54036713, val_loss: -20.72200966\n",
      "Epoch: [28] [ 300/ 548] time: 435.1684, train_loss: 19.26504517, val_loss: -18.63366699\n",
      "Epoch: [28] [ 310/ 548] time: 435.4127, train_loss: 46.41202927, val_loss: -17.91417694\n",
      "Epoch: [28] [ 320/ 548] time: 435.6660, train_loss: -31.27692795, val_loss: -13.06960297\n",
      "Epoch: [28] [ 330/ 548] time: 435.9170, train_loss: -17.20253372, val_loss: -10.38507080\n",
      "Epoch: [28] [ 340/ 548] time: 436.1596, train_loss: -21.77990532, val_loss: -17.13152695\n",
      "Epoch: [28] [ 350/ 548] time: 436.4046, train_loss: -15.47772980, val_loss: -16.58881760\n",
      "Epoch: [28] [ 360/ 548] time: 436.6592, train_loss: -13.21928787, val_loss: -18.33187675\n",
      "Epoch: [28] [ 370/ 548] time: 436.9199, train_loss: -27.46465302, val_loss: -19.95302200\n",
      "Epoch: [28] [ 380/ 548] time: 437.1813, train_loss: -12.71798706, val_loss: -19.89868736\n",
      "Epoch: [28] [ 390/ 548] time: 437.4263, train_loss: -9.14594269, val_loss: -21.80777740\n",
      "Epoch: [28] [ 400/ 548] time: 437.6715, train_loss: -23.67134666, val_loss: -20.15656853\n",
      "Epoch: [28] [ 410/ 548] time: 437.9086, train_loss: -26.71757507, val_loss: -21.56319618\n",
      "Epoch: [28] [ 420/ 548] time: 438.1521, train_loss: 2.28382492, val_loss: -20.03233337\n",
      "Epoch: [28] [ 430/ 548] time: 438.3934, train_loss: -22.52000618, val_loss: -20.57263947\n",
      "Epoch: [28] [ 440/ 548] time: 438.6429, train_loss: -24.69104576, val_loss: -12.05387878\n",
      "Epoch: [28] [ 450/ 548] time: 438.8932, train_loss: -5.02225876, val_loss: -12.83882904\n",
      "Epoch: [28] [ 460/ 548] time: 439.1383, train_loss: -19.21584511, val_loss: -11.59294891\n",
      "Epoch: [28] [ 470/ 548] time: 439.3784, train_loss: -2.11957932, val_loss: -17.03227615\n",
      "Epoch: [28] [ 480/ 548] time: 439.6322, train_loss: -34.22839737, val_loss: -19.22375870\n",
      "Epoch: [28] [ 490/ 548] time: 439.8727, train_loss: -6.68657684, val_loss: -21.48445129\n",
      "Epoch: [28] [ 500/ 548] time: 440.1185, train_loss: -9.67717361, val_loss: -21.30010605\n",
      "Epoch: [28] [ 510/ 548] time: 440.3893, train_loss: -17.68272400, val_loss: -22.14946556\n",
      "Epoch: [28] [ 520/ 548] time: 440.6892, train_loss: -18.69707298, val_loss: -18.49053001\n",
      "Epoch: [28] [ 530/ 548] time: 440.9876, train_loss: -4.32046890, val_loss: -22.07042313\n",
      "Epoch: [28] [ 540/ 548] time: 441.2732, train_loss: -33.87178040, val_loss: -20.00993729\n",
      "Epoch: [29] [   0/ 548] time: 441.4766, train_loss: 4.63341904, val_loss: -18.84467125\n",
      "Epoch: [29] [  10/ 548] time: 441.7274, train_loss: -17.78168488, val_loss: -18.45302582\n",
      "Epoch: [29] [  20/ 548] time: 441.9780, train_loss: -34.33325958, val_loss: -20.26691437\n",
      "Epoch: [29] [  30/ 548] time: 442.2217, train_loss: 125.32531738, val_loss: -20.50280952\n",
      "Epoch: [29] [  40/ 548] time: 442.4660, train_loss: 5.95548630, val_loss: -20.78694153\n",
      "Epoch: [29] [  50/ 548] time: 442.7056, train_loss: -39.06319809, val_loss: -20.45308304\n",
      "Epoch: [29] [  60/ 548] time: 442.9411, train_loss: 15.90776443, val_loss: -19.83712387\n",
      "Epoch: [29] [  70/ 548] time: 443.1841, train_loss: 18.41821289, val_loss: -19.57787132\n",
      "Epoch: [29] [  80/ 548] time: 443.4267, train_loss: -22.36297989, val_loss: -19.35931969\n",
      "Epoch: [29] [  90/ 548] time: 443.6678, train_loss: -22.78877640, val_loss: -20.58013916\n",
      "Epoch: [29] [ 100/ 548] time: 443.9089, train_loss: -17.78919601, val_loss: -20.80706978\n",
      "Saving checkpoint\n",
      "Epoch: [29] [ 110/ 548] time: 445.2190, train_loss: -35.33348846, val_loss: -20.58253098\n",
      "Epoch: [29] [ 120/ 548] time: 445.5104, train_loss: -11.77902222, val_loss: -21.60773659\n",
      "Epoch: [29] [ 130/ 548] time: 445.8195, train_loss: -31.93712234, val_loss: -21.86247635\n",
      "Epoch: [29] [ 140/ 548] time: 446.1012, train_loss: 5.63946915, val_loss: -21.71837234\n",
      "Epoch: [29] [ 150/ 548] time: 446.4097, train_loss: -5.50554657, val_loss: -22.30981827\n",
      "Epoch: [29] [ 160/ 548] time: 446.7202, train_loss: 20.81764984, val_loss: -19.28550720\n",
      "Epoch: [29] [ 170/ 548] time: 447.0382, train_loss: -20.76651573, val_loss: -16.14982986\n",
      "Epoch: [29] [ 180/ 548] time: 447.3408, train_loss: -24.61876297, val_loss: -17.11168289\n",
      "Epoch: [29] [ 190/ 548] time: 447.6379, train_loss: -22.61637497, val_loss: -20.11551666\n",
      "Epoch: [29] [ 200/ 548] time: 447.9283, train_loss: 31.22282791, val_loss: -20.66624832\n",
      "Epoch: [29] [ 210/ 548] time: 448.2178, train_loss: 1.54257965, val_loss: -21.46221542\n",
      "Epoch: [29] [ 220/ 548] time: 448.4856, train_loss: -17.38906479, val_loss: -18.75775909\n",
      "Epoch: [29] [ 230/ 548] time: 448.7393, train_loss: -3.65686035, val_loss: -21.15948486\n",
      "Epoch: [29] [ 240/ 548] time: 448.9907, train_loss: -21.69577980, val_loss: -23.32997704\n",
      "Epoch: [29] [ 250/ 548] time: 449.2410, train_loss: 18.18579102, val_loss: -21.79277611\n",
      "Epoch: [29] [ 260/ 548] time: 449.4779, train_loss: -28.91134262, val_loss: -20.11795425\n",
      "Epoch: [29] [ 270/ 548] time: 449.7230, train_loss: -16.28977203, val_loss: -21.40670586\n",
      "Epoch: [29] [ 280/ 548] time: 449.9606, train_loss: -29.95912361, val_loss: -22.62390709\n",
      "Epoch: [29] [ 290/ 548] time: 450.2272, train_loss: -23.36756897, val_loss: -23.69804955\n",
      "Epoch: [29] [ 300/ 548] time: 450.4991, train_loss: -24.46868896, val_loss: -23.35789299\n",
      "Epoch: [29] [ 310/ 548] time: 450.7748, train_loss: -21.16276550, val_loss: -20.59928131\n",
      "Epoch: [29] [ 320/ 548] time: 451.0321, train_loss: 9.01052856, val_loss: -23.40938187\n",
      "Epoch: [29] [ 330/ 548] time: 451.2910, train_loss: -25.08066368, val_loss: -19.97644234\n",
      "Epoch: [29] [ 340/ 548] time: 451.6129, train_loss: -22.79315376, val_loss: -20.87761497\n",
      "Epoch: [29] [ 350/ 548] time: 451.9144, train_loss: -20.04717255, val_loss: -21.79241180\n",
      "Epoch: [29] [ 360/ 548] time: 452.2968, train_loss: -20.68626785, val_loss: -23.90919113\n",
      "Epoch: [29] [ 370/ 548] time: 452.6770, train_loss: -8.55424118, val_loss: -22.84683418\n",
      "Epoch: [29] [ 380/ 548] time: 453.0174, train_loss: -22.29170418, val_loss: -18.61449623\n",
      "Epoch: [29] [ 390/ 548] time: 453.3662, train_loss: -17.18282318, val_loss: -21.99797058\n",
      "Epoch: [29] [ 400/ 548] time: 453.6941, train_loss: -23.59012222, val_loss: -23.52387047\n",
      "Epoch: [29] [ 410/ 548] time: 453.9946, train_loss: -34.73537064, val_loss: -21.36430168\n",
      "Epoch: [29] [ 420/ 548] time: 454.2721, train_loss: -15.98394775, val_loss: -21.05693817\n",
      "Epoch: [29] [ 430/ 548] time: 454.5540, train_loss: -8.74218750, val_loss: -22.91157150\n",
      "Epoch: [29] [ 440/ 548] time: 454.8323, train_loss: 3.96516037, val_loss: -25.81231880\n",
      "Epoch: [29] [ 450/ 548] time: 455.1038, train_loss: -34.61798096, val_loss: -23.07561684\n",
      "Epoch: [29] [ 460/ 548] time: 455.3682, train_loss: -0.13080215, val_loss: -22.94225502\n",
      "Epoch: [29] [ 470/ 548] time: 455.6387, train_loss: -26.98006821, val_loss: -21.25278664\n",
      "Epoch: [29] [ 480/ 548] time: 455.9137, train_loss: -30.12462425, val_loss: -8.94137192\n",
      "Epoch: [29] [ 490/ 548] time: 456.1533, train_loss: 10.20839310, val_loss: -17.65505219\n",
      "Epoch: [29] [ 500/ 548] time: 456.3884, train_loss: -30.69404030, val_loss: -21.78248024\n",
      "Epoch: [29] [ 510/ 548] time: 456.6384, train_loss: -36.31967163, val_loss: -19.25972939\n",
      "Epoch: [29] [ 520/ 548] time: 456.8815, train_loss: -23.64863777, val_loss: -20.09951782\n",
      "Epoch: [29] [ 530/ 548] time: 457.1413, train_loss: -13.10593414, val_loss: -18.94092560\n",
      "Epoch: [29] [ 540/ 548] time: 457.3922, train_loss: -22.08855057, val_loss: -20.42175102\n",
      "Epoch: [30] [   0/ 548] time: 457.5849, train_loss: -26.60728073, val_loss: -21.21203804\n",
      "Epoch: [30] [  10/ 548] time: 457.8233, train_loss: -28.65869522, val_loss: -20.79422760\n",
      "Epoch: [30] [  20/ 548] time: 458.0684, train_loss: -30.10840034, val_loss: -22.95676422\n",
      "Epoch: [30] [  30/ 548] time: 458.3082, train_loss: -22.95501328, val_loss: -23.31231499\n",
      "Epoch: [30] [  40/ 548] time: 458.5516, train_loss: -2.94613647, val_loss: -23.27983284\n",
      "Epoch: [30] [  50/ 548] time: 458.8004, train_loss: -19.91203690, val_loss: -22.53730774\n",
      "Epoch: [30] [  60/ 548] time: 459.0839, train_loss: -5.25733185, val_loss: -24.78108788\n",
      "Epoch: [30] [  70/ 548] time: 459.3627, train_loss: -12.27925873, val_loss: -24.09906006\n",
      "Epoch: [30] [  80/ 548] time: 459.6269, train_loss: 20.24859619, val_loss: -24.28041077\n",
      "Epoch: [30] [  90/ 548] time: 459.8998, train_loss: 0.95031738, val_loss: -25.30607796\n",
      "Epoch: [30] [ 100/ 548] time: 460.1623, train_loss: -18.19216919, val_loss: -22.60602570\n",
      "Epoch: [30] [ 110/ 548] time: 460.4080, train_loss: -28.45557404, val_loss: -22.91922188\n",
      "Epoch: [30] [ 120/ 548] time: 460.6544, train_loss: -12.31759262, val_loss: -24.28002357\n",
      "Epoch: [30] [ 130/ 548] time: 460.9371, train_loss: 19.59995270, val_loss: -18.70956612\n",
      "Epoch: [30] [ 140/ 548] time: 461.2063, train_loss: 34.71623230, val_loss: -20.19238663\n",
      "Epoch: [30] [ 150/ 548] time: 461.4713, train_loss: -24.58313942, val_loss: -23.49587631\n",
      "Epoch: [30] [ 160/ 548] time: 461.7423, train_loss: 3.77182770, val_loss: -22.76782036\n",
      "Epoch: [30] [ 170/ 548] time: 462.0165, train_loss: -32.26874542, val_loss: -24.91915703\n",
      "Epoch: [30] [ 180/ 548] time: 462.2689, train_loss: -24.17496109, val_loss: -23.72267532\n",
      "Epoch: [30] [ 190/ 548] time: 462.5301, train_loss: -28.37347412, val_loss: -24.39211655\n",
      "Epoch: [30] [ 200/ 548] time: 462.7841, train_loss: -25.92570877, val_loss: -24.53946686\n",
      "Epoch: [30] [ 210/ 548] time: 463.0538, train_loss: -27.39002037, val_loss: -25.73327255\n",
      "Epoch: [30] [ 220/ 548] time: 463.3293, train_loss: -27.65422821, val_loss: -24.96565819\n",
      "Epoch: [30] [ 230/ 548] time: 463.6012, train_loss: -32.07704163, val_loss: -26.73853302\n",
      "Epoch: [30] [ 240/ 548] time: 463.8500, train_loss: -30.13868332, val_loss: -24.61993217\n",
      "Epoch: [30] [ 250/ 548] time: 464.0991, train_loss: -38.38877106, val_loss: -12.11975098\n",
      "Epoch: [30] [ 260/ 548] time: 464.3522, train_loss: -31.18423462, val_loss: -17.42612839\n",
      "Epoch: [30] [ 270/ 548] time: 464.5893, train_loss: -27.37838936, val_loss: -16.46383286\n",
      "Epoch: [30] [ 280/ 548] time: 464.8265, train_loss: -31.61565399, val_loss: -22.04487991\n",
      "Epoch: [30] [ 290/ 548] time: 465.0670, train_loss: -35.68203354, val_loss: -22.92021179\n",
      "Epoch: [30] [ 300/ 548] time: 465.3523, train_loss: -27.88826942, val_loss: -23.39669037\n",
      "Epoch: [30] [ 310/ 548] time: 465.6279, train_loss: -8.47776413, val_loss: -20.58562279\n",
      "Epoch: [30] [ 320/ 548] time: 465.9159, train_loss: -36.60785675, val_loss: -18.29725456\n",
      "Epoch: [30] [ 330/ 548] time: 466.1955, train_loss: -37.82086945, val_loss: -16.78017044\n",
      "Epoch: [30] [ 340/ 548] time: 466.4546, train_loss: -32.75571442, val_loss: -22.79884720\n",
      "Epoch: [30] [ 350/ 548] time: 466.7034, train_loss: -25.77425385, val_loss: -25.51256943\n",
      "Epoch: [30] [ 360/ 548] time: 466.9586, train_loss: -36.26877594, val_loss: -25.61761093\n",
      "Epoch: [30] [ 370/ 548] time: 467.2091, train_loss: -30.51517677, val_loss: -25.67576027\n",
      "Epoch: [30] [ 380/ 548] time: 467.4576, train_loss: -22.13640594, val_loss: -25.07324219\n",
      "Epoch: [30] [ 390/ 548] time: 467.7103, train_loss: -25.54560852, val_loss: -23.00890350\n",
      "Epoch: [30] [ 400/ 548] time: 467.9588, train_loss: 37.39575195, val_loss: -25.90987778\n",
      "Epoch: [30] [ 410/ 548] time: 468.2334, train_loss: 297.93261719, val_loss: -25.69990730\n",
      "Epoch: [30] [ 420/ 548] time: 468.5012, train_loss: -31.48652077, val_loss: -25.87387848\n",
      "Epoch: [30] [ 430/ 548] time: 468.7687, train_loss: -37.10058594, val_loss: -25.35622978\n",
      "Epoch: [30] [ 440/ 548] time: 469.0338, train_loss: -14.14161682, val_loss: -25.15931702\n",
      "Epoch: [30] [ 450/ 548] time: 469.3320, train_loss: -38.64979553, val_loss: -24.95812988\n",
      "Epoch: [30] [ 460/ 548] time: 469.6206, train_loss: -35.68827438, val_loss: -26.34021759\n",
      "Epoch: [30] [ 470/ 548] time: 469.8910, train_loss: -22.99255180, val_loss: -24.81617928\n",
      "Epoch: [30] [ 480/ 548] time: 470.1810, train_loss: -33.11688995, val_loss: -24.30914497\n",
      "Epoch: [30] [ 490/ 548] time: 470.5558, train_loss: -41.50115967, val_loss: -23.78232384\n",
      "Epoch: [30] [ 500/ 548] time: 470.9092, train_loss: -26.98659897, val_loss: -23.53770638\n",
      "Epoch: [30] [ 510/ 548] time: 471.2599, train_loss: -25.19489098, val_loss: -26.59641075\n",
      "Epoch: [30] [ 520/ 548] time: 471.6242, train_loss: 88.37803650, val_loss: -27.30180168\n",
      "Epoch: [30] [ 530/ 548] time: 471.9224, train_loss: 2.75205994, val_loss: -28.15348816\n",
      "Epoch: [30] [ 540/ 548] time: 472.2252, train_loss: -37.51027679, val_loss: -26.49397850\n",
      "Epoch: [31] [   0/ 548] time: 472.4860, train_loss: -11.64957809, val_loss: -23.90789604\n",
      "Epoch: [31] [  10/ 548] time: 472.7913, train_loss: -23.96400452, val_loss: -25.31210327\n",
      "Saving checkpoint\n",
      "Epoch: [31] [  20/ 548] time: 474.1679, train_loss: -27.27803040, val_loss: -25.96044540\n",
      "Epoch: [31] [  30/ 548] time: 474.4456, train_loss: -23.08730698, val_loss: -27.10534859\n",
      "Epoch: [31] [  40/ 548] time: 474.7218, train_loss: 27.44379425, val_loss: -26.96544647\n",
      "Epoch: [31] [  50/ 548] time: 474.9967, train_loss: -22.35622787, val_loss: -25.40824699\n",
      "Epoch: [31] [  60/ 548] time: 475.2659, train_loss: -29.14352036, val_loss: -26.09936523\n",
      "Epoch: [31] [  70/ 548] time: 475.5437, train_loss: -28.41842842, val_loss: -25.20567513\n",
      "Epoch: [31] [  80/ 548] time: 475.8446, train_loss: 64.93888855, val_loss: -27.14832306\n",
      "Epoch: [31] [  90/ 548] time: 476.1231, train_loss: -21.57283020, val_loss: -27.91382790\n",
      "Epoch: [31] [ 100/ 548] time: 476.3984, train_loss: -42.07269287, val_loss: -28.73623848\n",
      "Epoch: [31] [ 110/ 548] time: 476.6761, train_loss: -33.28340149, val_loss: -26.53374481\n",
      "Epoch: [31] [ 120/ 548] time: 476.9929, train_loss: -29.14253616, val_loss: -27.05474663\n",
      "Epoch: [31] [ 130/ 548] time: 477.3332, train_loss: -29.47364998, val_loss: -27.66572189\n",
      "Epoch: [31] [ 140/ 548] time: 477.6398, train_loss: -34.75013733, val_loss: -27.83866119\n",
      "Epoch: [31] [ 150/ 548] time: 477.9386, train_loss: -34.70241547, val_loss: -28.20265198\n",
      "Epoch: [31] [ 160/ 548] time: 478.2643, train_loss: -28.17468834, val_loss: -27.48592377\n",
      "Epoch: [31] [ 170/ 548] time: 478.6488, train_loss: -23.93979263, val_loss: -25.96661377\n",
      "Epoch: [31] [ 180/ 548] time: 478.9734, train_loss: -23.08557320, val_loss: -26.68062401\n",
      "Epoch: [31] [ 190/ 548] time: 479.3043, train_loss: -38.04797745, val_loss: -27.95216370\n",
      "Epoch: [31] [ 200/ 548] time: 479.6392, train_loss: -36.90436172, val_loss: -27.47637939\n",
      "Epoch: [31] [ 210/ 548] time: 479.9517, train_loss: -18.87526703, val_loss: -26.56838608\n",
      "Epoch: [31] [ 220/ 548] time: 480.2735, train_loss: -36.58172607, val_loss: -27.18158722\n",
      "Epoch: [31] [ 230/ 548] time: 480.5985, train_loss: -25.25772476, val_loss: -28.38321304\n",
      "Epoch: [31] [ 240/ 548] time: 480.9776, train_loss: 564.08160400, val_loss: -29.66222382\n",
      "Epoch: [31] [ 250/ 548] time: 481.3114, train_loss: -18.53319168, val_loss: -19.47600365\n",
      "Epoch: [31] [ 260/ 548] time: 481.6515, train_loss: -21.98982811, val_loss: -21.93008995\n",
      "Epoch: [31] [ 270/ 548] time: 481.9706, train_loss: 18.79705048, val_loss: -25.56099892\n",
      "Epoch: [31] [ 280/ 548] time: 482.3043, train_loss: -30.43570709, val_loss: -25.86822701\n",
      "Epoch: [31] [ 290/ 548] time: 482.6204, train_loss: -13.56951141, val_loss: -24.73538589\n",
      "Epoch: [31] [ 300/ 548] time: 482.9565, train_loss: -30.90717888, val_loss: -26.40371895\n",
      "Epoch: [31] [ 310/ 548] time: 483.2696, train_loss: -18.65500641, val_loss: -26.69123459\n",
      "Epoch: [31] [ 320/ 548] time: 483.5964, train_loss: 5.13016129, val_loss: -28.31526566\n",
      "Epoch: [31] [ 330/ 548] time: 483.9082, train_loss: -31.68526840, val_loss: -26.48414612\n",
      "Epoch: [31] [ 340/ 548] time: 484.2614, train_loss: -21.09276390, val_loss: -24.94505310\n",
      "Epoch: [31] [ 350/ 548] time: 484.6050, train_loss: -23.53282547, val_loss: -23.50413704\n",
      "Epoch: [31] [ 360/ 548] time: 484.9152, train_loss: -26.49612808, val_loss: -27.62198448\n",
      "Epoch: [31] [ 370/ 548] time: 485.1904, train_loss: -22.24996185, val_loss: -29.52958679\n",
      "Epoch: [31] [ 380/ 548] time: 485.5098, train_loss: -31.23871994, val_loss: -27.62187195\n",
      "Epoch: [31] [ 390/ 548] time: 485.8119, train_loss: -35.56101227, val_loss: -25.96277046\n",
      "Epoch: [31] [ 400/ 548] time: 486.0815, train_loss: 220.04180908, val_loss: -24.95473862\n",
      "Epoch: [31] [ 410/ 548] time: 486.3527, train_loss: -36.29279327, val_loss: -21.42535782\n",
      "Epoch: [31] [ 420/ 548] time: 486.6193, train_loss: 47.75576782, val_loss: -18.99417114\n",
      "Epoch: [31] [ 430/ 548] time: 486.8870, train_loss: -4.11504745, val_loss: -22.86968994\n",
      "Epoch: [31] [ 440/ 548] time: 487.1551, train_loss: -4.83384705, val_loss: -24.24209213\n",
      "Epoch: [31] [ 450/ 548] time: 487.4095, train_loss: -19.95052719, val_loss: -26.23928070\n",
      "Epoch: [31] [ 460/ 548] time: 487.6686, train_loss: -10.80581665, val_loss: -26.39308548\n",
      "Epoch: [31] [ 470/ 548] time: 487.9149, train_loss: -29.64794922, val_loss: -28.86000443\n",
      "Epoch: [31] [ 480/ 548] time: 488.1617, train_loss: -28.72626495, val_loss: -27.25356102\n",
      "Epoch: [31] [ 490/ 548] time: 488.4092, train_loss: 2.07150269, val_loss: -24.38862610\n",
      "Epoch: [31] [ 500/ 548] time: 488.6581, train_loss: -28.14759445, val_loss: -26.31032562\n",
      "Epoch: [31] [ 510/ 548] time: 488.8956, train_loss: -28.17174721, val_loss: -27.42704391\n",
      "Epoch: [31] [ 520/ 548] time: 489.1294, train_loss: -24.92149544, val_loss: -27.43349838\n",
      "Epoch: [31] [ 530/ 548] time: 489.3634, train_loss: -29.12378120, val_loss: -27.54571915\n",
      "Epoch: [31] [ 540/ 548] time: 489.6132, train_loss: -7.75698090, val_loss: -29.30973816\n",
      "Epoch: [32] [   0/ 548] time: 489.8079, train_loss: -35.67530823, val_loss: -27.55864334\n",
      "Epoch: [32] [  10/ 548] time: 490.0839, train_loss: -6.93238449, val_loss: -27.79107857\n",
      "Epoch: [32] [  20/ 548] time: 490.3338, train_loss: -6.19773483, val_loss: -27.52177048\n",
      "Epoch: [32] [  30/ 548] time: 490.5839, train_loss: -42.19477081, val_loss: -26.76329613\n",
      "Epoch: [32] [  40/ 548] time: 490.8634, train_loss: -32.85343933, val_loss: -29.53590012\n",
      "Epoch: [32] [  50/ 548] time: 491.1179, train_loss: -16.04426575, val_loss: -28.34160423\n",
      "Epoch: [32] [  60/ 548] time: 491.3828, train_loss: -28.44880486, val_loss: -29.47978973\n",
      "Epoch: [32] [  70/ 548] time: 491.6624, train_loss: -43.86138535, val_loss: -30.10485458\n",
      "Epoch: [32] [  80/ 548] time: 491.9170, train_loss: -23.37294006, val_loss: -28.56188583\n",
      "Epoch: [32] [  90/ 548] time: 492.1997, train_loss: -35.16694641, val_loss: -28.92514420\n",
      "Epoch: [32] [ 100/ 548] time: 492.4572, train_loss: -19.87199783, val_loss: -30.23122978\n",
      "Epoch: [32] [ 110/ 548] time: 492.7082, train_loss: -32.11928177, val_loss: -30.05717278\n",
      "Epoch: [32] [ 120/ 548] time: 492.9531, train_loss: -28.22837448, val_loss: -29.78277588\n",
      "Epoch: [32] [ 130/ 548] time: 493.1926, train_loss: -36.30405426, val_loss: -27.55094910\n",
      "Epoch: [32] [ 140/ 548] time: 493.4399, train_loss: 45.74046326, val_loss: -28.57790756\n",
      "Epoch: [32] [ 150/ 548] time: 493.6951, train_loss: -33.85572052, val_loss: -27.20345688\n",
      "Epoch: [32] [ 160/ 548] time: 493.9665, train_loss: -28.95495605, val_loss: -26.69192314\n",
      "Epoch: [32] [ 170/ 548] time: 494.2230, train_loss: 43.84392548, val_loss: -27.58170891\n",
      "Epoch: [32] [ 180/ 548] time: 494.4663, train_loss: -31.92081070, val_loss: -30.56828690\n",
      "Epoch: [32] [ 190/ 548] time: 494.7130, train_loss: -26.72328186, val_loss: -29.85984230\n",
      "Epoch: [32] [ 200/ 548] time: 494.9723, train_loss: -12.30348969, val_loss: -30.34127045\n",
      "Epoch: [32] [ 210/ 548] time: 495.2258, train_loss: 3.00423431, val_loss: -27.35596848\n",
      "Epoch: [32] [ 220/ 548] time: 495.4654, train_loss: 37.64350128, val_loss: -30.46399307\n",
      "Epoch: [32] [ 230/ 548] time: 495.7258, train_loss: -32.01169586, val_loss: -28.32592964\n",
      "Epoch: [32] [ 240/ 548] time: 496.0037, train_loss: 210.10621643, val_loss: -27.45697784\n",
      "Epoch: [32] [ 250/ 548] time: 496.2891, train_loss: -25.35010910, val_loss: -26.89857101\n",
      "Epoch: [32] [ 260/ 548] time: 496.5811, train_loss: -23.83793640, val_loss: -26.74900436\n",
      "Epoch: [32] [ 270/ 548] time: 496.8908, train_loss: -36.82172394, val_loss: -27.53107262\n",
      "Epoch: [32] [ 280/ 548] time: 497.2188, train_loss: 11.19575500, val_loss: -27.97887993\n",
      "Epoch: [32] [ 290/ 548] time: 497.5166, train_loss: -33.49241257, val_loss: -28.96214294\n",
      "Epoch: [32] [ 300/ 548] time: 497.8231, train_loss: -29.26935959, val_loss: -30.35857391\n",
      "Epoch: [32] [ 310/ 548] time: 498.1811, train_loss: -33.09616089, val_loss: -29.77255249\n",
      "Epoch: [32] [ 320/ 548] time: 498.4833, train_loss: -31.15707779, val_loss: -27.00562859\n",
      "Epoch: [32] [ 330/ 548] time: 498.8208, train_loss: 52.85052490, val_loss: -27.29406548\n",
      "Epoch: [32] [ 340/ 548] time: 499.1657, train_loss: -11.05696106, val_loss: -28.53415489\n",
      "Epoch: [32] [ 350/ 548] time: 499.4801, train_loss: -34.48997498, val_loss: -29.94551659\n",
      "Epoch: [32] [ 360/ 548] time: 499.8369, train_loss: 309.63662720, val_loss: -30.62541771\n",
      "Epoch: [32] [ 370/ 548] time: 500.1656, train_loss: -37.11209106, val_loss: -22.89925957\n",
      "Epoch: [32] [ 380/ 548] time: 500.5374, train_loss: -24.72427940, val_loss: -20.73226357\n",
      "Epoch: [32] [ 390/ 548] time: 500.8875, train_loss: -24.12145805, val_loss: -22.76025009\n",
      "Epoch: [32] [ 400/ 548] time: 501.2246, train_loss: -35.01058960, val_loss: -25.04247093\n",
      "Epoch: [32] [ 410/ 548] time: 501.5518, train_loss: -19.72248459, val_loss: -27.27005577\n",
      "Epoch: [32] [ 420/ 548] time: 501.8946, train_loss: -41.68128204, val_loss: -28.54641914\n",
      "Epoch: [32] [ 430/ 548] time: 502.2169, train_loss: 181.95426941, val_loss: -29.68317223\n",
      "Epoch: [32] [ 440/ 548] time: 502.5466, train_loss: -34.82139587, val_loss: -29.10216141\n",
      "Epoch: [32] [ 450/ 548] time: 502.8781, train_loss: -30.55475235, val_loss: -29.01946449\n",
      "Epoch: [32] [ 460/ 548] time: 503.2010, train_loss: -19.19657516, val_loss: -29.53223801\n",
      "Saving checkpoint\n",
      "Epoch: [32] [ 470/ 548] time: 504.5362, train_loss: -38.93292999, val_loss: -27.97615242\n",
      "Epoch: [32] [ 480/ 548] time: 504.7852, train_loss: -14.38787460, val_loss: -31.00155449\n",
      "Epoch: [32] [ 490/ 548] time: 505.0294, train_loss: -8.54980087, val_loss: -30.99320793\n",
      "Epoch: [32] [ 500/ 548] time: 505.2562, train_loss: -9.89451218, val_loss: -31.22076797\n",
      "Epoch: [32] [ 510/ 548] time: 505.4826, train_loss: -34.15663910, val_loss: -31.74947166\n",
      "Epoch: [32] [ 520/ 548] time: 505.7149, train_loss: -30.60814095, val_loss: -31.69654465\n",
      "Epoch: [32] [ 530/ 548] time: 505.9575, train_loss: -37.44810486, val_loss: -32.32820511\n",
      "Epoch: [32] [ 540/ 548] time: 506.1893, train_loss: -20.89212418, val_loss: -31.53113937\n",
      "Epoch: [33] [   0/ 548] time: 506.3750, train_loss: 89.01145172, val_loss: -32.77970886\n",
      "Epoch: [33] [  10/ 548] time: 506.6018, train_loss: -40.76211929, val_loss: -31.27036667\n",
      "Epoch: [33] [  20/ 548] time: 506.8327, train_loss: -34.35026169, val_loss: -33.12397003\n",
      "Epoch: [33] [  30/ 548] time: 507.0613, train_loss: -36.93802643, val_loss: -32.49713898\n",
      "Epoch: [33] [  40/ 548] time: 507.2965, train_loss: -25.25396919, val_loss: -33.03173065\n",
      "Epoch: [33] [  50/ 548] time: 507.5598, train_loss: -32.01432800, val_loss: -32.29769135\n",
      "Epoch: [33] [  60/ 548] time: 507.8428, train_loss: -12.50299835, val_loss: -30.54568481\n",
      "Epoch: [33] [  70/ 548] time: 508.0927, train_loss: 3.46296692, val_loss: -31.76143074\n",
      "Epoch: [33] [  80/ 548] time: 508.3399, train_loss: -30.38963890, val_loss: -32.93832397\n",
      "Epoch: [33] [  90/ 548] time: 508.6062, train_loss: -28.65901756, val_loss: -31.72246170\n",
      "Epoch: [33] [ 100/ 548] time: 508.8635, train_loss: -25.26735878, val_loss: -31.21954155\n",
      "Epoch: [33] [ 110/ 548] time: 509.1254, train_loss: -30.70954514, val_loss: -29.05995560\n",
      "Epoch: [33] [ 120/ 548] time: 509.3963, train_loss: -25.73968124, val_loss: -27.10485268\n",
      "Epoch: [33] [ 130/ 548] time: 509.6463, train_loss: -26.44639587, val_loss: -28.92986298\n",
      "Epoch: [33] [ 140/ 548] time: 509.8904, train_loss: -26.57100677, val_loss: -29.57682800\n",
      "Epoch: [33] [ 150/ 548] time: 510.1405, train_loss: -27.50735092, val_loss: -29.36344528\n",
      "Epoch: [33] [ 160/ 548] time: 510.3877, train_loss: -30.26649094, val_loss: -29.38733673\n",
      "Epoch: [33] [ 170/ 548] time: 510.6414, train_loss: -25.06579971, val_loss: -31.61240578\n",
      "Epoch: [33] [ 180/ 548] time: 510.8936, train_loss: -26.02474594, val_loss: -30.26336288\n",
      "Epoch: [33] [ 190/ 548] time: 511.1424, train_loss: -22.43446350, val_loss: -31.44283676\n",
      "Epoch: [33] [ 200/ 548] time: 511.3958, train_loss: -29.48836327, val_loss: -30.90594292\n",
      "Epoch: [33] [ 210/ 548] time: 511.6843, train_loss: -32.43042755, val_loss: -28.88793945\n",
      "Epoch: [33] [ 220/ 548] time: 511.9381, train_loss: -34.20887375, val_loss: -32.15192413\n",
      "Epoch: [33] [ 230/ 548] time: 512.2189, train_loss: -30.90096664, val_loss: -29.12607002\n",
      "Epoch: [33] [ 240/ 548] time: 512.4627, train_loss: -38.56914139, val_loss: -26.85989189\n",
      "Epoch: [33] [ 250/ 548] time: 512.7042, train_loss: -29.46204567, val_loss: -26.92015076\n",
      "Epoch: [33] [ 260/ 548] time: 512.9371, train_loss: -32.48735046, val_loss: -29.22932434\n",
      "Epoch: [33] [ 270/ 548] time: 513.1707, train_loss: -35.22424698, val_loss: -29.31175232\n",
      "Epoch: [33] [ 280/ 548] time: 513.4115, train_loss: -34.04887009, val_loss: -31.98478889\n",
      "Epoch: [33] [ 290/ 548] time: 513.6454, train_loss: -44.47187042, val_loss: -32.19309616\n",
      "Epoch: [33] [ 300/ 548] time: 513.8885, train_loss: -9.73959732, val_loss: -30.20927811\n",
      "Epoch: [33] [ 310/ 548] time: 514.1220, train_loss: -31.78554726, val_loss: -31.00098038\n",
      "Epoch: [33] [ 320/ 548] time: 514.3615, train_loss: -8.21873474, val_loss: -32.48758698\n",
      "Epoch: [33] [ 330/ 548] time: 514.6215, train_loss: -2.19866943, val_loss: -32.14374542\n",
      "Epoch: [33] [ 340/ 548] time: 514.8842, train_loss: -35.48881531, val_loss: -30.70086288\n",
      "Epoch: [33] [ 350/ 548] time: 515.1585, train_loss: -36.58703995, val_loss: -30.53594971\n",
      "Epoch: [33] [ 360/ 548] time: 515.4478, train_loss: -36.19781494, val_loss: -31.58042717\n",
      "Epoch: [33] [ 370/ 548] time: 515.7099, train_loss: -21.13405418, val_loss: -32.81285858\n",
      "Epoch: [33] [ 380/ 548] time: 515.9792, train_loss: -32.13496017, val_loss: -31.95864105\n",
      "Epoch: [33] [ 390/ 548] time: 516.2311, train_loss: -35.73446655, val_loss: -32.87694550\n",
      "Epoch: [33] [ 400/ 548] time: 516.4848, train_loss: -35.21620178, val_loss: -31.05314636\n",
      "Epoch: [33] [ 410/ 548] time: 516.7377, train_loss: 8.14924240, val_loss: -31.39137840\n",
      "Epoch: [33] [ 420/ 548] time: 516.9831, train_loss: -34.07818222, val_loss: -32.75981903\n",
      "Epoch: [33] [ 430/ 548] time: 517.2232, train_loss: -25.25427628, val_loss: -33.49937057\n",
      "Epoch: [33] [ 440/ 548] time: 517.4681, train_loss: -32.10671234, val_loss: -32.53594208\n",
      "Epoch: [33] [ 450/ 548] time: 517.7055, train_loss: -17.39193344, val_loss: -32.37329865\n",
      "Epoch: [33] [ 460/ 548] time: 517.9436, train_loss: 85.93989563, val_loss: -32.63201141\n",
      "Epoch: [33] [ 470/ 548] time: 518.1856, train_loss: -35.72227859, val_loss: -32.39184189\n",
      "Epoch: [33] [ 480/ 548] time: 518.4250, train_loss: -28.51627541, val_loss: -31.43958855\n",
      "Epoch: [33] [ 490/ 548] time: 518.6671, train_loss: -36.62389374, val_loss: -29.51130486\n",
      "Epoch: [33] [ 500/ 548] time: 518.9036, train_loss: -36.45792389, val_loss: -31.52866554\n",
      "Epoch: [33] [ 510/ 548] time: 519.1369, train_loss: -35.82675171, val_loss: -32.32724380\n",
      "Epoch: [33] [ 520/ 548] time: 519.3733, train_loss: -41.88287354, val_loss: -33.04150391\n",
      "Epoch: [33] [ 530/ 548] time: 519.6082, train_loss: -24.94672012, val_loss: -32.67012787\n",
      "Epoch: [33] [ 540/ 548] time: 519.8412, train_loss: -11.87378693, val_loss: -32.99698257\n",
      "Epoch: [34] [   0/ 548] time: 520.0337, train_loss: -36.60705566, val_loss: -33.81929779\n",
      "Epoch: [34] [  10/ 548] time: 520.2684, train_loss: -38.05197525, val_loss: -34.13185501\n",
      "Epoch: [34] [  20/ 548] time: 520.5130, train_loss: -33.81832504, val_loss: -33.94714737\n",
      "Epoch: [34] [  30/ 548] time: 520.7944, train_loss: -29.30060768, val_loss: -34.02075195\n",
      "Epoch: [34] [  40/ 548] time: 521.0828, train_loss: -31.41304970, val_loss: -32.97477722\n",
      "Epoch: [34] [  50/ 548] time: 521.3607, train_loss: -36.76156235, val_loss: -32.76681519\n",
      "Epoch: [34] [  60/ 548] time: 521.6135, train_loss: -33.08911896, val_loss: -32.01540375\n",
      "Epoch: [34] [  70/ 548] time: 521.8572, train_loss: -8.55572128, val_loss: -31.98897171\n",
      "Epoch: [34] [  80/ 548] time: 522.1008, train_loss: -36.16061783, val_loss: -33.27807999\n",
      "Epoch: [34] [  90/ 548] time: 522.3391, train_loss: -36.66281128, val_loss: -32.18975830\n",
      "Epoch: [34] [ 100/ 548] time: 522.5810, train_loss: -38.83455658, val_loss: -32.99954987\n",
      "Epoch: [34] [ 110/ 548] time: 522.8273, train_loss: -36.70455551, val_loss: -33.37917709\n",
      "Epoch: [34] [ 120/ 548] time: 523.0667, train_loss: 0.05326080, val_loss: -34.48225403\n",
      "Epoch: [34] [ 130/ 548] time: 523.3110, train_loss: -37.08882904, val_loss: -33.39465332\n",
      "Epoch: [34] [ 140/ 548] time: 523.5542, train_loss: -26.51682472, val_loss: -33.19400787\n",
      "Epoch: [34] [ 150/ 548] time: 523.8005, train_loss: -41.55216217, val_loss: -33.20026398\n",
      "Epoch: [34] [ 160/ 548] time: 524.0490, train_loss: -32.22980881, val_loss: -34.45363617\n",
      "Epoch: [34] [ 170/ 548] time: 524.2872, train_loss: -30.87940025, val_loss: -34.40132523\n",
      "Epoch: [34] [ 180/ 548] time: 524.5239, train_loss: -33.02535248, val_loss: -33.69246674\n",
      "Epoch: [34] [ 190/ 548] time: 524.7675, train_loss: -34.25447845, val_loss: -32.92084885\n",
      "Epoch: [34] [ 200/ 548] time: 525.0080, train_loss: -41.31988144, val_loss: -33.73388290\n",
      "Epoch: [34] [ 210/ 548] time: 525.2440, train_loss: -26.17956161, val_loss: -31.05756187\n",
      "Epoch: [34] [ 220/ 548] time: 525.4814, train_loss: -1.04747391, val_loss: -29.82712746\n",
      "Epoch: [34] [ 230/ 548] time: 525.7279, train_loss: -3.09042740, val_loss: -30.57421684\n",
      "Epoch: [34] [ 240/ 548] time: 525.9786, train_loss: -21.26213264, val_loss: -31.83784485\n",
      "Epoch: [34] [ 250/ 548] time: 526.2178, train_loss: -37.40562439, val_loss: -32.81022644\n",
      "Epoch: [34] [ 260/ 548] time: 526.4544, train_loss: -35.63546371, val_loss: -30.01895332\n",
      "Epoch: [34] [ 270/ 548] time: 526.7157, train_loss: -13.45658875, val_loss: -29.67134094\n",
      "Epoch: [34] [ 280/ 548] time: 526.9780, train_loss: -32.60850906, val_loss: -30.28840637\n",
      "Epoch: [34] [ 290/ 548] time: 527.2468, train_loss: -33.54548264, val_loss: -30.90364265\n",
      "Epoch: [34] [ 300/ 548] time: 527.5223, train_loss: -7.46537781, val_loss: -33.21642303\n",
      "Epoch: [34] [ 310/ 548] time: 527.7730, train_loss: -31.35280037, val_loss: -32.10294724\n",
      "Epoch: [34] [ 320/ 548] time: 528.0184, train_loss: -33.70875549, val_loss: -31.30171585\n",
      "Epoch: [34] [ 330/ 548] time: 528.2603, train_loss: -37.06747437, val_loss: -29.65549469\n",
      "Epoch: [34] [ 340/ 548] time: 528.5035, train_loss: -29.04096985, val_loss: -32.78376007\n",
      "Epoch: [34] [ 350/ 548] time: 528.7500, train_loss: -33.63098907, val_loss: -31.59034157\n",
      "Epoch: [34] [ 360/ 548] time: 528.9849, train_loss: -37.81635284, val_loss: -32.20894623\n",
      "Saving checkpoint\n",
      "Epoch: [34] [ 370/ 548] time: 530.2763, train_loss: -36.98320389, val_loss: -33.08168030\n",
      "Epoch: [34] [ 380/ 548] time: 530.5305, train_loss: -33.73749924, val_loss: -33.03731537\n",
      "Epoch: [34] [ 390/ 548] time: 530.7806, train_loss: -35.12094498, val_loss: -34.29891205\n",
      "Epoch: [34] [ 400/ 548] time: 531.0239, train_loss: -32.29582214, val_loss: -32.97083282\n",
      "Epoch: [34] [ 410/ 548] time: 531.2573, train_loss: -42.28542328, val_loss: -34.14183807\n",
      "Epoch: [34] [ 420/ 548] time: 531.4882, train_loss: -28.37508583, val_loss: -30.87994003\n",
      "Epoch: [34] [ 430/ 548] time: 531.7262, train_loss: 226.16464233, val_loss: -30.19056702\n",
      "Epoch: [34] [ 440/ 548] time: 531.9818, train_loss: -37.62358093, val_loss: -31.65281868\n",
      "Epoch: [34] [ 450/ 548] time: 532.2667, train_loss: -29.29780960, val_loss: -32.05392075\n",
      "Epoch: [34] [ 460/ 548] time: 532.5291, train_loss: -32.35359192, val_loss: -32.93615723\n",
      "Epoch: [34] [ 470/ 548] time: 532.8157, train_loss: -25.88616562, val_loss: -33.52035904\n",
      "Epoch: [34] [ 480/ 548] time: 533.0915, train_loss: -34.94721222, val_loss: -34.08621216\n",
      "Epoch: [34] [ 490/ 548] time: 533.3802, train_loss: -36.50650406, val_loss: -34.60981369\n",
      "Epoch: [34] [ 500/ 548] time: 533.6514, train_loss: -32.62363434, val_loss: -34.09569550\n",
      "Epoch: [34] [ 510/ 548] time: 533.9099, train_loss: 7.22483063, val_loss: -35.22106171\n",
      "Epoch: [34] [ 520/ 548] time: 534.1603, train_loss: 41.52514648, val_loss: -33.34632111\n",
      "Epoch: [34] [ 530/ 548] time: 534.4272, train_loss: -15.97428894, val_loss: -34.73186493\n",
      "Epoch: [34] [ 540/ 548] time: 534.6911, train_loss: -36.62774277, val_loss: -35.32490158\n",
      "Epoch: [35] [   0/ 548] time: 534.9096, train_loss: 4.96355820, val_loss: -35.94561386\n",
      "Epoch: [35] [  10/ 548] time: 535.1645, train_loss: -28.37581253, val_loss: -34.40085602\n",
      "Epoch: [35] [  20/ 548] time: 535.4182, train_loss: -41.38384247, val_loss: -35.79824066\n",
      "Epoch: [35] [  30/ 548] time: 535.6642, train_loss: -41.19997406, val_loss: -35.33707428\n",
      "Epoch: [35] [  40/ 548] time: 535.9288, train_loss: -39.26942825, val_loss: -33.21210480\n",
      "Epoch: [35] [  50/ 548] time: 536.1789, train_loss: 181.81764221, val_loss: -33.15445328\n",
      "Epoch: [35] [  60/ 548] time: 536.4373, train_loss: -32.63040161, val_loss: -33.93106079\n",
      "Epoch: [35] [  70/ 548] time: 536.6911, train_loss: -39.93199921, val_loss: -34.23407745\n",
      "Epoch: [35] [  80/ 548] time: 536.9420, train_loss: -33.51644897, val_loss: -35.32142639\n",
      "Epoch: [35] [  90/ 548] time: 537.1986, train_loss: -43.04952621, val_loss: -35.82934952\n",
      "Epoch: [35] [ 100/ 548] time: 537.4444, train_loss: -19.72820473, val_loss: -36.31344223\n",
      "Epoch: [35] [ 110/ 548] time: 537.6944, train_loss: -0.86145401, val_loss: -36.40142059\n",
      "Epoch: [35] [ 120/ 548] time: 537.9367, train_loss: -39.45497131, val_loss: -35.90519714\n",
      "Epoch: [35] [ 130/ 548] time: 538.1832, train_loss: -33.87081528, val_loss: -33.62765884\n",
      "Epoch: [35] [ 140/ 548] time: 538.4330, train_loss: -33.43367004, val_loss: -32.97980118\n",
      "Epoch: [35] [ 150/ 548] time: 538.6908, train_loss: -25.02840042, val_loss: -34.86495209\n",
      "Epoch: [35] [ 160/ 548] time: 538.9567, train_loss: -28.89163399, val_loss: -35.06889343\n",
      "Epoch: [35] [ 170/ 548] time: 539.2194, train_loss: 38.03643036, val_loss: -35.23717117\n",
      "Epoch: [35] [ 180/ 548] time: 539.4796, train_loss: -35.57320023, val_loss: -36.01215363\n",
      "Epoch: [35] [ 190/ 548] time: 539.7327, train_loss: -39.17449188, val_loss: -35.48233032\n",
      "Epoch: [35] [ 200/ 548] time: 539.9703, train_loss: -23.47152710, val_loss: -35.55171967\n",
      "Epoch: [35] [ 210/ 548] time: 540.2100, train_loss: -38.16640472, val_loss: -37.56876373\n",
      "Epoch: [35] [ 220/ 548] time: 540.4427, train_loss: -40.31098175, val_loss: -35.96592331\n",
      "Epoch: [35] [ 230/ 548] time: 540.6739, train_loss: -39.95765686, val_loss: -35.13340759\n",
      "Epoch: [35] [ 240/ 548] time: 540.9254, train_loss: -35.55935669, val_loss: -35.74571228\n",
      "Epoch: [35] [ 250/ 548] time: 541.1779, train_loss: -33.07901001, val_loss: -35.68565750\n",
      "Epoch: [35] [ 260/ 548] time: 541.4256, train_loss: -41.48567963, val_loss: -36.95741272\n",
      "Epoch: [35] [ 270/ 548] time: 541.6778, train_loss: -8.14751434, val_loss: -36.36391068\n",
      "Epoch: [35] [ 280/ 548] time: 541.9348, train_loss: -41.01034164, val_loss: -36.27676773\n",
      "Epoch: [35] [ 290/ 548] time: 542.2276, train_loss: -42.41396332, val_loss: -35.83937454\n",
      "Epoch: [35] [ 300/ 548] time: 542.4733, train_loss: -39.87746429, val_loss: -35.58056641\n",
      "Epoch: [35] [ 310/ 548] time: 542.7215, train_loss: -33.83283234, val_loss: -36.30261230\n",
      "Epoch: [35] [ 320/ 548] time: 542.9603, train_loss: -32.48624420, val_loss: -34.69037628\n",
      "Epoch: [35] [ 330/ 548] time: 543.2117, train_loss: -37.48377609, val_loss: -30.54510498\n",
      "Epoch: [35] [ 340/ 548] time: 543.4561, train_loss: -42.07568359, val_loss: -32.52458191\n",
      "Epoch: [35] [ 350/ 548] time: 543.7035, train_loss: -40.37714767, val_loss: -32.31211090\n",
      "Epoch: [35] [ 360/ 548] time: 543.9426, train_loss: -41.66780853, val_loss: -33.01840973\n",
      "Epoch: [35] [ 370/ 548] time: 544.1973, train_loss: -42.19282532, val_loss: -34.27668762\n",
      "Epoch: [35] [ 380/ 548] time: 544.4449, train_loss: -20.35560608, val_loss: -35.67797852\n",
      "Epoch: [35] [ 390/ 548] time: 544.7025, train_loss: -38.23479843, val_loss: -35.53033447\n",
      "Epoch: [35] [ 400/ 548] time: 544.9996, train_loss: -40.20998001, val_loss: -36.52564621\n",
      "Epoch: [35] [ 410/ 548] time: 545.3053, train_loss: -39.70394897, val_loss: -35.63295364\n",
      "Epoch: [35] [ 420/ 548] time: 545.6449, train_loss: -28.09902000, val_loss: -35.74681854\n",
      "Epoch: [35] [ 430/ 548] time: 545.9686, train_loss: -13.38507462, val_loss: -35.51560211\n",
      "Epoch: [35] [ 440/ 548] time: 546.2670, train_loss: -39.33819199, val_loss: -36.15574646\n",
      "Epoch: [35] [ 450/ 548] time: 546.5761, train_loss: -35.19293976, val_loss: -36.60276031\n",
      "Epoch: [35] [ 460/ 548] time: 546.9538, train_loss: 20.57766724, val_loss: -35.96246719\n",
      "Epoch: [35] [ 470/ 548] time: 547.3062, train_loss: -38.29747772, val_loss: -35.71283340\n",
      "Epoch: [35] [ 480/ 548] time: 547.6369, train_loss: -36.68130112, val_loss: -35.03634644\n",
      "Epoch: [35] [ 490/ 548] time: 547.9626, train_loss: -31.20694733, val_loss: -35.68667603\n",
      "Epoch: [35] [ 500/ 548] time: 548.3018, train_loss: -2.18144608, val_loss: -35.38354874\n",
      "Epoch: [35] [ 510/ 548] time: 548.6257, train_loss: -30.42041969, val_loss: -37.15720367\n",
      "Epoch: [35] [ 520/ 548] time: 548.9612, train_loss: -33.74937439, val_loss: -35.80004501\n",
      "Epoch: [35] [ 530/ 548] time: 549.2450, train_loss: -20.44399643, val_loss: -37.21006393\n",
      "Epoch: [35] [ 540/ 548] time: 549.5737, train_loss: -38.65370560, val_loss: -35.12297058\n",
      "Epoch: [36] [   0/ 548] time: 549.7925, train_loss: -43.49480820, val_loss: -34.25967789\n",
      "Epoch: [36] [  10/ 548] time: 550.0855, train_loss: -36.04817963, val_loss: -34.68690872\n",
      "Epoch: [36] [  20/ 548] time: 550.3720, train_loss: -35.79795837, val_loss: -36.00324631\n",
      "Epoch: [36] [  30/ 548] time: 550.7019, train_loss: -38.97018433, val_loss: -35.42050171\n",
      "Epoch: [36] [  40/ 548] time: 550.9984, train_loss: -6.14530563, val_loss: -34.84271240\n",
      "Epoch: [36] [  50/ 548] time: 551.2711, train_loss: -39.75172806, val_loss: -34.49380493\n",
      "Epoch: [36] [  60/ 548] time: 551.5725, train_loss: -36.90303040, val_loss: -35.91278076\n",
      "Epoch: [36] [  70/ 548] time: 551.8894, train_loss: -38.00580978, val_loss: -36.00627518\n",
      "Epoch: [36] [  80/ 548] time: 552.1685, train_loss: -43.74921417, val_loss: -36.43809891\n",
      "Epoch: [36] [  90/ 548] time: 552.4119, train_loss: 6.81788635, val_loss: -36.35414505\n",
      "Epoch: [36] [ 100/ 548] time: 552.6556, train_loss: -43.73232269, val_loss: -36.45322418\n",
      "Epoch: [36] [ 110/ 548] time: 552.8947, train_loss: -29.68902588, val_loss: -36.33361435\n",
      "Epoch: [36] [ 120/ 548] time: 553.1285, train_loss: -32.81496811, val_loss: -35.71755981\n",
      "Epoch: [36] [ 130/ 548] time: 553.3660, train_loss: -31.05243301, val_loss: -36.08217621\n",
      "Epoch: [36] [ 140/ 548] time: 553.6067, train_loss: -41.31396103, val_loss: -33.44430542\n",
      "Epoch: [36] [ 150/ 548] time: 553.8408, train_loss: -15.86202240, val_loss: -34.94782257\n",
      "Epoch: [36] [ 160/ 548] time: 554.0704, train_loss: -41.42575455, val_loss: -36.62643051\n",
      "Epoch: [36] [ 170/ 548] time: 554.3079, train_loss: -31.71287918, val_loss: -30.88809204\n",
      "Epoch: [36] [ 180/ 548] time: 554.5465, train_loss: -29.22705841, val_loss: -32.11644745\n",
      "Epoch: [36] [ 190/ 548] time: 554.7930, train_loss: -41.42218781, val_loss: -33.27450943\n",
      "Epoch: [36] [ 200/ 548] time: 555.0312, train_loss: -41.16424561, val_loss: -33.02581406\n",
      "Epoch: [36] [ 210/ 548] time: 555.2679, train_loss: -19.98033524, val_loss: -33.92081833\n",
      "Epoch: [36] [ 220/ 548] time: 555.5018, train_loss: -42.32234192, val_loss: -35.06126404\n",
      "Epoch: [36] [ 230/ 548] time: 555.7413, train_loss: -36.96984482, val_loss: -36.78339767\n",
      "Epoch: [36] [ 240/ 548] time: 555.9896, train_loss: -36.30535507, val_loss: -36.96271515\n",
      "Epoch: [36] [ 250/ 548] time: 556.2358, train_loss: -33.10581207, val_loss: -36.41828537\n",
      "Epoch: [36] [ 260/ 548] time: 556.4734, train_loss: -34.20542145, val_loss: -36.47571182\n",
      "Epoch: [36] [ 270/ 548] time: 556.7089, train_loss: 35.82749176, val_loss: -36.76168442\n",
      "Saving checkpoint\n",
      "Epoch: [36] [ 280/ 548] time: 557.9602, train_loss: -39.65677643, val_loss: -37.31457901\n",
      "Epoch: [36] [ 290/ 548] time: 558.2016, train_loss: -32.52982712, val_loss: -37.89963531\n",
      "Epoch: [36] [ 300/ 548] time: 558.4370, train_loss: -34.23987579, val_loss: -37.65716171\n",
      "Epoch: [36] [ 310/ 548] time: 558.6620, train_loss: -19.04120636, val_loss: -38.06662369\n",
      "Epoch: [36] [ 320/ 548] time: 558.8908, train_loss: -36.27769089, val_loss: -36.89653778\n",
      "Epoch: [36] [ 330/ 548] time: 559.1169, train_loss: -37.53915787, val_loss: -36.11584473\n",
      "Epoch: [36] [ 340/ 548] time: 559.3445, train_loss: -35.66472244, val_loss: -36.06013870\n",
      "Epoch: [36] [ 350/ 548] time: 559.5697, train_loss: -33.91735458, val_loss: -36.89356613\n",
      "Epoch: [36] [ 360/ 548] time: 559.8000, train_loss: 30.19642639, val_loss: -33.62032318\n",
      "Epoch: [36] [ 370/ 548] time: 560.0336, train_loss: -14.96017075, val_loss: -31.67996788\n",
      "Epoch: [36] [ 380/ 548] time: 560.2710, train_loss: -20.09066963, val_loss: -33.95066071\n",
      "Epoch: [36] [ 390/ 548] time: 560.5053, train_loss: -19.88327599, val_loss: -33.64076996\n",
      "Epoch: [36] [ 400/ 548] time: 560.7438, train_loss: -3.30052567, val_loss: -33.17581177\n",
      "Epoch: [36] [ 410/ 548] time: 561.0133, train_loss: -35.86831665, val_loss: -31.71523094\n",
      "Epoch: [36] [ 420/ 548] time: 561.2609, train_loss: -41.49302673, val_loss: -35.38731003\n",
      "Epoch: [36] [ 430/ 548] time: 561.5040, train_loss: -29.98322296, val_loss: -35.81458282\n",
      "Epoch: [36] [ 440/ 548] time: 561.7441, train_loss: -41.42679596, val_loss: -37.14866257\n",
      "Epoch: [36] [ 450/ 548] time: 561.9889, train_loss: -45.36260223, val_loss: -37.61428070\n",
      "Epoch: [36] [ 460/ 548] time: 562.2344, train_loss: -28.37110329, val_loss: -37.52510834\n",
      "Epoch: [36] [ 470/ 548] time: 562.4780, train_loss: -40.00114441, val_loss: -36.79311371\n",
      "Epoch: [36] [ 480/ 548] time: 562.7204, train_loss: -37.29866791, val_loss: -35.82922745\n",
      "Epoch: [36] [ 490/ 548] time: 562.9884, train_loss: -18.08629990, val_loss: -35.38858414\n",
      "Epoch: [36] [ 500/ 548] time: 563.2572, train_loss: -41.17082977, val_loss: -36.66432190\n",
      "Epoch: [36] [ 510/ 548] time: 563.5254, train_loss: -40.75945282, val_loss: -37.27486038\n",
      "Epoch: [36] [ 520/ 548] time: 563.7760, train_loss: -38.07516479, val_loss: -35.23628616\n",
      "Epoch: [36] [ 530/ 548] time: 564.0246, train_loss: -41.81379318, val_loss: -36.89782333\n",
      "Epoch: [36] [ 540/ 548] time: 564.2637, train_loss: -37.01143265, val_loss: -37.96418381\n",
      "Epoch: [37] [   0/ 548] time: 564.4508, train_loss: -35.64581680, val_loss: -38.61673355\n",
      "Epoch: [37] [  10/ 548] time: 564.6876, train_loss: -37.81043243, val_loss: -36.54887772\n",
      "Epoch: [37] [  20/ 548] time: 564.9326, train_loss: -13.47484970, val_loss: -36.64754105\n",
      "Epoch: [37] [  30/ 548] time: 565.1756, train_loss: -32.94124222, val_loss: -35.11266327\n",
      "Epoch: [37] [  40/ 548] time: 565.4161, train_loss: -43.33472061, val_loss: -37.03366089\n",
      "Epoch: [37] [  50/ 548] time: 565.6618, train_loss: -39.41532135, val_loss: -37.92465591\n",
      "Epoch: [37] [  60/ 548] time: 565.9115, train_loss: -34.94116211, val_loss: -37.94629288\n",
      "Epoch: [37] [  70/ 548] time: 566.1716, train_loss: -36.18156052, val_loss: -37.94131470\n",
      "Epoch: [37] [  80/ 548] time: 566.4187, train_loss: -43.60386658, val_loss: -37.32875061\n",
      "Epoch: [37] [  90/ 548] time: 566.6587, train_loss: 32.92449188, val_loss: -38.21566391\n",
      "Epoch: [37] [ 100/ 548] time: 566.8955, train_loss: -36.70632172, val_loss: -34.81667709\n",
      "Epoch: [37] [ 110/ 548] time: 567.1360, train_loss: -19.34013748, val_loss: -37.34968948\n",
      "Epoch: [37] [ 120/ 548] time: 567.3720, train_loss: -43.39966965, val_loss: -37.99362183\n",
      "Epoch: [37] [ 130/ 548] time: 567.6158, train_loss: -43.49163055, val_loss: -38.38060760\n",
      "Epoch: [37] [ 140/ 548] time: 567.8586, train_loss: -40.94159698, val_loss: -39.34777069\n",
      "Epoch: [37] [ 150/ 548] time: 568.1051, train_loss: -43.71587372, val_loss: -38.45115662\n",
      "Epoch: [37] [ 160/ 548] time: 568.3483, train_loss: -42.04590988, val_loss: -38.49923706\n",
      "Epoch: [37] [ 170/ 548] time: 568.5877, train_loss: -32.44499969, val_loss: -39.67952347\n",
      "Epoch: [37] [ 180/ 548] time: 568.8530, train_loss: -30.94563675, val_loss: -39.89841080\n",
      "Epoch: [37] [ 190/ 548] time: 569.1227, train_loss: -32.87631226, val_loss: -40.10810852\n",
      "Epoch: [37] [ 200/ 548] time: 569.3948, train_loss: -45.06229782, val_loss: -39.35107422\n",
      "Epoch: [37] [ 210/ 548] time: 569.6652, train_loss: -7.39069748, val_loss: -38.51978302\n",
      "Epoch: [37] [ 220/ 548] time: 569.9116, train_loss: -18.42885971, val_loss: -38.04171753\n",
      "Epoch: [37] [ 230/ 548] time: 570.1484, train_loss: -36.95134735, val_loss: -39.26452255\n",
      "Epoch: [37] [ 240/ 548] time: 570.3840, train_loss: -39.97234344, val_loss: -39.21966934\n",
      "Epoch: [37] [ 250/ 548] time: 570.6164, train_loss: -42.90499878, val_loss: -39.74352264\n",
      "Epoch: [37] [ 260/ 548] time: 570.8500, train_loss: -38.21456146, val_loss: -39.70638275\n",
      "Epoch: [37] [ 270/ 548] time: 571.0993, train_loss: -39.48339462, val_loss: -40.05090714\n",
      "Epoch: [37] [ 280/ 548] time: 571.3388, train_loss: -44.48052979, val_loss: -39.52257156\n",
      "Epoch: [37] [ 290/ 548] time: 571.6074, train_loss: -25.64594841, val_loss: -39.21191406\n",
      "Epoch: [37] [ 300/ 548] time: 571.8638, train_loss: -42.16503525, val_loss: -39.89170456\n",
      "Epoch: [37] [ 310/ 548] time: 572.1057, train_loss: -40.76517487, val_loss: -38.56363297\n",
      "Epoch: [37] [ 320/ 548] time: 572.3884, train_loss: -30.41495132, val_loss: -39.57841110\n",
      "Epoch: [37] [ 330/ 548] time: 572.6344, train_loss: -35.78792572, val_loss: -39.02044296\n",
      "Epoch: [37] [ 340/ 548] time: 572.8821, train_loss: -33.71720886, val_loss: -39.42936325\n",
      "Epoch: [37] [ 350/ 548] time: 573.1306, train_loss: -45.93746567, val_loss: -36.16513062\n",
      "Epoch: [37] [ 360/ 548] time: 573.3679, train_loss: -38.75657654, val_loss: -35.83291626\n",
      "Epoch: [37] [ 370/ 548] time: 573.6093, train_loss: -39.28998566, val_loss: -35.70443726\n",
      "Epoch: [37] [ 380/ 548] time: 573.8515, train_loss: -38.37261963, val_loss: -36.23230362\n",
      "Epoch: [37] [ 390/ 548] time: 574.0890, train_loss: -42.19580078, val_loss: -35.75579071\n",
      "Epoch: [37] [ 400/ 548] time: 574.3265, train_loss: -36.28398514, val_loss: -37.12873077\n",
      "Epoch: [37] [ 410/ 548] time: 574.5617, train_loss: -8.21476746, val_loss: -38.30617142\n",
      "Epoch: [37] [ 420/ 548] time: 574.8069, train_loss: -43.11820221, val_loss: -38.48322296\n",
      "Epoch: [37] [ 430/ 548] time: 575.0616, train_loss: 95.49755859, val_loss: -38.79796600\n",
      "Epoch: [37] [ 440/ 548] time: 575.3372, train_loss: -41.20143890, val_loss: -38.65700912\n",
      "Epoch: [37] [ 450/ 548] time: 575.6294, train_loss: -43.21493530, val_loss: -38.58956146\n",
      "Epoch: [37] [ 460/ 548] time: 575.9042, train_loss: -24.85375214, val_loss: -38.55914688\n",
      "Epoch: [37] [ 470/ 548] time: 576.1733, train_loss: -34.04451370, val_loss: -37.97112274\n",
      "Epoch: [37] [ 480/ 548] time: 576.4129, train_loss: -27.78459549, val_loss: -39.14212036\n",
      "Epoch: [37] [ 490/ 548] time: 576.6581, train_loss: -41.36511993, val_loss: -39.51880646\n",
      "Epoch: [37] [ 500/ 548] time: 576.9117, train_loss: -34.39843369, val_loss: -39.35699463\n",
      "Epoch: [37] [ 510/ 548] time: 577.1622, train_loss: -19.38837433, val_loss: -37.12779617\n",
      "Epoch: [37] [ 520/ 548] time: 577.4091, train_loss: -29.80590630, val_loss: -38.26886749\n",
      "Epoch: [37] [ 530/ 548] time: 577.6493, train_loss: -26.95210075, val_loss: -38.93546295\n",
      "Epoch: [37] [ 540/ 548] time: 577.8834, train_loss: -32.36810684, val_loss: -39.42826080\n",
      "Epoch: [38] [   0/ 548] time: 578.0717, train_loss: -34.93311310, val_loss: -39.06015015\n",
      "Epoch: [38] [  10/ 548] time: 578.3125, train_loss: -41.56751251, val_loss: -39.60810471\n",
      "Epoch: [38] [  20/ 548] time: 578.5543, train_loss: -28.81743813, val_loss: -38.54287720\n",
      "Epoch: [38] [  30/ 548] time: 578.7869, train_loss: -22.88246155, val_loss: -38.28861618\n",
      "Epoch: [38] [  40/ 548] time: 579.0221, train_loss: -36.80724335, val_loss: -39.48075867\n",
      "Epoch: [38] [  50/ 548] time: 579.2597, train_loss: -38.48343277, val_loss: -39.15685272\n",
      "Epoch: [38] [  60/ 548] time: 579.4953, train_loss: -9.39109039, val_loss: -39.58783340\n",
      "Epoch: [38] [  70/ 548] time: 579.7336, train_loss: -43.60223770, val_loss: -39.79484177\n",
      "Epoch: [38] [  80/ 548] time: 579.9771, train_loss: -36.07386017, val_loss: -38.03017807\n",
      "Epoch: [38] [  90/ 548] time: 580.2172, train_loss: -29.96865082, val_loss: -35.25314331\n",
      "Epoch: [38] [ 100/ 548] time: 580.4480, train_loss: -39.26064682, val_loss: -39.37150955\n",
      "Epoch: [38] [ 110/ 548] time: 580.6869, train_loss: -37.65370941, val_loss: -39.01248169\n",
      "Epoch: [38] [ 120/ 548] time: 580.9269, train_loss: -42.60190582, val_loss: -38.72719574\n",
      "Epoch: [38] [ 130/ 548] time: 581.2027, train_loss: -39.90972137, val_loss: -40.18630219\n",
      "Epoch: [38] [ 140/ 548] time: 581.4782, train_loss: -41.70216370, val_loss: -40.21948624\n",
      "Epoch: [38] [ 150/ 548] time: 581.7423, train_loss: -42.29705811, val_loss: -40.46487427\n",
      "Epoch: [38] [ 160/ 548] time: 582.0140, train_loss: -22.78892517, val_loss: -39.81704712\n",
      "Epoch: [38] [ 170/ 548] time: 582.2571, train_loss: -36.51361465, val_loss: -38.95330048\n",
      "Saving checkpoint\n",
      "Epoch: [38] [ 180/ 548] time: 583.5460, train_loss: -39.08650970, val_loss: -40.25547028\n",
      "Epoch: [38] [ 190/ 548] time: 583.7995, train_loss: -29.03117752, val_loss: -41.30946350\n",
      "Epoch: [38] [ 200/ 548] time: 584.0393, train_loss: -39.94123459, val_loss: -40.33333588\n",
      "Epoch: [38] [ 210/ 548] time: 584.2602, train_loss: -35.99353790, val_loss: -40.80496216\n",
      "Epoch: [38] [ 220/ 548] time: 584.4846, train_loss: -44.62564087, val_loss: -38.02577591\n",
      "Epoch: [38] [ 230/ 548] time: 584.7086, train_loss: -38.23733902, val_loss: -38.70938873\n",
      "Epoch: [38] [ 240/ 548] time: 584.9332, train_loss: -30.19763565, val_loss: -40.37224960\n",
      "Epoch: [38] [ 250/ 548] time: 585.1652, train_loss: -42.55239868, val_loss: -40.57109070\n",
      "Epoch: [38] [ 260/ 548] time: 585.3904, train_loss: -35.99859619, val_loss: -38.43207550\n",
      "Epoch: [38] [ 270/ 548] time: 585.6134, train_loss: -18.60623550, val_loss: -40.60124207\n",
      "Epoch: [38] [ 280/ 548] time: 585.8461, train_loss: -23.38619041, val_loss: -40.90135193\n",
      "Epoch: [38] [ 290/ 548] time: 586.0980, train_loss: -47.37022781, val_loss: -40.83791351\n",
      "Epoch: [38] [ 300/ 548] time: 586.3322, train_loss: -36.88285828, val_loss: -40.63552094\n",
      "Epoch: [38] [ 310/ 548] time: 586.5793, train_loss: -42.52677917, val_loss: -41.84333038\n",
      "Epoch: [38] [ 320/ 548] time: 586.8184, train_loss: -40.07217407, val_loss: -41.59364319\n",
      "Epoch: [38] [ 330/ 548] time: 587.0710, train_loss: -33.85314178, val_loss: -41.08978271\n",
      "Epoch: [38] [ 340/ 548] time: 587.3480, train_loss: -42.47253418, val_loss: -42.16567230\n",
      "Epoch: [38] [ 350/ 548] time: 587.6157, train_loss: -42.84664917, val_loss: -42.56714249\n",
      "Epoch: [38] [ 360/ 548] time: 587.9022, train_loss: -46.57148361, val_loss: -41.77540588\n",
      "Epoch: [38] [ 370/ 548] time: 588.1543, train_loss: -28.88752174, val_loss: -42.02670670\n",
      "Epoch: [38] [ 380/ 548] time: 588.4098, train_loss: -40.85645294, val_loss: -41.52734375\n",
      "Epoch: [38] [ 390/ 548] time: 588.6517, train_loss: -32.97612000, val_loss: -42.43759155\n",
      "Epoch: [38] [ 400/ 548] time: 588.8912, train_loss: 78.99957275, val_loss: -42.35099792\n",
      "Epoch: [38] [ 410/ 548] time: 589.1296, train_loss: -33.86436462, val_loss: -42.15000153\n",
      "Epoch: [38] [ 420/ 548] time: 589.3649, train_loss: -41.05913162, val_loss: -41.37284088\n",
      "Epoch: [38] [ 430/ 548] time: 589.5961, train_loss: -39.91592789, val_loss: -40.86758804\n",
      "Epoch: [38] [ 440/ 548] time: 589.8286, train_loss: -39.99976349, val_loss: -41.42909622\n",
      "Epoch: [38] [ 450/ 548] time: 590.0714, train_loss: -43.88648987, val_loss: -41.08184052\n",
      "Epoch: [38] [ 460/ 548] time: 590.3183, train_loss: -39.81122208, val_loss: -40.81091309\n",
      "Epoch: [38] [ 470/ 548] time: 590.5574, train_loss: -19.82246017, val_loss: -41.14327621\n",
      "Epoch: [38] [ 480/ 548] time: 590.7988, train_loss: -45.17112732, val_loss: -40.67666626\n",
      "Epoch: [38] [ 490/ 548] time: 591.0476, train_loss: -24.62891006, val_loss: -39.43235397\n",
      "Epoch: [38] [ 500/ 548] time: 591.2861, train_loss: -34.62149048, val_loss: -39.06995773\n",
      "Epoch: [38] [ 510/ 548] time: 591.5241, train_loss: -33.81245041, val_loss: -38.28724289\n",
      "Epoch: [38] [ 520/ 548] time: 591.7563, train_loss: -39.58749008, val_loss: -39.85738373\n",
      "Epoch: [38] [ 530/ 548] time: 591.9929, train_loss: -31.76776314, val_loss: -38.74620056\n",
      "Epoch: [38] [ 540/ 548] time: 592.2415, train_loss: -42.53011703, val_loss: -37.80749512\n",
      "Epoch: [39] [   0/ 548] time: 592.4360, train_loss: -44.18744659, val_loss: -37.62842941\n",
      "Epoch: [39] [  10/ 548] time: 592.6780, train_loss: -46.11755371, val_loss: -39.06040192\n",
      "Epoch: [39] [  20/ 548] time: 592.9271, train_loss: -29.28023529, val_loss: -39.27156448\n",
      "Epoch: [39] [  30/ 548] time: 593.1974, train_loss: -30.94332123, val_loss: -39.45202255\n",
      "Epoch: [39] [  40/ 548] time: 593.4690, train_loss: -46.76153183, val_loss: -38.85150146\n",
      "Epoch: [39] [  50/ 548] time: 593.7425, train_loss: -44.26692963, val_loss: -39.18498993\n",
      "Epoch: [39] [  60/ 548] time: 594.0135, train_loss: -46.31538773, val_loss: -39.79172516\n",
      "Epoch: [39] [  70/ 548] time: 594.2529, train_loss: -34.74391174, val_loss: -39.57447433\n",
      "Epoch: [39] [  80/ 548] time: 594.4961, train_loss: -38.27524185, val_loss: -39.78060150\n",
      "Epoch: [39] [  90/ 548] time: 594.7317, train_loss: -16.28252029, val_loss: -39.26748657\n",
      "Epoch: [39] [ 100/ 548] time: 594.9656, train_loss: -42.01852417, val_loss: -40.42445374\n",
      "Epoch: [39] [ 110/ 548] time: 595.1996, train_loss: -20.24239349, val_loss: -42.14325714\n",
      "Epoch: [39] [ 120/ 548] time: 595.4454, train_loss: -40.36737061, val_loss: -41.55064774\n",
      "Epoch: [39] [ 130/ 548] time: 595.6836, train_loss: -48.88167953, val_loss: -41.67366791\n",
      "Epoch: [39] [ 140/ 548] time: 595.9263, train_loss: -35.90717316, val_loss: -41.24748993\n",
      "Epoch: [39] [ 150/ 548] time: 596.1783, train_loss: -42.53491211, val_loss: -41.22544098\n",
      "Epoch: [39] [ 160/ 548] time: 596.4159, train_loss: -39.14954758, val_loss: -40.94634247\n",
      "Epoch: [39] [ 170/ 548] time: 596.6586, train_loss: -14.91637039, val_loss: -40.48477173\n",
      "Epoch: [39] [ 180/ 548] time: 596.8939, train_loss: -37.57188416, val_loss: -40.78847122\n",
      "Epoch: [39] [ 190/ 548] time: 597.1259, train_loss: -31.19974136, val_loss: -42.09436035\n",
      "Epoch: [39] [ 200/ 548] time: 597.3604, train_loss: -35.34831238, val_loss: -42.63441467\n",
      "Epoch: [39] [ 210/ 548] time: 597.5893, train_loss: -38.04679108, val_loss: -41.32129288\n",
      "Epoch: [39] [ 220/ 548] time: 597.8232, train_loss: -21.13778687, val_loss: -41.85205078\n",
      "Epoch: [39] [ 230/ 548] time: 598.0589, train_loss: -49.35391617, val_loss: -41.66565323\n",
      "Epoch: [39] [ 240/ 548] time: 598.2907, train_loss: -38.18051910, val_loss: -40.64093399\n",
      "Epoch: [39] [ 250/ 548] time: 598.5422, train_loss: -45.61283493, val_loss: -42.24684906\n",
      "Epoch: [39] [ 260/ 548] time: 598.8057, train_loss: -34.91268539, val_loss: -42.31324387\n",
      "Epoch: [39] [ 270/ 548] time: 599.0775, train_loss: -35.00032043, val_loss: -41.66057587\n",
      "Epoch: [39] [ 280/ 548] time: 599.3467, train_loss: -22.29997635, val_loss: -42.22187424\n",
      "Epoch: [39] [ 290/ 548] time: 599.6572, train_loss: -46.80554199, val_loss: -41.44883728\n",
      "Epoch: [39] [ 300/ 548] time: 599.9623, train_loss: 82.73120117, val_loss: -42.17453003\n",
      "Epoch: [39] [ 310/ 548] time: 600.2520, train_loss: -33.58994675, val_loss: -41.31938553\n",
      "Epoch: [39] [ 320/ 548] time: 600.5550, train_loss: -43.56576157, val_loss: -41.02139282\n",
      "Epoch: [39] [ 330/ 548] time: 600.9316, train_loss: -38.61844635, val_loss: -39.77893066\n",
      "Epoch: [39] [ 340/ 548] time: 601.3017, train_loss: -44.88586044, val_loss: -39.87272263\n",
      "Epoch: [39] [ 350/ 548] time: 601.6195, train_loss: -38.33606720, val_loss: -42.28537369\n",
      "Epoch: [39] [ 360/ 548] time: 601.9572, train_loss: -45.72243118, val_loss: -40.41184235\n",
      "Epoch: [39] [ 370/ 548] time: 602.3389, train_loss: -42.51018524, val_loss: -40.18791962\n",
      "Epoch: [39] [ 380/ 548] time: 602.6816, train_loss: -42.33304596, val_loss: -38.85351944\n",
      "Epoch: [39] [ 390/ 548] time: 603.0073, train_loss: -39.39917755, val_loss: -40.84282303\n",
      "Epoch: [39] [ 400/ 548] time: 603.3265, train_loss: -38.88135910, val_loss: -41.39036179\n",
      "Epoch: [39] [ 410/ 548] time: 603.6515, train_loss: -45.81892014, val_loss: -40.27732468\n",
      "Epoch: [39] [ 420/ 548] time: 603.9727, train_loss: -44.33989716, val_loss: -40.71940231\n",
      "Epoch: [39] [ 430/ 548] time: 604.2676, train_loss: 4.54571152, val_loss: -40.81287766\n",
      "Epoch: [39] [ 440/ 548] time: 604.5612, train_loss: -33.60822296, val_loss: -40.53842926\n",
      "Epoch: [39] [ 450/ 548] time: 604.8846, train_loss: -23.01766586, val_loss: -40.93440247\n",
      "Epoch: [39] [ 460/ 548] time: 605.2247, train_loss: -46.62508392, val_loss: -39.97187805\n",
      "Epoch: [39] [ 470/ 548] time: 605.5779, train_loss: -39.04565048, val_loss: -39.62029648\n",
      "Epoch: [39] [ 480/ 548] time: 605.9092, train_loss: -43.06032181, val_loss: -40.47467041\n",
      "Epoch: [39] [ 490/ 548] time: 606.2652, train_loss: -35.24822235, val_loss: -40.39256668\n",
      "Epoch: [39] [ 500/ 548] time: 606.6147, train_loss: -41.81492615, val_loss: -41.14132690\n",
      "Epoch: [39] [ 510/ 548] time: 606.9520, train_loss: -43.22682571, val_loss: -38.72745514\n",
      "Epoch: [39] [ 520/ 548] time: 607.2956, train_loss: 50.98577881, val_loss: -40.31668854\n",
      "Epoch: [39] [ 530/ 548] time: 607.5977, train_loss: -29.58373833, val_loss: -39.26901245\n",
      "Epoch: [39] [ 540/ 548] time: 607.9401, train_loss: -34.94858170, val_loss: -38.25192261\n",
      "Epoch: [40] [   0/ 548] time: 608.1914, train_loss: -28.36816216, val_loss: -34.65818787\n",
      "Epoch: [40] [  10/ 548] time: 608.5227, train_loss: -44.29611588, val_loss: -39.04199982\n",
      "Epoch: [40] [  20/ 548] time: 608.8329, train_loss: -43.63724899, val_loss: -38.75038910\n",
      "Epoch: [40] [  30/ 548] time: 609.1226, train_loss: -41.64491272, val_loss: -40.01896667\n",
      "Epoch: [40] [  40/ 548] time: 609.4275, train_loss: -37.91020584, val_loss: -38.55697632\n",
      "Epoch: [40] [  50/ 548] time: 609.6800, train_loss: -37.76644516, val_loss: -39.79452896\n",
      "Epoch: [40] [  60/ 548] time: 609.9298, train_loss: -45.85268784, val_loss: -40.98089600\n",
      "Epoch: [40] [  70/ 548] time: 610.1906, train_loss: -18.14162064, val_loss: -40.88147354\n",
      "Epoch: [40] [  80/ 548] time: 610.4349, train_loss: -40.95512390, val_loss: -42.10865402\n",
      "Saving checkpoint\n",
      "Epoch: [40] [  90/ 548] time: 611.7634, train_loss: -44.12964630, val_loss: -40.92366791\n",
      "Epoch: [40] [ 100/ 548] time: 612.0226, train_loss: -38.55541229, val_loss: -40.94348907\n",
      "Epoch: [40] [ 110/ 548] time: 612.2937, train_loss: -39.63143921, val_loss: -41.38874817\n",
      "Epoch: [40] [ 120/ 548] time: 612.5503, train_loss: -44.86917496, val_loss: -42.01316071\n",
      "Epoch: [40] [ 130/ 548] time: 612.7841, train_loss: -41.89715195, val_loss: -40.70344543\n",
      "Epoch: [40] [ 140/ 548] time: 613.0104, train_loss: -36.77768707, val_loss: -42.46401215\n",
      "Epoch: [40] [ 150/ 548] time: 613.2388, train_loss: -43.35667801, val_loss: -42.88497162\n",
      "Epoch: [40] [ 160/ 548] time: 613.4739, train_loss: -37.07280731, val_loss: -42.64712143\n",
      "Epoch: [40] [ 170/ 548] time: 613.7114, train_loss: -36.74654007, val_loss: -42.05589294\n",
      "Epoch: [40] [ 180/ 548] time: 613.9459, train_loss: -23.74365807, val_loss: -41.81301117\n",
      "Epoch: [40] [ 190/ 548] time: 614.1831, train_loss: -37.25536346, val_loss: -41.57537079\n",
      "Epoch: [40] [ 200/ 548] time: 614.4238, train_loss: -45.00871277, val_loss: -40.70990753\n",
      "Epoch: [40] [ 210/ 548] time: 614.6728, train_loss: -37.81396866, val_loss: -41.01636505\n",
      "Epoch: [40] [ 220/ 548] time: 614.9148, train_loss: -41.65127563, val_loss: -42.84521103\n",
      "Epoch: [40] [ 230/ 548] time: 615.1597, train_loss: -45.04543304, val_loss: -43.70098495\n",
      "Epoch: [40] [ 240/ 548] time: 615.4019, train_loss: -41.05055237, val_loss: -43.35049438\n",
      "Epoch: [40] [ 250/ 548] time: 615.6380, train_loss: -32.76426697, val_loss: -43.96527481\n",
      "Epoch: [40] [ 260/ 548] time: 615.8752, train_loss: -47.29164886, val_loss: -43.51215744\n",
      "Epoch: [40] [ 270/ 548] time: 616.1390, train_loss: -44.07341766, val_loss: -43.15962219\n",
      "Epoch: [40] [ 280/ 548] time: 616.4042, train_loss: -49.13721848, val_loss: -42.58658600\n",
      "Epoch: [40] [ 290/ 548] time: 616.6739, train_loss: -37.47268295, val_loss: -42.03995514\n",
      "Epoch: [40] [ 300/ 548] time: 616.9293, train_loss: -44.28398132, val_loss: -42.28390884\n",
      "Epoch: [40] [ 310/ 548] time: 617.1828, train_loss: -42.58573151, val_loss: -42.95039368\n",
      "Epoch: [40] [ 320/ 548] time: 617.4486, train_loss: -45.12666702, val_loss: -43.32385254\n",
      "Epoch: [40] [ 330/ 548] time: 617.7123, train_loss: -28.62754059, val_loss: -43.20141602\n",
      "Epoch: [40] [ 340/ 548] time: 617.9923, train_loss: -33.37118912, val_loss: -43.53073502\n",
      "Epoch: [40] [ 350/ 548] time: 618.2766, train_loss: -24.43566132, val_loss: -43.04800415\n",
      "Epoch: [40] [ 360/ 548] time: 618.5695, train_loss: -43.55923080, val_loss: -43.34572601\n",
      "Epoch: [40] [ 370/ 548] time: 618.8482, train_loss: -46.08874893, val_loss: -43.53906250\n",
      "Epoch: [40] [ 380/ 548] time: 619.1224, train_loss: -15.21442795, val_loss: -40.43894196\n",
      "Epoch: [40] [ 390/ 548] time: 619.4044, train_loss: -29.68563080, val_loss: -41.27285004\n",
      "Epoch: [40] [ 400/ 548] time: 619.6857, train_loss: -38.52017212, val_loss: -41.93704605\n",
      "Epoch: [40] [ 410/ 548] time: 619.9517, train_loss: -49.79058838, val_loss: -42.20494080\n",
      "Epoch: [40] [ 420/ 548] time: 620.1992, train_loss: -40.63053894, val_loss: -41.39926910\n",
      "Epoch: [40] [ 430/ 548] time: 620.4683, train_loss: -6.13871384, val_loss: -40.04014587\n",
      "Epoch: [40] [ 440/ 548] time: 620.7172, train_loss: -46.74082947, val_loss: -41.40694427\n",
      "Epoch: [40] [ 450/ 548] time: 620.9785, train_loss: -41.51829529, val_loss: -40.68644714\n",
      "Epoch: [40] [ 460/ 548] time: 621.2462, train_loss: -41.63409042, val_loss: -42.25464630\n",
      "Epoch: [40] [ 470/ 548] time: 621.5012, train_loss: -36.40873337, val_loss: -41.86583710\n",
      "Epoch: [40] [ 480/ 548] time: 621.7749, train_loss: -31.17310143, val_loss: -43.15753174\n",
      "Epoch: [40] [ 490/ 548] time: 622.0504, train_loss: -46.34281158, val_loss: -44.33512115\n",
      "Epoch: [40] [ 500/ 548] time: 622.3331, train_loss: -43.20942688, val_loss: -43.95446014\n",
      "Epoch: [40] [ 510/ 548] time: 622.6112, train_loss: -43.73639679, val_loss: -43.42557144\n",
      "Epoch: [40] [ 520/ 548] time: 622.8915, train_loss: -45.44829941, val_loss: -43.20639420\n",
      "Epoch: [40] [ 530/ 548] time: 623.1766, train_loss: -30.51982498, val_loss: -41.65699768\n",
      "Epoch: [40] [ 540/ 548] time: 623.4608, train_loss: -20.43349075, val_loss: -43.40879440\n",
      "Epoch: [41] [   0/ 548] time: 623.6871, train_loss: -40.18202972, val_loss: -44.13881683\n",
      "Epoch: [41] [  10/ 548] time: 623.9990, train_loss: -45.25298309, val_loss: -44.64215469\n",
      "Epoch: [41] [  20/ 548] time: 624.3183, train_loss: -45.56278992, val_loss: -44.79367447\n",
      "Epoch: [41] [  30/ 548] time: 624.6306, train_loss: -43.13603210, val_loss: -43.93650055\n",
      "Epoch: [41] [  40/ 548] time: 624.9111, train_loss: -23.69402122, val_loss: -44.00116348\n",
      "Epoch: [41] [  50/ 548] time: 625.1730, train_loss: -45.24279022, val_loss: -43.98989487\n",
      "Epoch: [41] [  60/ 548] time: 625.4228, train_loss: -43.51334000, val_loss: -44.01228333\n",
      "Epoch: [41] [  70/ 548] time: 625.6897, train_loss: -48.08580780, val_loss: -44.43136978\n",
      "Epoch: [41] [  80/ 548] time: 625.9683, train_loss: -43.86793518, val_loss: -44.15816498\n",
      "Epoch: [41] [  90/ 548] time: 626.2577, train_loss: -45.84765625, val_loss: -43.58266068\n",
      "Epoch: [41] [ 100/ 548] time: 626.5327, train_loss: -23.87116051, val_loss: -43.25270081\n",
      "Epoch: [41] [ 110/ 548] time: 626.7902, train_loss: -39.23023987, val_loss: -42.66765213\n",
      "Epoch: [41] [ 120/ 548] time: 627.0416, train_loss: -44.56031036, val_loss: -42.95545578\n",
      "Epoch: [41] [ 130/ 548] time: 627.2959, train_loss: -47.93425369, val_loss: -41.19712067\n",
      "Epoch: [41] [ 140/ 548] time: 627.5557, train_loss: -43.84228134, val_loss: -41.72279739\n",
      "Epoch: [41] [ 150/ 548] time: 627.8207, train_loss: -46.70824051, val_loss: -41.63617706\n",
      "Epoch: [41] [ 160/ 548] time: 628.0930, train_loss: -19.32851410, val_loss: -42.69263840\n",
      "Epoch: [41] [ 170/ 548] time: 628.3561, train_loss: -41.46405029, val_loss: -42.73186111\n",
      "Epoch: [41] [ 180/ 548] time: 628.6184, train_loss: -47.97337723, val_loss: -42.85587692\n",
      "Epoch: [41] [ 190/ 548] time: 628.8727, train_loss: -37.91459656, val_loss: -42.96155930\n",
      "Epoch: [41] [ 200/ 548] time: 629.1283, train_loss: -39.67343140, val_loss: -43.10662460\n",
      "Epoch: [41] [ 210/ 548] time: 629.3784, train_loss: -45.42880630, val_loss: -43.07502365\n",
      "Epoch: [41] [ 220/ 548] time: 629.6280, train_loss: -45.31874847, val_loss: -44.74558640\n",
      "Epoch: [41] [ 230/ 548] time: 629.8860, train_loss: -37.69660950, val_loss: -44.40415192\n",
      "Epoch: [41] [ 240/ 548] time: 630.1585, train_loss: -49.31111908, val_loss: -44.73292542\n",
      "Epoch: [41] [ 250/ 548] time: 630.4367, train_loss: -22.74737358, val_loss: -44.36637115\n",
      "Epoch: [41] [ 260/ 548] time: 630.7289, train_loss: -41.28102875, val_loss: -42.77574921\n",
      "Epoch: [41] [ 270/ 548] time: 631.0172, train_loss: -30.39832497, val_loss: -43.83686829\n",
      "Epoch: [41] [ 280/ 548] time: 631.2861, train_loss: -45.81175995, val_loss: -44.47363663\n",
      "Epoch: [41] [ 290/ 548] time: 631.5621, train_loss: -40.66339874, val_loss: -43.10240555\n",
      "Epoch: [41] [ 300/ 548] time: 631.8324, train_loss: -48.88251495, val_loss: -44.01323700\n",
      "Epoch: [41] [ 310/ 548] time: 632.0830, train_loss: -40.31032181, val_loss: -45.20924759\n",
      "Epoch: [41] [ 320/ 548] time: 632.3525, train_loss: -42.10415649, val_loss: -45.07743454\n",
      "Epoch: [41] [ 330/ 548] time: 632.6099, train_loss: -43.79636383, val_loss: -45.36817932\n",
      "Epoch: [41] [ 340/ 548] time: 632.8711, train_loss: -43.97548294, val_loss: -44.88784027\n",
      "Epoch: [41] [ 350/ 548] time: 633.1368, train_loss: -47.96004868, val_loss: -44.80627060\n",
      "Epoch: [41] [ 360/ 548] time: 633.4082, train_loss: -38.85627747, val_loss: -45.34112549\n",
      "Epoch: [41] [ 370/ 548] time: 633.6634, train_loss: -44.67347717, val_loss: -44.77808762\n",
      "Epoch: [41] [ 380/ 548] time: 633.9254, train_loss: -42.96384811, val_loss: -45.35179901\n",
      "Epoch: [41] [ 390/ 548] time: 634.1881, train_loss: -43.80253601, val_loss: -44.66674805\n",
      "Epoch: [41] [ 400/ 548] time: 634.4433, train_loss: -46.04502487, val_loss: -44.79368210\n",
      "Epoch: [41] [ 410/ 548] time: 634.6926, train_loss: -45.96862793, val_loss: -45.24370193\n",
      "Epoch: [41] [ 420/ 548] time: 634.9404, train_loss: -37.96062088, val_loss: -45.05486298\n",
      "Epoch: [41] [ 430/ 548] time: 635.2050, train_loss: -45.15542603, val_loss: -45.37602615\n",
      "Epoch: [41] [ 440/ 548] time: 635.4885, train_loss: -43.94311523, val_loss: -45.46862793\n",
      "Epoch: [41] [ 450/ 548] time: 635.7415, train_loss: -21.28713989, val_loss: -43.51552200\n",
      "Epoch: [41] [ 460/ 548] time: 635.9839, train_loss: -42.73342133, val_loss: -42.63055420\n",
      "Epoch: [41] [ 470/ 548] time: 636.2506, train_loss: -50.77359772, val_loss: -45.07905579\n",
      "Epoch: [41] [ 480/ 548] time: 636.5204, train_loss: -40.72310638, val_loss: -42.63455963\n",
      "Epoch: [41] [ 490/ 548] time: 636.7926, train_loss: -36.01127625, val_loss: -41.63253784\n",
      "Epoch: [41] [ 500/ 548] time: 637.0652, train_loss: -29.23222733, val_loss: -41.67316818\n",
      "Epoch: [41] [ 510/ 548] time: 637.3252, train_loss: -13.84528732, val_loss: -39.70415115\n",
      "Epoch: [41] [ 520/ 548] time: 637.5705, train_loss: -32.83957672, val_loss: -36.74476624\n",
      "Epoch: [41] [ 530/ 548] time: 637.8275, train_loss: -35.22948074, val_loss: -43.42201614\n",
      "Saving checkpoint\n",
      "Epoch: [41] [ 540/ 548] time: 639.1434, train_loss: -44.32690048, val_loss: -41.03305054\n",
      "Epoch: [42] [   0/ 548] time: 639.3466, train_loss: -31.26306725, val_loss: -41.77194595\n",
      "Epoch: [42] [  10/ 548] time: 639.6060, train_loss: -32.96019745, val_loss: -42.88393784\n",
      "Epoch: [42] [  20/ 548] time: 639.8700, train_loss: -44.54483795, val_loss: -44.43747330\n",
      "Epoch: [42] [  30/ 548] time: 640.1082, train_loss: -44.94673920, val_loss: -44.81693268\n",
      "Epoch: [42] [  40/ 548] time: 640.3491, train_loss: -28.55041504, val_loss: -45.01832962\n",
      "Epoch: [42] [  50/ 548] time: 640.5736, train_loss: -44.35998917, val_loss: -44.34609604\n",
      "Epoch: [42] [  60/ 548] time: 640.8166, train_loss: -47.69095993, val_loss: -44.31979752\n",
      "Epoch: [42] [  70/ 548] time: 641.0448, train_loss: -36.39708328, val_loss: -43.91796875\n",
      "Epoch: [42] [  80/ 548] time: 641.2925, train_loss: -47.67092514, val_loss: -45.18070984\n",
      "Epoch: [42] [  90/ 548] time: 641.5363, train_loss: -38.39328766, val_loss: -45.22697449\n",
      "Epoch: [42] [ 100/ 548] time: 641.7864, train_loss: -46.32044601, val_loss: -45.33280945\n",
      "Epoch: [42] [ 110/ 548] time: 642.0405, train_loss: -45.36016083, val_loss: -45.24333954\n",
      "Epoch: [42] [ 120/ 548] time: 642.3056, train_loss: -43.62433624, val_loss: -45.64346313\n",
      "Epoch: [42] [ 130/ 548] time: 642.5806, train_loss: -45.13288879, val_loss: -45.40269470\n",
      "Epoch: [42] [ 140/ 548] time: 642.8453, train_loss: -41.08899689, val_loss: -45.17909622\n",
      "Epoch: [42] [ 150/ 548] time: 643.1205, train_loss: -44.16278076, val_loss: -45.69849014\n",
      "Epoch: [42] [ 160/ 548] time: 643.3688, train_loss: -42.73530960, val_loss: -45.60039902\n",
      "Epoch: [42] [ 170/ 548] time: 643.6158, train_loss: -12.63966751, val_loss: -44.92604446\n",
      "Epoch: [42] [ 180/ 548] time: 643.8629, train_loss: -38.33821869, val_loss: -44.65364456\n",
      "Epoch: [42] [ 190/ 548] time: 644.1146, train_loss: -24.70131874, val_loss: -46.02091980\n",
      "Epoch: [42] [ 200/ 548] time: 644.3757, train_loss: -46.52890778, val_loss: -46.00425339\n",
      "Epoch: [42] [ 210/ 548] time: 644.6269, train_loss: -30.90776825, val_loss: -45.50638199\n",
      "Epoch: [42] [ 220/ 548] time: 644.8730, train_loss: -40.57350922, val_loss: -45.48248672\n",
      "Epoch: [42] [ 230/ 548] time: 645.1195, train_loss: -46.46309662, val_loss: -45.10041809\n",
      "Epoch: [42] [ 240/ 548] time: 645.3655, train_loss: -39.11548615, val_loss: -44.72719193\n",
      "Epoch: [42] [ 250/ 548] time: 645.6095, train_loss: -46.06729889, val_loss: -45.35717010\n",
      "Epoch: [42] [ 260/ 548] time: 645.8547, train_loss: -39.35484314, val_loss: -43.34906769\n",
      "Epoch: [42] [ 270/ 548] time: 646.1045, train_loss: -45.14554596, val_loss: -45.03339767\n",
      "Epoch: [42] [ 280/ 548] time: 646.3495, train_loss: -39.13648605, val_loss: -45.33706665\n",
      "Epoch: [42] [ 290/ 548] time: 646.5863, train_loss: -46.48707581, val_loss: -45.54043961\n",
      "Epoch: [42] [ 300/ 548] time: 646.8260, train_loss: -47.11855316, val_loss: -45.78091431\n",
      "Epoch: [42] [ 310/ 548] time: 647.0729, train_loss: -45.51527405, val_loss: -45.91815186\n",
      "Epoch: [42] [ 320/ 548] time: 647.3196, train_loss: -46.63664627, val_loss: -45.74415207\n",
      "Epoch: [42] [ 330/ 548] time: 647.5649, train_loss: -52.26865005, val_loss: -45.04301834\n",
      "Epoch: [42] [ 340/ 548] time: 647.8069, train_loss: -45.59506226, val_loss: -43.03049469\n",
      "Epoch: [42] [ 350/ 548] time: 648.0455, train_loss: -25.80145264, val_loss: -44.74694824\n",
      "Epoch: [42] [ 360/ 548] time: 648.3092, train_loss: -41.77606201, val_loss: -45.12524414\n",
      "Epoch: [42] [ 370/ 548] time: 648.5768, train_loss: -40.58352280, val_loss: -43.35429382\n",
      "Epoch: [42] [ 380/ 548] time: 648.8645, train_loss: -44.01601410, val_loss: -45.10890579\n",
      "Epoch: [42] [ 390/ 548] time: 649.1462, train_loss: -45.98612213, val_loss: -44.57716751\n",
      "Epoch: [42] [ 400/ 548] time: 649.4217, train_loss: -39.47922516, val_loss: -44.68289566\n",
      "Epoch: [42] [ 410/ 548] time: 649.6811, train_loss: -38.51633453, val_loss: -45.46375275\n",
      "Epoch: [42] [ 420/ 548] time: 649.9447, train_loss: -41.84454346, val_loss: -43.74951172\n",
      "Epoch: [42] [ 430/ 548] time: 650.2096, train_loss: -43.96355438, val_loss: -44.84663391\n",
      "Epoch: [42] [ 440/ 548] time: 650.4541, train_loss: -38.29941940, val_loss: -43.66555786\n",
      "Epoch: [42] [ 450/ 548] time: 650.6999, train_loss: -30.74304199, val_loss: -45.12752914\n",
      "Epoch: [42] [ 460/ 548] time: 650.9362, train_loss: -31.68213463, val_loss: -45.36486435\n",
      "Epoch: [42] [ 470/ 548] time: 651.1868, train_loss: -47.14139175, val_loss: -45.74847412\n",
      "Epoch: [42] [ 480/ 548] time: 651.4418, train_loss: -41.43974304, val_loss: -45.50648880\n",
      "Epoch: [42] [ 490/ 548] time: 651.6996, train_loss: -42.64208984, val_loss: -44.47631836\n",
      "Epoch: [42] [ 500/ 548] time: 651.9688, train_loss: -50.23131180, val_loss: -45.69508362\n",
      "Epoch: [42] [ 510/ 548] time: 652.2693, train_loss: -45.89530945, val_loss: -44.31300354\n",
      "Epoch: [42] [ 520/ 548] time: 652.5446, train_loss: -38.92938232, val_loss: -41.65510178\n",
      "Epoch: [42] [ 530/ 548] time: 652.7978, train_loss: -34.81919861, val_loss: -43.64479828\n",
      "Epoch: [42] [ 540/ 548] time: 653.0443, train_loss: -40.43988800, val_loss: -43.52115631\n",
      "Epoch: [43] [   0/ 548] time: 653.2409, train_loss: -30.13000298, val_loss: -44.26772690\n",
      "Epoch: [43] [  10/ 548] time: 653.4902, train_loss: -43.94985199, val_loss: -43.02313995\n",
      "Epoch: [43] [  20/ 548] time: 653.7308, train_loss: -48.10746002, val_loss: -44.77943039\n",
      "Epoch: [43] [  30/ 548] time: 653.9759, train_loss: -15.31844330, val_loss: -45.30523682\n",
      "Epoch: [43] [  40/ 548] time: 654.2229, train_loss: -39.14308929, val_loss: -44.67947388\n",
      "Epoch: [43] [  50/ 548] time: 654.4872, train_loss: -48.69686127, val_loss: -43.93050766\n",
      "Epoch: [43] [  60/ 548] time: 654.7640, train_loss: -41.27922821, val_loss: -45.70092773\n",
      "Epoch: [43] [  70/ 548] time: 655.0227, train_loss: -48.53858185, val_loss: -45.64676666\n",
      "Epoch: [43] [  80/ 548] time: 655.2933, train_loss: -44.63153839, val_loss: -46.60310364\n",
      "Epoch: [43] [  90/ 548] time: 655.5354, train_loss: -46.40611267, val_loss: -46.47861481\n",
      "Epoch: [43] [ 100/ 548] time: 655.7748, train_loss: -47.86962509, val_loss: -47.01501846\n",
      "Epoch: [43] [ 110/ 548] time: 656.0181, train_loss: -47.35130692, val_loss: -46.81886292\n",
      "Epoch: [43] [ 120/ 548] time: 656.2718, train_loss: -45.89017105, val_loss: -46.49948883\n",
      "Epoch: [43] [ 130/ 548] time: 656.5192, train_loss: -41.49794006, val_loss: -44.66357803\n",
      "Epoch: [43] [ 140/ 548] time: 656.7749, train_loss: -43.84868622, val_loss: -38.09721375\n",
      "Epoch: [43] [ 150/ 548] time: 657.0267, train_loss: -38.78836823, val_loss: -40.92737198\n",
      "Epoch: [43] [ 160/ 548] time: 657.2910, train_loss: -45.67535019, val_loss: -42.55274200\n",
      "Epoch: [43] [ 170/ 548] time: 657.5478, train_loss: -43.35072327, val_loss: -43.64629364\n",
      "Epoch: [43] [ 180/ 548] time: 657.7963, train_loss: -50.83578491, val_loss: -44.45489120\n",
      "Epoch: [43] [ 190/ 548] time: 658.0438, train_loss: -46.99011993, val_loss: -45.32084274\n",
      "Epoch: [43] [ 200/ 548] time: 658.2940, train_loss: -38.75819397, val_loss: -45.48771667\n",
      "Epoch: [43] [ 210/ 548] time: 658.5498, train_loss: -47.62983322, val_loss: -46.09838867\n",
      "Epoch: [43] [ 220/ 548] time: 658.7958, train_loss: -47.08965302, val_loss: -46.20627975\n",
      "Epoch: [43] [ 230/ 548] time: 659.0423, train_loss: -44.40322113, val_loss: -44.14179993\n",
      "Epoch: [43] [ 240/ 548] time: 659.2959, train_loss: -44.76928329, val_loss: -44.23228455\n",
      "Epoch: [43] [ 250/ 548] time: 659.5378, train_loss: -44.92552948, val_loss: -44.99881744\n",
      "Epoch: [43] [ 260/ 548] time: 659.7749, train_loss: -49.09948730, val_loss: -44.37655258\n",
      "Epoch: [43] [ 270/ 548] time: 660.0147, train_loss: -40.33161926, val_loss: -44.89517212\n",
      "Epoch: [43] [ 280/ 548] time: 660.2593, train_loss: -41.97470093, val_loss: -45.31371307\n",
      "Epoch: [43] [ 290/ 548] time: 660.5201, train_loss: -43.73482895, val_loss: -45.58690262\n",
      "Epoch: [43] [ 300/ 548] time: 660.7819, train_loss: -38.90669250, val_loss: -45.40229797\n",
      "Epoch: [43] [ 310/ 548] time: 661.0413, train_loss: -47.77228546, val_loss: -43.66046524\n",
      "Epoch: [43] [ 320/ 548] time: 661.3295, train_loss: -31.96033859, val_loss: -45.07753754\n",
      "Epoch: [43] [ 330/ 548] time: 661.5867, train_loss: -45.25740051, val_loss: -45.95249939\n",
      "Epoch: [43] [ 340/ 548] time: 661.8326, train_loss: -36.89960098, val_loss: -46.37342834\n",
      "Epoch: [43] [ 350/ 548] time: 662.0774, train_loss: -43.89906311, val_loss: -45.95125580\n",
      "Epoch: [43] [ 360/ 548] time: 662.3537, train_loss: -47.67384338, val_loss: -46.14673615\n",
      "Epoch: [43] [ 370/ 548] time: 662.6056, train_loss: -51.54408264, val_loss: -47.17535400\n",
      "Epoch: [43] [ 380/ 548] time: 662.8521, train_loss: -41.22108459, val_loss: -47.32354736\n",
      "Epoch: [43] [ 390/ 548] time: 663.1068, train_loss: -45.33232498, val_loss: -46.65964508\n",
      "Epoch: [43] [ 400/ 548] time: 663.3555, train_loss: -50.45429230, val_loss: -47.34022522\n",
      "Epoch: [43] [ 410/ 548] time: 663.6022, train_loss: -40.85250092, val_loss: -47.12453461\n",
      "Epoch: [43] [ 420/ 548] time: 663.8477, train_loss: -50.46541977, val_loss: -46.78199005\n",
      "Epoch: [43] [ 430/ 548] time: 664.0898, train_loss: -47.66920471, val_loss: -46.18889236\n",
      "Saving checkpoint\n",
      "Epoch: [43] [ 440/ 548] time: 665.4803, train_loss: -43.53725433, val_loss: -46.57689285\n",
      "Epoch: [43] [ 450/ 548] time: 665.7520, train_loss: -46.69068146, val_loss: -47.45853424\n",
      "Epoch: [43] [ 460/ 548] time: 666.0263, train_loss: -51.40708160, val_loss: -47.16933060\n",
      "Epoch: [43] [ 470/ 548] time: 666.3027, train_loss: -49.06440735, val_loss: -47.52050018\n",
      "Epoch: [43] [ 480/ 548] time: 666.5590, train_loss: -17.77587128, val_loss: -46.57233810\n",
      "Epoch: [43] [ 490/ 548] time: 666.8378, train_loss: -49.94011307, val_loss: -46.94077682\n",
      "Epoch: [43] [ 500/ 548] time: 667.1098, train_loss: -41.49374390, val_loss: -47.02895355\n",
      "Epoch: [43] [ 510/ 548] time: 667.3788, train_loss: -48.17881012, val_loss: -45.52286911\n",
      "Epoch: [43] [ 520/ 548] time: 667.6281, train_loss: -47.82841492, val_loss: -47.08845139\n",
      "Epoch: [43] [ 530/ 548] time: 667.8802, train_loss: -43.53387451, val_loss: -45.99818420\n",
      "Epoch: [43] [ 540/ 548] time: 668.1291, train_loss: -29.07870674, val_loss: -45.25314713\n",
      "Epoch: [44] [   0/ 548] time: 668.3254, train_loss: -43.90033722, val_loss: -44.95122910\n",
      "Epoch: [44] [  10/ 548] time: 668.5740, train_loss: -45.64869690, val_loss: -45.07815552\n",
      "Epoch: [44] [  20/ 548] time: 668.8410, train_loss: -41.29983521, val_loss: -45.91492844\n",
      "Epoch: [44] [  30/ 548] time: 669.1130, train_loss: -36.10438538, val_loss: -46.85792923\n",
      "Epoch: [44] [  40/ 548] time: 669.3636, train_loss: -44.21820831, val_loss: -46.54658127\n",
      "Epoch: [44] [  50/ 548] time: 669.6092, train_loss: -40.54131317, val_loss: -46.36191559\n",
      "Epoch: [44] [  60/ 548] time: 669.8586, train_loss: -45.15991974, val_loss: -47.03796768\n",
      "Epoch: [44] [  70/ 548] time: 670.1213, train_loss: -42.47044373, val_loss: -46.19183350\n",
      "Epoch: [44] [  80/ 548] time: 670.3847, train_loss: -47.80680847, val_loss: -45.79458618\n",
      "Epoch: [44] [  90/ 548] time: 670.6576, train_loss: -50.07582474, val_loss: -45.71287155\n",
      "Epoch: [44] [ 100/ 548] time: 670.9140, train_loss: -40.55139542, val_loss: -46.15553665\n",
      "Epoch: [44] [ 110/ 548] time: 671.1731, train_loss: -50.51490021, val_loss: -46.79813004\n",
      "Epoch: [44] [ 120/ 548] time: 671.4403, train_loss: -42.23265076, val_loss: -47.41883469\n",
      "Epoch: [44] [ 130/ 548] time: 671.6867, train_loss: -47.39086914, val_loss: -46.37213898\n",
      "Epoch: [44] [ 140/ 548] time: 671.9372, train_loss: -27.60986519, val_loss: -45.94211960\n",
      "Epoch: [44] [ 150/ 548] time: 672.1801, train_loss: -48.70703125, val_loss: -47.26231384\n",
      "Epoch: [44] [ 160/ 548] time: 672.4296, train_loss: -31.51485252, val_loss: -48.36687469\n",
      "Epoch: [44] [ 170/ 548] time: 672.6929, train_loss: -45.95774460, val_loss: -48.12397003\n",
      "Epoch: [44] [ 180/ 548] time: 672.9593, train_loss: -50.04173660, val_loss: -47.91715240\n",
      "Epoch: [44] [ 190/ 548] time: 673.2327, train_loss: -42.02380371, val_loss: -48.23143768\n",
      "Epoch: [44] [ 200/ 548] time: 673.5014, train_loss: -46.34696579, val_loss: -48.32007217\n",
      "Epoch: [44] [ 210/ 548] time: 673.7531, train_loss: -48.68716431, val_loss: -47.86496353\n",
      "Epoch: [44] [ 220/ 548] time: 673.9937, train_loss: -27.29585457, val_loss: -47.13697052\n",
      "Epoch: [44] [ 230/ 548] time: 674.2395, train_loss: -37.95423126, val_loss: -45.66329193\n",
      "Epoch: [44] [ 240/ 548] time: 674.4825, train_loss: -44.09827423, val_loss: -44.51243591\n",
      "Epoch: [44] [ 250/ 548] time: 674.7277, train_loss: -47.83390808, val_loss: -46.27806091\n",
      "Epoch: [44] [ 260/ 548] time: 674.9745, train_loss: -45.97205353, val_loss: -46.88130951\n",
      "Epoch: [44] [ 270/ 548] time: 675.2290, train_loss: -41.93349838, val_loss: -47.37546158\n",
      "Epoch: [44] [ 280/ 548] time: 675.4775, train_loss: -40.87353134, val_loss: -46.72057343\n",
      "Epoch: [44] [ 290/ 548] time: 675.7212, train_loss: -39.00756836, val_loss: -47.26242828\n",
      "Epoch: [44] [ 300/ 548] time: 675.9591, train_loss: -52.28787231, val_loss: -47.22952271\n",
      "Epoch: [44] [ 310/ 548] time: 676.2138, train_loss: -48.10622787, val_loss: -46.80621719\n",
      "Epoch: [44] [ 320/ 548] time: 676.4599, train_loss: -47.68233490, val_loss: -47.65682983\n",
      "Epoch: [44] [ 330/ 548] time: 676.6973, train_loss: -52.33933258, val_loss: -47.83050537\n",
      "Epoch: [44] [ 340/ 548] time: 676.9348, train_loss: -46.95277405, val_loss: -47.90294647\n",
      "Epoch: [44] [ 350/ 548] time: 677.1743, train_loss: -45.32936859, val_loss: -46.01058197\n",
      "Epoch: [44] [ 360/ 548] time: 677.4162, train_loss: 91.19917297, val_loss: -47.24198914\n",
      "Epoch: [44] [ 370/ 548] time: 677.6572, train_loss: -50.17010880, val_loss: -46.88673019\n",
      "Epoch: [44] [ 380/ 548] time: 677.9010, train_loss: -51.43342209, val_loss: -46.47068787\n",
      "Epoch: [44] [ 390/ 548] time: 678.1522, train_loss: -1.60742950, val_loss: -46.23957825\n",
      "Epoch: [44] [ 400/ 548] time: 678.3928, train_loss: -45.30395508, val_loss: -47.10774994\n",
      "Epoch: [44] [ 410/ 548] time: 678.6842, train_loss: -50.06628036, val_loss: -47.78973389\n",
      "Epoch: [44] [ 420/ 548] time: 678.9582, train_loss: -47.46147156, val_loss: -48.02542114\n",
      "Epoch: [44] [ 430/ 548] time: 679.2306, train_loss: -47.20507050, val_loss: -47.43381500\n",
      "Epoch: [44] [ 440/ 548] time: 679.5046, train_loss: -46.30880737, val_loss: -46.43035126\n",
      "Epoch: [44] [ 450/ 548] time: 679.7637, train_loss: -51.07772064, val_loss: -47.02972794\n",
      "Epoch: [44] [ 460/ 548] time: 680.0131, train_loss: -50.44460297, val_loss: -47.49359512\n",
      "Epoch: [44] [ 470/ 548] time: 680.2642, train_loss: -37.05988312, val_loss: -47.63375092\n",
      "Epoch: [44] [ 480/ 548] time: 680.5129, train_loss: -38.42248535, val_loss: -47.93874741\n",
      "Epoch: [44] [ 490/ 548] time: 680.7635, train_loss: -48.75605774, val_loss: -48.13835526\n",
      "Epoch: [44] [ 500/ 548] time: 681.0205, train_loss: -35.76989746, val_loss: -47.77659607\n",
      "Epoch: [44] [ 510/ 548] time: 681.2906, train_loss: -44.60951996, val_loss: -48.98622513\n",
      "Epoch: [44] [ 520/ 548] time: 681.5443, train_loss: -46.61849594, val_loss: -48.19054031\n",
      "Epoch: [44] [ 530/ 548] time: 681.8037, train_loss: -45.59909821, val_loss: -48.12042618\n",
      "Epoch: [44] [ 540/ 548] time: 682.0569, train_loss: -43.84793091, val_loss: -45.06412506\n",
      "Epoch: [45] [   0/ 548] time: 682.2598, train_loss: -39.05057907, val_loss: -45.21289825\n",
      "Epoch: [45] [  10/ 548] time: 682.5270, train_loss: -51.20478058, val_loss: -44.93343353\n",
      "Epoch: [45] [  20/ 548] time: 682.7805, train_loss: -44.68840408, val_loss: -47.23293304\n",
      "Epoch: [45] [  30/ 548] time: 683.0467, train_loss: -46.96855927, val_loss: -48.04179382\n",
      "Epoch: [45] [  40/ 548] time: 683.3107, train_loss: -31.17750359, val_loss: -47.38076782\n",
      "Epoch: [45] [  50/ 548] time: 683.5614, train_loss: -44.97472382, val_loss: -48.36696625\n",
      "Epoch: [45] [  60/ 548] time: 683.8368, train_loss: -48.97451782, val_loss: -48.01493454\n",
      "Epoch: [45] [  70/ 548] time: 684.0918, train_loss: -44.79053497, val_loss: -47.73958206\n",
      "Epoch: [45] [  80/ 548] time: 684.3429, train_loss: -32.37493515, val_loss: -46.58164215\n",
      "Epoch: [45] [  90/ 548] time: 684.5871, train_loss: -46.67013168, val_loss: -42.93420029\n",
      "Epoch: [45] [ 100/ 548] time: 684.8541, train_loss: -44.67227936, val_loss: -42.69860458\n",
      "Epoch: [45] [ 110/ 548] time: 685.1343, train_loss: -45.20215607, val_loss: -38.64930725\n",
      "Epoch: [45] [ 120/ 548] time: 685.4107, train_loss: -14.81399155, val_loss: -39.13093567\n",
      "Epoch: [45] [ 130/ 548] time: 685.6799, train_loss: -42.81597519, val_loss: -35.55455017\n",
      "Epoch: [45] [ 140/ 548] time: 685.9302, train_loss: -32.63814545, val_loss: -37.81824493\n",
      "Epoch: [45] [ 150/ 548] time: 686.1707, train_loss: -17.00046921, val_loss: -40.78623199\n",
      "Epoch: [45] [ 160/ 548] time: 686.4183, train_loss: -27.24135780, val_loss: -41.87282562\n",
      "Epoch: [45] [ 170/ 548] time: 686.6536, train_loss: -48.17724991, val_loss: -41.60915375\n",
      "Epoch: [45] [ 180/ 548] time: 686.8902, train_loss: -32.16169739, val_loss: -44.97468567\n",
      "Epoch: [45] [ 190/ 548] time: 687.1295, train_loss: -41.31916046, val_loss: -41.99105072\n",
      "Epoch: [45] [ 200/ 548] time: 687.3718, train_loss: -37.72899628, val_loss: -41.32915878\n",
      "Epoch: [45] [ 210/ 548] time: 687.6047, train_loss: -45.39391327, val_loss: -45.45046997\n",
      "Epoch: [45] [ 220/ 548] time: 687.8364, train_loss: -49.58361053, val_loss: -45.25960922\n",
      "Epoch: [45] [ 230/ 548] time: 688.0784, train_loss: -45.68641663, val_loss: -45.05790710\n",
      "Epoch: [45] [ 240/ 548] time: 688.3261, train_loss: -37.57012177, val_loss: -45.34294510\n",
      "Epoch: [45] [ 250/ 548] time: 688.5725, train_loss: -36.45857620, val_loss: -46.49744415\n",
      "Epoch: [45] [ 260/ 548] time: 688.8122, train_loss: -20.21868515, val_loss: -47.71598816\n",
      "Epoch: [45] [ 270/ 548] time: 689.0609, train_loss: -39.58744812, val_loss: -46.02488708\n",
      "Epoch: [45] [ 280/ 548] time: 689.3047, train_loss: -40.37255096, val_loss: -47.60652542\n",
      "Epoch: [45] [ 290/ 548] time: 689.5521, train_loss: -44.74906921, val_loss: -47.80442047\n",
      "Epoch: [45] [ 300/ 548] time: 689.8003, train_loss: -45.48107910, val_loss: -47.68354416\n",
      "Epoch: [45] [ 310/ 548] time: 690.0409, train_loss: -47.78037262, val_loss: -48.19499207\n",
      "Epoch: [45] [ 320/ 548] time: 690.2872, train_loss: -49.00579071, val_loss: -47.32081985\n",
      "Epoch: [45] [ 330/ 548] time: 690.5286, train_loss: -48.14197540, val_loss: -47.27811813\n",
      "Epoch: [45] [ 340/ 548] time: 690.7838, train_loss: -45.96686172, val_loss: -48.67604446\n",
      "Saving checkpoint\n",
      "Epoch: [45] [ 350/ 548] time: 692.1884, train_loss: -48.28028870, val_loss: -48.57835388\n",
      "Epoch: [45] [ 360/ 548] time: 692.4465, train_loss: -49.37799072, val_loss: -48.53215790\n",
      "Epoch: [45] [ 370/ 548] time: 692.6841, train_loss: -49.43759537, val_loss: -47.96527863\n",
      "Epoch: [45] [ 380/ 548] time: 692.9184, train_loss: -48.24313736, val_loss: -48.45154190\n",
      "Epoch: [45] [ 390/ 548] time: 693.1529, train_loss: -33.96103668, val_loss: -48.66063690\n",
      "Epoch: [45] [ 400/ 548] time: 693.4015, train_loss: -48.43907928, val_loss: -47.94707108\n",
      "Epoch: [45] [ 410/ 548] time: 693.6537, train_loss: -50.15972137, val_loss: -48.77142715\n",
      "Epoch: [45] [ 420/ 548] time: 693.8984, train_loss: -47.46878052, val_loss: -48.79535675\n",
      "Epoch: [45] [ 430/ 548] time: 694.1438, train_loss: -49.85253525, val_loss: -48.99540710\n",
      "Epoch: [45] [ 440/ 548] time: 694.4006, train_loss: -44.02560425, val_loss: -49.65871048\n",
      "Epoch: [45] [ 450/ 548] time: 694.6450, train_loss: -49.73669434, val_loss: -48.12656403\n",
      "Epoch: [45] [ 460/ 548] time: 694.8898, train_loss: -42.26163864, val_loss: -48.99110794\n",
      "Epoch: [45] [ 470/ 548] time: 695.1363, train_loss: -49.39677429, val_loss: -49.27970886\n",
      "Epoch: [45] [ 480/ 548] time: 695.4113, train_loss: -31.58377838, val_loss: -48.70105743\n",
      "Epoch: [45] [ 490/ 548] time: 695.6708, train_loss: 0.64751053, val_loss: -48.45122910\n",
      "Epoch: [45] [ 500/ 548] time: 695.9111, train_loss: -48.29320526, val_loss: -48.89472580\n",
      "Epoch: [45] [ 510/ 548] time: 696.1613, train_loss: -50.05870438, val_loss: -49.52557373\n",
      "Epoch: [45] [ 520/ 548] time: 696.4284, train_loss: -44.29397202, val_loss: -49.21933746\n",
      "Epoch: [45] [ 530/ 548] time: 696.7156, train_loss: -50.25139999, val_loss: -49.17882156\n",
      "Epoch: [45] [ 540/ 548] time: 696.9911, train_loss: -52.14495087, val_loss: -49.10189056\n",
      "Epoch: [46] [   0/ 548] time: 697.2118, train_loss: -42.64071655, val_loss: -49.15726471\n",
      "Epoch: [46] [  10/ 548] time: 697.4616, train_loss: -33.76206970, val_loss: -48.63298035\n",
      "Epoch: [46] [  20/ 548] time: 697.7154, train_loss: -49.44008255, val_loss: -49.64836502\n",
      "Epoch: [46] [  30/ 548] time: 697.9642, train_loss: -46.61066818, val_loss: -48.86925507\n",
      "Epoch: [46] [  40/ 548] time: 698.2050, train_loss: -47.50864410, val_loss: -48.43033218\n",
      "Epoch: [46] [  50/ 548] time: 698.4424, train_loss: -46.40223312, val_loss: -49.38521194\n",
      "Epoch: [46] [  60/ 548] time: 698.6811, train_loss: -47.25108719, val_loss: -49.78456116\n",
      "Epoch: [46] [  70/ 548] time: 698.9158, train_loss: -50.96950531, val_loss: -49.17520142\n",
      "Epoch: [46] [  80/ 548] time: 699.1586, train_loss: -51.55441284, val_loss: -48.81770325\n",
      "Epoch: [46] [  90/ 548] time: 699.3956, train_loss: -50.54258347, val_loss: -49.39667130\n",
      "Epoch: [46] [ 100/ 548] time: 699.6347, train_loss: 29.84169769, val_loss: -49.42459488\n",
      "Epoch: [46] [ 110/ 548] time: 699.8744, train_loss: -39.78252792, val_loss: -47.07648087\n",
      "Epoch: [46] [ 120/ 548] time: 700.1106, train_loss: -48.96195221, val_loss: -46.60596848\n",
      "Epoch: [46] [ 130/ 548] time: 700.3557, train_loss: -46.05428314, val_loss: -48.23230743\n",
      "Epoch: [46] [ 140/ 548] time: 700.6013, train_loss: -28.58183479, val_loss: -49.17605972\n",
      "Epoch: [46] [ 150/ 548] time: 700.8480, train_loss: -45.86503983, val_loss: -49.85364151\n",
      "Epoch: [46] [ 160/ 548] time: 701.0932, train_loss: -49.66855621, val_loss: -48.86803436\n",
      "Epoch: [46] [ 170/ 548] time: 701.3598, train_loss: -44.79045105, val_loss: -48.45183563\n",
      "Epoch: [46] [ 180/ 548] time: 701.6071, train_loss: -49.05444336, val_loss: -47.84904861\n",
      "Epoch: [46] [ 190/ 548] time: 701.8561, train_loss: -44.61941528, val_loss: -48.02380753\n",
      "Epoch: [46] [ 200/ 548] time: 702.0991, train_loss: -34.26378632, val_loss: -48.32116318\n",
      "Epoch: [46] [ 210/ 548] time: 702.4062, train_loss: -50.41422653, val_loss: -49.29851151\n",
      "Epoch: [46] [ 220/ 548] time: 702.7046, train_loss: -42.85632324, val_loss: -48.66298676\n",
      "Epoch: [46] [ 230/ 548] time: 702.9747, train_loss: -44.77738953, val_loss: -48.89226913\n",
      "Epoch: [46] [ 240/ 548] time: 703.2477, train_loss: -47.31067657, val_loss: -49.05122375\n",
      "Epoch: [46] [ 250/ 548] time: 703.5087, train_loss: -48.63714981, val_loss: -49.17166138\n",
      "Epoch: [46] [ 260/ 548] time: 703.7538, train_loss: -52.78052139, val_loss: -49.38425446\n",
      "Epoch: [46] [ 270/ 548] time: 703.9975, train_loss: -50.01057816, val_loss: -49.28480911\n",
      "Epoch: [46] [ 280/ 548] time: 704.2467, train_loss: -38.96553421, val_loss: -49.99570847\n",
      "Epoch: [46] [ 290/ 548] time: 704.4889, train_loss: -50.09408569, val_loss: -50.07363892\n",
      "Epoch: [46] [ 300/ 548] time: 704.7398, train_loss: -49.44170380, val_loss: -49.24348831\n",
      "Epoch: [46] [ 310/ 548] time: 704.9818, train_loss: -50.70217514, val_loss: -49.11124420\n",
      "Epoch: [46] [ 320/ 548] time: 705.2276, train_loss: -45.95309448, val_loss: -49.72427368\n",
      "Epoch: [46] [ 330/ 548] time: 705.4852, train_loss: -46.79413605, val_loss: -50.24274445\n",
      "Epoch: [46] [ 340/ 548] time: 705.7376, train_loss: -47.90075684, val_loss: -51.02349854\n",
      "Epoch: [46] [ 350/ 548] time: 705.9822, train_loss: -46.79160309, val_loss: -50.08060455\n",
      "Epoch: [46] [ 360/ 548] time: 706.2453, train_loss: -46.39248276, val_loss: -49.81255341\n",
      "Epoch: [46] [ 370/ 548] time: 706.4954, train_loss: -51.59660339, val_loss: -50.05910110\n",
      "Epoch: [46] [ 380/ 548] time: 706.7437, train_loss: -44.81792450, val_loss: -49.80650711\n",
      "Epoch: [46] [ 390/ 548] time: 706.9875, train_loss: -44.19635773, val_loss: -49.65207291\n",
      "Epoch: [46] [ 400/ 548] time: 707.2247, train_loss: -51.42103195, val_loss: -49.60351562\n",
      "Epoch: [46] [ 410/ 548] time: 707.4644, train_loss: -50.91950226, val_loss: -50.91640854\n",
      "Epoch: [46] [ 420/ 548] time: 707.6969, train_loss: -54.70167923, val_loss: -49.71246719\n",
      "Epoch: [46] [ 430/ 548] time: 707.9341, train_loss: -43.82509232, val_loss: -49.88158798\n",
      "Epoch: [46] [ 440/ 548] time: 708.1690, train_loss: -43.33302689, val_loss: -49.06021118\n",
      "Epoch: [46] [ 450/ 548] time: 708.4101, train_loss: -52.22593689, val_loss: -48.82468414\n",
      "Epoch: [46] [ 460/ 548] time: 708.6763, train_loss: -48.99468231, val_loss: -48.03237534\n",
      "Epoch: [46] [ 470/ 548] time: 708.9469, train_loss: -50.53990173, val_loss: -46.62890625\n",
      "Epoch: [46] [ 480/ 548] time: 709.2215, train_loss: -31.54492760, val_loss: -44.09400940\n",
      "Epoch: [46] [ 490/ 548] time: 709.4777, train_loss: -27.96723557, val_loss: -44.50143051\n",
      "Epoch: [46] [ 500/ 548] time: 709.7205, train_loss: -47.89031982, val_loss: -47.53383255\n",
      "Epoch: [46] [ 510/ 548] time: 709.9618, train_loss: -50.34286118, val_loss: -47.68253326\n",
      "Epoch: [46] [ 520/ 548] time: 710.2063, train_loss: -33.10993958, val_loss: -46.47584534\n",
      "Epoch: [46] [ 530/ 548] time: 710.4501, train_loss: -34.50899124, val_loss: -46.25891876\n",
      "Epoch: [46] [ 540/ 548] time: 710.6974, train_loss: -27.15164566, val_loss: -47.91359329\n",
      "Epoch: [47] [   0/ 548] time: 710.9000, train_loss: -41.36185837, val_loss: -48.14720917\n",
      "Epoch: [47] [  10/ 548] time: 711.1565, train_loss: -51.08760834, val_loss: -48.07722473\n",
      "Epoch: [47] [  20/ 548] time: 711.4211, train_loss: -44.17766953, val_loss: -48.06835556\n",
      "Epoch: [47] [  30/ 548] time: 711.6688, train_loss: -49.30429459, val_loss: -46.57160568\n",
      "Epoch: [47] [  40/ 548] time: 711.9137, train_loss: -40.35838318, val_loss: -47.34495163\n",
      "Epoch: [47] [  50/ 548] time: 712.1537, train_loss: -47.05820465, val_loss: -46.01644135\n",
      "Epoch: [47] [  60/ 548] time: 712.3898, train_loss: -41.39070511, val_loss: -47.12162399\n",
      "Epoch: [47] [  70/ 548] time: 712.6227, train_loss: -39.30519104, val_loss: -48.09456635\n",
      "Epoch: [47] [  80/ 548] time: 712.8732, train_loss: -18.33094788, val_loss: -48.68718338\n",
      "Epoch: [47] [  90/ 548] time: 713.1134, train_loss: -48.85886383, val_loss: -49.28712845\n",
      "Epoch: [47] [ 100/ 548] time: 713.3542, train_loss: -24.78502655, val_loss: -50.05221558\n",
      "Epoch: [47] [ 110/ 548] time: 713.5909, train_loss: -50.19770432, val_loss: -50.03475189\n",
      "Epoch: [47] [ 120/ 548] time: 713.8274, train_loss: -49.97840118, val_loss: -49.02784729\n",
      "Epoch: [47] [ 130/ 548] time: 714.0677, train_loss: -48.05598831, val_loss: -49.83308029\n",
      "Epoch: [47] [ 140/ 548] time: 714.3199, train_loss: -46.26210022, val_loss: -49.95111847\n",
      "Epoch: [47] [ 150/ 548] time: 714.5807, train_loss: -52.98345947, val_loss: -50.08123779\n",
      "Epoch: [47] [ 160/ 548] time: 714.8550, train_loss: -46.68546677, val_loss: -48.71649170\n",
      "Epoch: [47] [ 170/ 548] time: 715.1235, train_loss: -50.72188950, val_loss: -48.86974335\n",
      "Epoch: [47] [ 180/ 548] time: 715.3937, train_loss: -50.89094162, val_loss: -50.10515213\n",
      "Epoch: [47] [ 190/ 548] time: 715.6448, train_loss: -49.90358353, val_loss: -50.20872116\n",
      "Epoch: [47] [ 200/ 548] time: 715.8857, train_loss: -54.76388931, val_loss: -50.71591949\n",
      "Epoch: [47] [ 210/ 548] time: 716.1286, train_loss: -50.59014893, val_loss: -50.13681793\n",
      "Epoch: [47] [ 220/ 548] time: 716.3848, train_loss: -51.50422668, val_loss: -50.08490753\n",
      "Epoch: [47] [ 230/ 548] time: 716.6261, train_loss: -53.70648956, val_loss: -49.80641174\n",
      "Epoch: [47] [ 240/ 548] time: 716.8716, train_loss: -46.75844193, val_loss: -49.47822571\n",
      "Saving checkpoint\n",
      "Epoch: [47] [ 250/ 548] time: 718.1662, train_loss: -18.24637604, val_loss: -49.99108505\n",
      "Epoch: [47] [ 260/ 548] time: 718.4102, train_loss: -42.17305756, val_loss: -50.25303268\n",
      "Epoch: [47] [ 270/ 548] time: 718.6542, train_loss: -46.31543350, val_loss: -47.40090179\n",
      "Epoch: [47] [ 280/ 548] time: 718.8878, train_loss: -50.89745331, val_loss: -45.67873001\n",
      "Epoch: [47] [ 290/ 548] time: 719.1145, train_loss: -52.63587570, val_loss: -46.63893890\n",
      "Epoch: [47] [ 300/ 548] time: 719.3485, train_loss: -51.62521362, val_loss: -48.17653275\n",
      "Epoch: [47] [ 310/ 548] time: 719.5780, train_loss: -49.78852844, val_loss: -48.05446243\n",
      "Epoch: [47] [ 320/ 548] time: 719.8057, train_loss: -48.77626038, val_loss: -47.37600327\n",
      "Epoch: [47] [ 330/ 548] time: 720.0335, train_loss: -38.93003845, val_loss: -49.32646942\n",
      "Epoch: [47] [ 340/ 548] time: 720.2669, train_loss: -47.73743820, val_loss: -48.26844788\n",
      "Epoch: [47] [ 350/ 548] time: 720.5061, train_loss: -42.06877899, val_loss: -45.59230804\n",
      "Epoch: [47] [ 360/ 548] time: 720.7693, train_loss: -36.12731552, val_loss: -46.55093384\n",
      "Epoch: [47] [ 370/ 548] time: 721.0545, train_loss: -42.98732376, val_loss: -46.15106201\n",
      "Epoch: [47] [ 380/ 548] time: 721.3612, train_loss: -48.22956467, val_loss: -47.56807327\n",
      "Epoch: [47] [ 390/ 548] time: 721.6221, train_loss: -44.48517990, val_loss: -48.68181610\n",
      "Epoch: [47] [ 400/ 548] time: 721.8826, train_loss: -42.17079544, val_loss: -49.24348068\n",
      "Epoch: [47] [ 410/ 548] time: 722.1612, train_loss: -48.49707794, val_loss: -48.54079437\n",
      "Epoch: [47] [ 420/ 548] time: 722.4142, train_loss: -47.47808838, val_loss: -49.73674393\n",
      "Epoch: [47] [ 430/ 548] time: 722.6582, train_loss: -42.68956757, val_loss: -46.61365509\n",
      "Epoch: [47] [ 440/ 548] time: 722.8989, train_loss: -40.71614838, val_loss: -48.62244034\n",
      "Epoch: [47] [ 450/ 548] time: 723.1418, train_loss: -43.48979187, val_loss: -48.81040192\n",
      "Epoch: [47] [ 460/ 548] time: 723.3829, train_loss: -46.85095215, val_loss: -48.07594299\n",
      "Epoch: [47] [ 470/ 548] time: 723.6252, train_loss: -44.51131821, val_loss: -48.57000351\n",
      "Epoch: [47] [ 480/ 548] time: 723.8777, train_loss: -52.29674149, val_loss: -49.70618820\n",
      "Epoch: [47] [ 490/ 548] time: 724.1326, train_loss: -53.46961975, val_loss: -50.25737000\n",
      "Epoch: [47] [ 500/ 548] time: 724.3825, train_loss: -45.71276474, val_loss: -49.96369171\n",
      "Epoch: [47] [ 510/ 548] time: 724.6354, train_loss: -46.24086761, val_loss: -50.62362671\n",
      "Epoch: [47] [ 520/ 548] time: 724.8771, train_loss: -50.53717804, val_loss: -50.32864380\n",
      "Epoch: [47] [ 530/ 548] time: 725.1395, train_loss: -50.07069778, val_loss: -50.28767014\n",
      "Epoch: [47] [ 540/ 548] time: 725.5070, train_loss: -50.24153900, val_loss: -49.85318756\n",
      "Epoch: [48] [   0/ 548] time: 725.7905, train_loss: -45.20341110, val_loss: -50.03997421\n",
      "Epoch: [48] [  10/ 548] time: 726.0714, train_loss: -48.18752289, val_loss: -49.21552277\n",
      "Epoch: [48] [  20/ 548] time: 726.3650, train_loss: -47.64445496, val_loss: -50.33376694\n",
      "Epoch: [48] [  30/ 548] time: 726.6833, train_loss: -52.00414276, val_loss: -50.59180450\n",
      "Epoch: [48] [  40/ 548] time: 726.9916, train_loss: -52.21500778, val_loss: -49.65607071\n",
      "Epoch: [48] [  50/ 548] time: 727.2922, train_loss: -52.78782654, val_loss: -50.23190308\n",
      "Epoch: [48] [  60/ 548] time: 727.6160, train_loss: -36.89435959, val_loss: -50.33808899\n",
      "Epoch: [48] [  70/ 548] time: 727.8885, train_loss: -40.47404861, val_loss: -50.60821915\n",
      "Epoch: [48] [  80/ 548] time: 728.1717, train_loss: -53.76995850, val_loss: -49.71000290\n",
      "Epoch: [48] [  90/ 548] time: 728.4211, train_loss: -50.31285858, val_loss: -51.11787796\n",
      "Epoch: [48] [ 100/ 548] time: 728.6773, train_loss: -53.08935928, val_loss: -50.69229889\n",
      "Epoch: [48] [ 110/ 548] time: 728.9236, train_loss: -50.66633224, val_loss: -50.83147812\n",
      "Epoch: [48] [ 120/ 548] time: 729.1734, train_loss: -51.78882599, val_loss: -50.51773834\n",
      "Epoch: [48] [ 130/ 548] time: 729.4349, train_loss: -46.30152512, val_loss: -51.02919769\n",
      "Epoch: [48] [ 140/ 548] time: 729.6814, train_loss: -49.81473923, val_loss: -51.22807312\n",
      "Epoch: [48] [ 150/ 548] time: 729.9245, train_loss: -22.91326523, val_loss: -51.40090942\n",
      "Epoch: [48] [ 160/ 548] time: 730.1643, train_loss: -49.92820740, val_loss: -50.71741486\n",
      "Epoch: [48] [ 170/ 548] time: 730.4046, train_loss: -48.02579117, val_loss: -51.32780075\n",
      "Epoch: [48] [ 180/ 548] time: 730.6372, train_loss: -43.47307968, val_loss: -50.30837250\n",
      "Epoch: [48] [ 190/ 548] time: 730.8745, train_loss: -46.93848038, val_loss: -51.36655045\n",
      "Epoch: [48] [ 200/ 548] time: 731.1095, train_loss: -45.27520370, val_loss: -50.73725891\n",
      "Epoch: [48] [ 210/ 548] time: 731.3645, train_loss: -48.19899750, val_loss: -51.07205582\n",
      "Epoch: [48] [ 220/ 548] time: 731.6042, train_loss: -47.54985809, val_loss: -50.43729401\n",
      "Epoch: [48] [ 230/ 548] time: 731.8413, train_loss: -46.82798767, val_loss: -50.86291122\n",
      "Epoch: [48] [ 240/ 548] time: 732.0867, train_loss: -52.83774567, val_loss: -49.87179184\n",
      "Epoch: [48] [ 250/ 548] time: 732.3270, train_loss: -35.56306076, val_loss: -47.21620941\n",
      "Epoch: [48] [ 260/ 548] time: 732.5702, train_loss: -51.41317368, val_loss: -48.68019485\n",
      "Epoch: [48] [ 270/ 548] time: 732.8214, train_loss: -44.30210876, val_loss: -49.12974548\n",
      "Epoch: [48] [ 280/ 548] time: 733.0869, train_loss: -50.52423477, val_loss: -48.46956253\n",
      "Epoch: [48] [ 290/ 548] time: 733.3650, train_loss: -49.24139404, val_loss: -49.28622055\n",
      "Epoch: [48] [ 300/ 548] time: 733.6374, train_loss: -34.25466537, val_loss: -49.04933929\n",
      "Epoch: [48] [ 310/ 548] time: 733.8862, train_loss: -12.23851776, val_loss: -47.79499817\n",
      "Epoch: [48] [ 320/ 548] time: 734.1257, train_loss: -43.77606201, val_loss: -49.50934982\n",
      "Epoch: [48] [ 330/ 548] time: 734.3688, train_loss: -41.56352234, val_loss: -49.53460693\n",
      "Epoch: [48] [ 340/ 548] time: 734.6118, train_loss: -48.98457336, val_loss: -48.66521072\n",
      "Epoch: [48] [ 350/ 548] time: 734.8511, train_loss: -51.80989456, val_loss: -47.97404099\n",
      "Epoch: [48] [ 360/ 548] time: 735.0936, train_loss: -53.27360916, val_loss: -49.02052689\n",
      "Epoch: [48] [ 370/ 548] time: 735.3404, train_loss: -46.32784271, val_loss: -47.13961792\n",
      "Epoch: [48] [ 380/ 548] time: 735.5801, train_loss: -44.05043793, val_loss: -48.62813950\n",
      "Epoch: [48] [ 390/ 548] time: 735.8231, train_loss: -51.50415039, val_loss: -47.43733978\n",
      "Epoch: [48] [ 400/ 548] time: 736.0603, train_loss: -45.25148392, val_loss: -49.22738266\n",
      "Epoch: [48] [ 410/ 548] time: 736.3144, train_loss: -51.27555466, val_loss: -48.49742508\n",
      "Epoch: [48] [ 420/ 548] time: 736.5562, train_loss: -44.75942230, val_loss: -47.76104736\n",
      "Epoch: [48] [ 430/ 548] time: 736.8190, train_loss: -46.29062271, val_loss: -48.91996002\n",
      "Epoch: [48] [ 440/ 548] time: 737.0857, train_loss: -44.48149109, val_loss: -49.73346710\n",
      "Epoch: [48] [ 450/ 548] time: 737.3380, train_loss: -39.33491516, val_loss: -50.63677597\n",
      "Epoch: [48] [ 460/ 548] time: 737.5891, train_loss: -51.65522766, val_loss: -50.54549408\n",
      "Epoch: [48] [ 470/ 548] time: 737.8479, train_loss: -50.59526062, val_loss: -50.23522949\n",
      "Epoch: [48] [ 480/ 548] time: 738.0941, train_loss: -49.90410233, val_loss: -51.44445038\n",
      "Epoch: [48] [ 490/ 548] time: 738.3489, train_loss: -43.05094528, val_loss: -50.22048950\n",
      "Epoch: [48] [ 500/ 548] time: 738.5916, train_loss: -43.87189102, val_loss: -50.14091492\n",
      "Epoch: [48] [ 510/ 548] time: 738.8502, train_loss: -48.75633240, val_loss: -49.82152176\n",
      "Epoch: [48] [ 520/ 548] time: 739.1137, train_loss: -24.99769592, val_loss: -50.26355362\n",
      "Epoch: [48] [ 530/ 548] time: 739.3904, train_loss: -52.42303085, val_loss: -49.69801331\n",
      "Epoch: [48] [ 540/ 548] time: 739.6648, train_loss: -40.60567093, val_loss: -50.99748611\n",
      "Epoch: [49] [   0/ 548] time: 739.8856, train_loss: -50.30090332, val_loss: -50.09119415\n",
      "Epoch: [49] [  10/ 548] time: 740.1394, train_loss: -53.93244553, val_loss: -50.87782669\n",
      "Epoch: [49] [  20/ 548] time: 740.4076, train_loss: -52.96118164, val_loss: -51.01729202\n",
      "Epoch: [49] [  30/ 548] time: 740.6518, train_loss: -48.07532501, val_loss: -50.40425491\n",
      "Epoch: [49] [  40/ 548] time: 740.9053, train_loss: -51.55959320, val_loss: -49.32315063\n",
      "Epoch: [49] [  50/ 548] time: 741.1482, train_loss: -42.63056946, val_loss: -49.44820786\n",
      "Epoch: [49] [  60/ 548] time: 741.3974, train_loss: -48.05119705, val_loss: -48.43366241\n",
      "Epoch: [49] [  70/ 548] time: 741.6361, train_loss: -49.17185974, val_loss: -47.72132111\n",
      "Epoch: [49] [  80/ 548] time: 741.8826, train_loss: -39.60641098, val_loss: -48.79949951\n",
      "Epoch: [49] [  90/ 548] time: 742.1139, train_loss: -53.13842773, val_loss: -49.19208908\n",
      "Epoch: [49] [ 100/ 548] time: 742.3579, train_loss: -51.05461121, val_loss: -50.38380432\n",
      "Epoch: [49] [ 110/ 548] time: 742.6066, train_loss: -50.74492264, val_loss: -50.26651382\n",
      "Epoch: [49] [ 120/ 548] time: 742.8460, train_loss: -32.51295471, val_loss: -49.56898117\n",
      "Epoch: [49] [ 130/ 548] time: 743.0906, train_loss: -46.20320129, val_loss: -49.90326691\n",
      "Epoch: [49] [ 140/ 548] time: 743.3382, train_loss: -52.51540375, val_loss: -49.52542877\n",
      "Saving checkpoint\n",
      "Epoch: [49] [ 150/ 548] time: 744.8128, train_loss: -53.69194031, val_loss: -50.06622314\n",
      "Epoch: [49] [ 160/ 548] time: 745.0696, train_loss: -48.66834259, val_loss: -49.93849182\n",
      "Epoch: [49] [ 170/ 548] time: 745.3459, train_loss: -50.05310440, val_loss: -49.57136154\n",
      "Epoch: [49] [ 180/ 548] time: 745.6067, train_loss: -50.06704330, val_loss: -49.55078125\n",
      "Epoch: [49] [ 190/ 548] time: 745.8506, train_loss: -50.71580887, val_loss: -51.21051788\n",
      "Epoch: [49] [ 200/ 548] time: 746.0813, train_loss: -54.17108154, val_loss: -51.16728592\n",
      "Epoch: [49] [ 210/ 548] time: 746.3139, train_loss: -49.67450714, val_loss: -50.84627914\n",
      "Epoch: [49] [ 220/ 548] time: 746.5497, train_loss: -48.37940979, val_loss: -50.01248550\n",
      "Epoch: [49] [ 230/ 548] time: 746.8013, train_loss: -45.24982071, val_loss: -50.31662750\n",
      "Epoch: [49] [ 240/ 548] time: 747.0545, train_loss: -49.12802124, val_loss: -50.55636597\n",
      "Epoch: [49] [ 250/ 548] time: 747.3268, train_loss: -47.04066086, val_loss: -50.63964844\n",
      "Epoch: [49] [ 260/ 548] time: 747.5874, train_loss: -47.59445953, val_loss: -51.11792755\n",
      "Epoch: [49] [ 270/ 548] time: 747.8406, train_loss: -52.31298447, val_loss: -49.95291901\n",
      "Epoch: [49] [ 280/ 548] time: 748.0886, train_loss: -35.65472794, val_loss: -50.45092392\n",
      "Epoch: [49] [ 290/ 548] time: 748.3545, train_loss: -49.95574188, val_loss: -51.23091888\n",
      "Epoch: [49] [ 300/ 548] time: 748.6163, train_loss: -49.87027359, val_loss: -50.28424072\n",
      "Epoch: [49] [ 310/ 548] time: 748.8784, train_loss: -43.39992523, val_loss: -49.02120590\n",
      "Epoch: [49] [ 320/ 548] time: 749.1481, train_loss: -51.74636078, val_loss: -49.92120361\n",
      "Epoch: [49] [ 330/ 548] time: 749.4002, train_loss: -25.83366013, val_loss: -49.98265457\n",
      "Epoch: [49] [ 340/ 548] time: 749.6424, train_loss: -47.85199738, val_loss: -47.90920258\n",
      "Epoch: [49] [ 350/ 548] time: 749.8863, train_loss: -50.93620300, val_loss: -48.97850800\n",
      "Epoch: [49] [ 360/ 548] time: 750.1944, train_loss: -47.41601562, val_loss: -48.89149094\n",
      "Epoch: [49] [ 370/ 548] time: 750.4845, train_loss: -51.12912750, val_loss: -47.88367462\n",
      "Epoch: [49] [ 380/ 548] time: 750.7510, train_loss: -49.61529160, val_loss: -48.17504120\n",
      "Epoch: [49] [ 390/ 548] time: 751.1194, train_loss: -49.17543030, val_loss: -47.57170868\n",
      "Epoch: [49] [ 400/ 548] time: 751.4600, train_loss: -47.75468445, val_loss: -50.05858994\n",
      "Epoch: [49] [ 410/ 548] time: 751.8189, train_loss: -50.14911652, val_loss: -50.95274353\n",
      "Epoch: [49] [ 420/ 548] time: 752.1705, train_loss: -44.76210785, val_loss: -51.09567261\n",
      "Epoch: [49] [ 430/ 548] time: 752.5194, train_loss: -40.19228745, val_loss: -49.08384323\n",
      "Epoch: [49] [ 440/ 548] time: 752.8390, train_loss: -47.32157516, val_loss: -49.89621353\n",
      "Epoch: [49] [ 450/ 548] time: 753.1451, train_loss: -50.30490112, val_loss: -49.44783020\n",
      "Epoch: [49] [ 460/ 548] time: 753.4503, train_loss: -51.43915558, val_loss: -50.61838913\n",
      "Epoch: [49] [ 470/ 548] time: 753.7701, train_loss: -50.41654968, val_loss: -50.91042709\n",
      "Epoch: [49] [ 480/ 548] time: 754.0699, train_loss: -51.74588776, val_loss: -51.10248184\n",
      "Epoch: [49] [ 490/ 548] time: 754.3760, train_loss: -51.46873093, val_loss: -52.09597778\n",
      "Epoch: [49] [ 500/ 548] time: 754.6546, train_loss: -51.45590591, val_loss: -51.73703003\n",
      "Epoch: [49] [ 510/ 548] time: 754.9168, train_loss: -49.32627869, val_loss: -51.49999237\n",
      "Epoch: [49] [ 520/ 548] time: 755.1798, train_loss: -53.45415878, val_loss: -51.88207245\n",
      "Epoch: [49] [ 530/ 548] time: 755.4713, train_loss: -49.49833679, val_loss: -50.81947327\n",
      "Epoch: [49] [ 540/ 548] time: 755.7364, train_loss: -49.62620926, val_loss: -50.93938065\n",
      "Epoch: [50] [   0/ 548] time: 755.9417, train_loss: -44.83705902, val_loss: -51.54958344\n",
      "Epoch: [50] [  10/ 548] time: 756.2063, train_loss: -51.22845459, val_loss: -51.82253265\n",
      "Epoch: [50] [  20/ 548] time: 756.5104, train_loss: -52.98067474, val_loss: -51.94607162\n",
      "Epoch: [50] [  30/ 548] time: 756.7585, train_loss: -50.15151215, val_loss: -51.63925552\n",
      "Epoch: [50] [  40/ 548] time: 757.0013, train_loss: -49.89986801, val_loss: -48.81535339\n",
      "Epoch: [50] [  50/ 548] time: 757.2455, train_loss: -49.31053543, val_loss: -49.99404907\n",
      "Epoch: [50] [  60/ 548] time: 757.4965, train_loss: -49.40292358, val_loss: -51.12351227\n",
      "Epoch: [50] [  70/ 548] time: 757.7626, train_loss: -53.43045807, val_loss: -51.45825195\n",
      "Epoch: [50] [  80/ 548] time: 758.0424, train_loss: -52.17912292, val_loss: -51.50397491\n",
      "Epoch: [50] [  90/ 548] time: 758.3130, train_loss: -48.73244476, val_loss: -51.48434067\n",
      "Epoch: [50] [ 100/ 548] time: 758.5762, train_loss: -41.17499542, val_loss: -51.05846405\n",
      "Epoch: [50] [ 110/ 548] time: 758.8322, train_loss: -51.72885895, val_loss: -51.23810577\n",
      "Epoch: [50] [ 120/ 548] time: 759.0720, train_loss: -41.34497833, val_loss: -51.73862076\n",
      "Epoch: [50] [ 130/ 548] time: 759.3123, train_loss: -52.81964493, val_loss: -51.22926331\n",
      "Epoch: [50] [ 140/ 548] time: 759.5488, train_loss: -42.76149750, val_loss: -51.24453735\n",
      "Epoch: [50] [ 150/ 548] time: 759.7825, train_loss: -28.49136734, val_loss: -49.67544937\n",
      "Epoch: [50] [ 160/ 548] time: 760.0240, train_loss: -46.95020676, val_loss: -48.12082672\n",
      "Epoch: [50] [ 170/ 548] time: 760.2598, train_loss: -42.53713226, val_loss: -46.69899750\n",
      "Epoch: [50] [ 180/ 548] time: 760.5011, train_loss: -40.95024490, val_loss: -47.61655807\n",
      "Epoch: [50] [ 190/ 548] time: 760.7351, train_loss: -47.15113831, val_loss: -48.40798187\n",
      "Epoch: [50] [ 200/ 548] time: 760.9676, train_loss: -38.09270096, val_loss: -47.74478531\n",
      "Epoch: [50] [ 210/ 548] time: 761.2168, train_loss: -47.75175858, val_loss: -46.70336914\n",
      "Epoch: [50] [ 220/ 548] time: 761.4731, train_loss: -49.90267944, val_loss: -50.67162323\n",
      "Epoch: [50] [ 230/ 548] time: 761.7229, train_loss: -52.65100098, val_loss: -49.07371521\n",
      "Epoch: [50] [ 240/ 548] time: 761.9650, train_loss: -44.07323837, val_loss: -48.10863495\n",
      "Epoch: [50] [ 250/ 548] time: 762.2210, train_loss: -48.32109833, val_loss: -48.53369904\n",
      "Epoch: [50] [ 260/ 548] time: 762.4665, train_loss: -47.72088623, val_loss: -50.66231918\n",
      "Epoch: [50] [ 270/ 548] time: 762.7110, train_loss: -42.33798981, val_loss: -50.20700073\n",
      "Epoch: [50] [ 280/ 548] time: 762.9585, train_loss: -39.31484985, val_loss: -46.89047623\n",
      "Epoch: [50] [ 290/ 548] time: 763.2110, train_loss: -37.48253250, val_loss: -50.58453369\n",
      "Epoch: [50] [ 300/ 548] time: 763.4611, train_loss: -30.96327591, val_loss: -50.58606720\n",
      "Epoch: [50] [ 310/ 548] time: 763.7261, train_loss: -51.85813522, val_loss: -49.58376312\n",
      "Epoch: [50] [ 320/ 548] time: 763.9946, train_loss: -40.78083801, val_loss: -48.46173859\n",
      "Epoch: [50] [ 330/ 548] time: 764.2778, train_loss: -48.64697647, val_loss: -48.12947083\n",
      "Epoch: [50] [ 340/ 548] time: 764.5718, train_loss: -45.91744995, val_loss: -50.61334991\n",
      "Epoch: [50] [ 350/ 548] time: 764.8321, train_loss: -47.23032379, val_loss: -49.86824417\n",
      "Epoch: [50] [ 360/ 548] time: 765.0950, train_loss: -40.43417358, val_loss: -50.40235138\n",
      "Epoch: [50] [ 370/ 548] time: 765.3526, train_loss: -53.86859131, val_loss: -50.37024689\n",
      "Epoch: [50] [ 380/ 548] time: 765.6090, train_loss: -38.86605453, val_loss: -50.88906097\n",
      "Epoch: [50] [ 390/ 548] time: 765.8573, train_loss: -50.03026199, val_loss: -50.22546387\n",
      "Epoch: [50] [ 400/ 548] time: 766.1054, train_loss: -45.98997498, val_loss: -50.06339264\n",
      "Epoch: [50] [ 410/ 548] time: 766.3593, train_loss: -51.21639252, val_loss: -50.64302063\n",
      "Epoch: [50] [ 420/ 548] time: 766.6160, train_loss: -50.24469376, val_loss: -50.72601700\n",
      "Epoch: [50] [ 430/ 548] time: 766.8661, train_loss: -51.03815460, val_loss: -50.93368912\n",
      "Epoch: [50] [ 440/ 548] time: 767.1147, train_loss: -54.86513901, val_loss: -51.13587189\n",
      "Epoch: [50] [ 450/ 548] time: 767.3582, train_loss: -48.67804718, val_loss: -49.76576614\n",
      "Epoch: [50] [ 460/ 548] time: 767.6052, train_loss: -50.50746536, val_loss: -50.24260712\n",
      "Epoch: [50] [ 470/ 548] time: 767.8624, train_loss: -40.38983154, val_loss: -51.29596710\n",
      "Epoch: [50] [ 480/ 548] time: 768.1053, train_loss: -42.93128967, val_loss: -51.47299194\n",
      "Epoch: [50] [ 490/ 548] time: 768.3425, train_loss: -51.53094864, val_loss: -51.23450851\n",
      "Epoch: [50] [ 500/ 548] time: 768.5818, train_loss: -54.14334488, val_loss: -50.92117310\n",
      "Epoch: [50] [ 510/ 548] time: 768.8190, train_loss: -54.16447449, val_loss: -51.92192459\n",
      "Epoch: [50] [ 520/ 548] time: 769.0520, train_loss: -33.39120483, val_loss: -52.03123093\n",
      "Epoch: [50] [ 530/ 548] time: 769.2869, train_loss: -47.82898712, val_loss: -52.70603180\n",
      "Epoch: [50] [ 540/ 548] time: 769.5239, train_loss: -56.10214233, val_loss: -52.76369095\n",
      "Epoch: [51] [   0/ 548] time: 769.7156, train_loss: -50.08886719, val_loss: -53.13829041\n",
      "Epoch: [51] [  10/ 548] time: 769.9776, train_loss: -54.85231400, val_loss: -52.23537445\n",
      "Epoch: [51] [  20/ 548] time: 770.2475, train_loss: -49.60400391, val_loss: -52.09313583\n",
      "Epoch: [51] [  30/ 548] time: 770.5169, train_loss: -36.43241119, val_loss: -52.08082199\n",
      "Epoch: [51] [  40/ 548] time: 770.7837, train_loss: -50.16366577, val_loss: -52.39399719\n",
      "Epoch: [51] [  50/ 548] time: 771.0284, train_loss: -50.42581177, val_loss: -51.94258881\n",
      "Saving checkpoint\n",
      "Epoch: [51] [  60/ 548] time: 772.4326, train_loss: -53.01582336, val_loss: -52.72867203\n",
      "Epoch: [51] [  70/ 548] time: 772.7060, train_loss: -54.58802414, val_loss: -52.77296448\n",
      "Epoch: [51] [  80/ 548] time: 772.9575, train_loss: -48.29533005, val_loss: -51.66092300\n",
      "Epoch: [51] [  90/ 548] time: 773.2085, train_loss: -54.47283936, val_loss: -52.22422409\n",
      "Epoch: [51] [ 100/ 548] time: 773.4592, train_loss: -39.05085754, val_loss: -52.61645508\n",
      "Epoch: [51] [ 110/ 548] time: 773.7075, train_loss: -51.86399841, val_loss: -51.90117645\n",
      "Epoch: [51] [ 120/ 548] time: 773.9552, train_loss: -50.46316528, val_loss: -52.41563034\n",
      "Epoch: [51] [ 130/ 548] time: 774.2101, train_loss: -52.56391525, val_loss: -52.48370361\n",
      "Epoch: [51] [ 140/ 548] time: 774.4550, train_loss: -51.08592606, val_loss: -51.80685043\n",
      "Epoch: [51] [ 150/ 548] time: 774.6981, train_loss: -50.98181915, val_loss: -51.55674362\n",
      "Epoch: [51] [ 160/ 548] time: 774.9428, train_loss: -52.77005386, val_loss: -51.60135269\n",
      "Epoch: [51] [ 170/ 548] time: 775.1899, train_loss: -50.75082779, val_loss: -51.53558350\n",
      "Epoch: [51] [ 180/ 548] time: 775.4438, train_loss: -45.14157104, val_loss: -51.49472809\n",
      "Epoch: [51] [ 190/ 548] time: 775.6879, train_loss: -44.03692627, val_loss: -51.14507294\n",
      "Epoch: [51] [ 200/ 548] time: 775.9553, train_loss: -52.50173950, val_loss: -51.88950348\n",
      "Epoch: [51] [ 210/ 548] time: 776.2328, train_loss: -51.37260056, val_loss: -51.87025833\n",
      "Epoch: [51] [ 220/ 548] time: 776.5180, train_loss: -52.95615768, val_loss: -50.87409973\n",
      "Epoch: [51] [ 230/ 548] time: 776.7632, train_loss: -51.04074097, val_loss: -51.45848846\n",
      "Epoch: [51] [ 240/ 548] time: 777.0142, train_loss: -53.08498001, val_loss: -50.42000580\n",
      "Epoch: [51] [ 250/ 548] time: 777.2695, train_loss: -49.93796539, val_loss: -51.70386887\n",
      "Epoch: [51] [ 260/ 548] time: 777.5183, train_loss: -52.26509476, val_loss: -49.37532425\n",
      "Epoch: [51] [ 270/ 548] time: 777.7642, train_loss: -50.01638031, val_loss: -50.47403336\n",
      "Epoch: [51] [ 280/ 548] time: 778.0117, train_loss: -54.48729706, val_loss: -51.33943939\n",
      "Epoch: [51] [ 290/ 548] time: 778.2537, train_loss: -48.86913300, val_loss: -51.83829117\n",
      "Epoch: [51] [ 300/ 548] time: 778.4961, train_loss: -56.02805710, val_loss: -52.67955780\n",
      "Epoch: [51] [ 310/ 548] time: 778.7409, train_loss: -51.34545898, val_loss: -51.96608734\n",
      "Epoch: [51] [ 320/ 548] time: 778.9897, train_loss: -56.15630341, val_loss: -51.84217072\n",
      "Epoch: [51] [ 330/ 548] time: 779.2324, train_loss: -44.83248520, val_loss: -52.66621399\n",
      "Epoch: [51] [ 340/ 548] time: 779.4783, train_loss: -48.09888077, val_loss: -50.15151215\n",
      "Epoch: [51] [ 350/ 548] time: 779.7215, train_loss: -48.53457260, val_loss: -48.02500153\n",
      "Epoch: [51] [ 360/ 548] time: 779.9639, train_loss: -46.22380447, val_loss: -50.28578186\n",
      "Epoch: [51] [ 370/ 548] time: 780.2126, train_loss: -45.48937988, val_loss: -51.42569733\n",
      "Epoch: [51] [ 380/ 548] time: 780.4557, train_loss: -51.32367325, val_loss: -51.13190460\n",
      "Epoch: [51] [ 390/ 548] time: 780.6989, train_loss: -48.92121506, val_loss: -51.61343002\n",
      "Epoch: [51] [ 400/ 548] time: 780.9548, train_loss: -46.76683044, val_loss: -51.14501190\n",
      "Epoch: [51] [ 410/ 548] time: 781.2156, train_loss: -48.28636169, val_loss: -50.23275757\n",
      "Epoch: [51] [ 420/ 548] time: 781.4814, train_loss: -48.81167603, val_loss: -51.33748627\n",
      "Epoch: [51] [ 430/ 548] time: 781.7412, train_loss: -38.19438171, val_loss: -52.27669144\n",
      "Epoch: [51] [ 440/ 548] time: 782.0247, train_loss: -47.77344513, val_loss: -50.82855225\n",
      "Epoch: [51] [ 450/ 548] time: 782.3692, train_loss: -50.18567276, val_loss: -50.94439697\n",
      "Epoch: [51] [ 460/ 548] time: 782.6604, train_loss: -51.63447571, val_loss: -50.69602585\n",
      "Epoch: [51] [ 470/ 548] time: 782.9445, train_loss: -52.04201508, val_loss: -50.86949921\n",
      "Epoch: [51] [ 480/ 548] time: 783.1994, train_loss: -38.92321014, val_loss: -52.83213806\n",
      "Epoch: [51] [ 490/ 548] time: 783.4447, train_loss: -47.96346283, val_loss: -50.61679077\n",
      "Epoch: [51] [ 500/ 548] time: 783.6900, train_loss: -52.97523880, val_loss: -50.80917358\n",
      "Epoch: [51] [ 510/ 548] time: 783.9393, train_loss: -54.06491470, val_loss: -51.49721146\n",
      "Epoch: [51] [ 520/ 548] time: 784.1920, train_loss: -39.24243927, val_loss: -52.15613174\n",
      "Epoch: [51] [ 530/ 548] time: 784.4274, train_loss: -53.11983109, val_loss: -50.13212204\n",
      "Epoch: [51] [ 540/ 548] time: 784.6646, train_loss: -42.25878906, val_loss: -51.63465118\n",
      "Epoch: [52] [   0/ 548] time: 784.8596, train_loss: -54.38553619, val_loss: -49.34685516\n",
      "Epoch: [52] [  10/ 548] time: 785.1110, train_loss: -51.27713013, val_loss: -49.98812103\n",
      "Epoch: [52] [  20/ 548] time: 785.4020, train_loss: -47.20891571, val_loss: -51.47623444\n",
      "Epoch: [52] [  30/ 548] time: 785.6811, train_loss: -50.19077301, val_loss: -51.04740906\n",
      "Epoch: [52] [  40/ 548] time: 785.9311, train_loss: -51.55720139, val_loss: -49.13356781\n",
      "Epoch: [52] [  50/ 548] time: 786.1812, train_loss: -50.82296371, val_loss: -51.40109634\n",
      "Epoch: [52] [  60/ 548] time: 786.4653, train_loss: -47.79923248, val_loss: -51.96975708\n",
      "Epoch: [52] [  70/ 548] time: 786.7220, train_loss: -51.64217377, val_loss: -52.46060181\n",
      "Epoch: [52] [  80/ 548] time: 786.9646, train_loss: -51.76411438, val_loss: -50.16790771\n",
      "Epoch: [52] [  90/ 548] time: 787.2282, train_loss: -53.47672653, val_loss: -48.90841675\n",
      "Epoch: [52] [ 100/ 548] time: 787.4825, train_loss: -41.98459625, val_loss: -49.33703232\n",
      "Epoch: [52] [ 110/ 548] time: 787.7287, train_loss: -43.63394928, val_loss: -45.76204300\n",
      "Epoch: [52] [ 120/ 548] time: 788.0024, train_loss: -34.12683105, val_loss: -50.52605820\n",
      "Epoch: [52] [ 130/ 548] time: 788.2730, train_loss: -50.69803238, val_loss: -46.91568756\n",
      "Epoch: [52] [ 140/ 548] time: 788.5649, train_loss: -45.87939835, val_loss: -45.50406647\n",
      "Epoch: [52] [ 150/ 548] time: 788.8586, train_loss: -38.38301849, val_loss: -44.63955307\n",
      "Epoch: [52] [ 160/ 548] time: 789.1192, train_loss: -36.25740051, val_loss: -44.21342468\n",
      "Epoch: [52] [ 170/ 548] time: 789.3636, train_loss: -51.05713654, val_loss: -47.73255539\n",
      "Epoch: [52] [ 180/ 548] time: 789.6068, train_loss: -52.18056488, val_loss: -49.64860153\n",
      "Epoch: [52] [ 190/ 548] time: 789.8488, train_loss: -48.36763763, val_loss: -50.21067047\n",
      "Epoch: [52] [ 200/ 548] time: 790.0935, train_loss: -43.17100525, val_loss: -50.12637329\n",
      "Epoch: [52] [ 210/ 548] time: 790.3393, train_loss: -51.63354874, val_loss: -50.66688538\n",
      "Epoch: [52] [ 220/ 548] time: 790.5789, train_loss: -51.64479065, val_loss: -50.63226700\n",
      "Epoch: [52] [ 230/ 548] time: 790.8398, train_loss: -52.42322159, val_loss: -52.16384888\n",
      "Epoch: [52] [ 240/ 548] time: 791.0894, train_loss: -51.98742294, val_loss: -52.26540756\n",
      "Epoch: [52] [ 250/ 548] time: 791.3463, train_loss: -46.33238602, val_loss: -52.01126862\n",
      "Epoch: [52] [ 260/ 548] time: 791.5990, train_loss: -55.01219559, val_loss: -51.31196213\n",
      "Epoch: [52] [ 270/ 548] time: 791.8496, train_loss: -52.84085083, val_loss: -51.55064774\n",
      "Epoch: [52] [ 280/ 548] time: 792.0962, train_loss: -52.16242218, val_loss: -52.61559296\n",
      "Epoch: [52] [ 290/ 548] time: 792.3507, train_loss: -51.88137817, val_loss: -52.95089722\n",
      "Epoch: [52] [ 300/ 548] time: 792.5912, train_loss: -53.76156616, val_loss: -53.60742188\n",
      "Epoch: [52] [ 310/ 548] time: 792.8272, train_loss: -46.57590866, val_loss: -52.46844482\n",
      "Epoch: [52] [ 320/ 548] time: 793.0680, train_loss: -51.22005081, val_loss: -52.81150436\n",
      "Epoch: [52] [ 330/ 548] time: 793.3023, train_loss: -50.05152893, val_loss: -51.50942993\n",
      "Epoch: [52] [ 340/ 548] time: 793.5324, train_loss: -46.88707733, val_loss: -52.42879486\n",
      "Epoch: [52] [ 350/ 548] time: 793.7675, train_loss: -52.92625809, val_loss: -52.42066193\n",
      "Epoch: [52] [ 360/ 548] time: 794.0027, train_loss: -56.38325500, val_loss: -52.79575348\n",
      "Epoch: [52] [ 370/ 548] time: 794.2754, train_loss: -46.09250641, val_loss: -53.00841141\n",
      "Epoch: [52] [ 380/ 548] time: 794.5357, train_loss: -47.41913605, val_loss: -51.89673996\n",
      "Epoch: [52] [ 390/ 548] time: 794.8102, train_loss: -54.41721725, val_loss: -51.53224564\n",
      "Epoch: [52] [ 400/ 548] time: 795.0755, train_loss: -47.84283447, val_loss: -52.76512527\n",
      "Epoch: [52] [ 410/ 548] time: 795.3177, train_loss: -51.42845154, val_loss: -52.24458313\n",
      "Epoch: [52] [ 420/ 548] time: 795.5617, train_loss: -56.21811676, val_loss: -53.05425644\n",
      "Epoch: [52] [ 430/ 548] time: 795.8038, train_loss: -50.74593353, val_loss: -51.95442581\n",
      "Epoch: [52] [ 440/ 548] time: 796.0514, train_loss: -48.76451874, val_loss: -50.97303391\n",
      "Epoch: [52] [ 450/ 548] time: 796.3023, train_loss: -49.61290359, val_loss: -51.07580185\n",
      "Epoch: [52] [ 460/ 548] time: 796.5591, train_loss: -39.22397614, val_loss: -51.70055389\n",
      "Epoch: [52] [ 470/ 548] time: 796.8045, train_loss: -33.14574814, val_loss: -44.10630798\n",
      "Epoch: [52] [ 480/ 548] time: 797.0472, train_loss: -49.43175125, val_loss: -44.59875488\n",
      "Epoch: [52] [ 490/ 548] time: 797.2930, train_loss: -45.67319107, val_loss: -41.63960648\n",
      "Epoch: [52] [ 500/ 548] time: 797.5358, train_loss: -47.91105652, val_loss: -41.96013641\n",
      "Saving checkpoint\n",
      "Epoch: [52] [ 510/ 548] time: 798.8993, train_loss: -42.86087799, val_loss: -33.94228745\n",
      "Epoch: [52] [ 520/ 548] time: 799.1455, train_loss: -42.56444168, val_loss: -40.82687378\n",
      "Epoch: [52] [ 530/ 548] time: 799.3954, train_loss: -47.43796921, val_loss: -44.82344437\n",
      "Epoch: [52] [ 540/ 548] time: 799.6534, train_loss: -45.61877441, val_loss: -45.07557678\n",
      "Epoch: [53] [   0/ 548] time: 799.8440, train_loss: -42.70992279, val_loss: -42.79663086\n",
      "Epoch: [53] [  10/ 548] time: 800.0856, train_loss: -37.97819519, val_loss: -50.37570953\n",
      "Epoch: [53] [  20/ 548] time: 800.3411, train_loss: -50.26002502, val_loss: -48.63957214\n",
      "Epoch: [53] [  30/ 548] time: 800.5861, train_loss: -47.63309479, val_loss: -50.37470627\n",
      "Epoch: [53] [  40/ 548] time: 800.8378, train_loss: 16.07169724, val_loss: -50.73226929\n",
      "Epoch: [53] [  50/ 548] time: 801.0825, train_loss: -45.09933472, val_loss: -51.90959167\n",
      "Epoch: [53] [  60/ 548] time: 801.3381, train_loss: -51.36404419, val_loss: -52.03493500\n",
      "Epoch: [53] [  70/ 548] time: 801.5805, train_loss: -51.46784210, val_loss: -51.47571564\n",
      "Epoch: [53] [  80/ 548] time: 801.8165, train_loss: -52.95093155, val_loss: -50.66539383\n",
      "Epoch: [53] [  90/ 548] time: 802.0451, train_loss: -53.34609222, val_loss: -51.12026978\n",
      "Epoch: [53] [ 100/ 548] time: 802.2834, train_loss: -49.10966492, val_loss: -51.51095581\n",
      "Epoch: [53] [ 110/ 548] time: 802.5138, train_loss: -51.88109589, val_loss: -52.68541718\n",
      "Epoch: [53] [ 120/ 548] time: 802.7488, train_loss: -49.85565948, val_loss: -52.48838043\n",
      "Epoch: [53] [ 130/ 548] time: 803.0100, train_loss: -51.97536850, val_loss: -52.60147476\n",
      "Epoch: [53] [ 140/ 548] time: 803.2620, train_loss: -50.32162476, val_loss: -49.91079330\n",
      "Epoch: [53] [ 150/ 548] time: 803.5157, train_loss: -51.83433914, val_loss: -51.14915466\n",
      "Epoch: [53] [ 160/ 548] time: 803.7642, train_loss: -49.06053925, val_loss: -51.33054352\n",
      "Epoch: [53] [ 170/ 548] time: 804.0173, train_loss: -52.97089386, val_loss: -51.90948486\n",
      "Epoch: [53] [ 180/ 548] time: 804.2741, train_loss: -52.55787277, val_loss: -52.09215927\n",
      "Epoch: [53] [ 190/ 548] time: 804.5316, train_loss: -48.99291611, val_loss: -51.67752457\n",
      "Epoch: [53] [ 200/ 548] time: 804.7791, train_loss: -46.74166107, val_loss: -52.00871658\n",
      "Epoch: [53] [ 210/ 548] time: 805.0274, train_loss: -51.31006622, val_loss: -52.73781204\n",
      "Epoch: [53] [ 220/ 548] time: 805.2766, train_loss: -48.96264648, val_loss: -53.34414291\n",
      "Epoch: [53] [ 230/ 548] time: 805.5184, train_loss: -52.80327606, val_loss: -53.16887283\n",
      "Epoch: [53] [ 240/ 548] time: 805.7620, train_loss: -54.91418839, val_loss: -52.60695648\n",
      "Epoch: [53] [ 250/ 548] time: 806.0302, train_loss: -47.06216049, val_loss: -52.75631714\n",
      "Epoch: [53] [ 260/ 548] time: 806.3085, train_loss: -48.13896942, val_loss: -52.08692551\n",
      "Epoch: [53] [ 270/ 548] time: 806.5908, train_loss: -49.86705780, val_loss: -51.15098572\n",
      "Epoch: [53] [ 280/ 548] time: 806.8590, train_loss: -51.94163132, val_loss: -51.38676453\n",
      "Epoch: [53] [ 290/ 548] time: 807.1023, train_loss: -49.31282043, val_loss: -51.89088058\n",
      "Epoch: [53] [ 300/ 548] time: 807.3688, train_loss: -50.95919800, val_loss: -52.38983154\n",
      "Epoch: [53] [ 310/ 548] time: 807.6121, train_loss: -47.19487381, val_loss: -44.37012863\n",
      "Epoch: [53] [ 320/ 548] time: 807.8661, train_loss: -50.91878128, val_loss: -49.65552902\n",
      "Epoch: [53] [ 330/ 548] time: 808.1395, train_loss: -51.61021423, val_loss: -50.04076004\n",
      "Epoch: [53] [ 340/ 548] time: 808.3881, train_loss: -53.84391403, val_loss: -50.40746307\n",
      "Epoch: [53] [ 350/ 548] time: 808.6330, train_loss: -49.53971863, val_loss: -51.44635391\n",
      "Epoch: [53] [ 360/ 548] time: 808.8802, train_loss: -47.25628662, val_loss: -51.61922455\n",
      "Epoch: [53] [ 370/ 548] time: 809.1257, train_loss: -53.50393677, val_loss: -52.47172546\n",
      "Epoch: [53] [ 380/ 548] time: 809.3719, train_loss: -49.56487274, val_loss: -52.74567032\n",
      "Epoch: [53] [ 390/ 548] time: 809.6155, train_loss: -48.51126862, val_loss: -53.17493820\n",
      "Epoch: [53] [ 400/ 548] time: 809.8563, train_loss: -47.15396118, val_loss: -53.45116425\n",
      "Epoch: [53] [ 410/ 548] time: 810.1000, train_loss: -54.35729599, val_loss: -52.06331635\n",
      "Epoch: [53] [ 420/ 548] time: 810.3413, train_loss: -51.06854630, val_loss: -53.12644958\n",
      "Epoch: [53] [ 430/ 548] time: 810.5750, train_loss: -28.34119797, val_loss: -52.40408325\n",
      "Epoch: [53] [ 440/ 548] time: 810.8182, train_loss: -53.15089798, val_loss: -53.21113586\n",
      "Epoch: [53] [ 450/ 548] time: 811.0552, train_loss: -53.02613068, val_loss: -53.53414917\n",
      "Epoch: [53] [ 460/ 548] time: 811.2884, train_loss: -50.03903198, val_loss: -53.30437469\n",
      "Epoch: [53] [ 470/ 548] time: 811.5819, train_loss: -53.34114075, val_loss: -52.87396622\n",
      "Epoch: [53] [ 480/ 548] time: 811.8362, train_loss: -54.26153946, val_loss: -53.16817474\n",
      "Epoch: [53] [ 490/ 548] time: 812.1018, train_loss: -51.75643158, val_loss: -53.60733032\n",
      "Epoch: [53] [ 500/ 548] time: 812.4186, train_loss: -54.74259186, val_loss: -53.59892654\n",
      "Epoch: [53] [ 510/ 548] time: 812.6935, train_loss: -54.66723251, val_loss: -53.58378983\n",
      "Epoch: [53] [ 520/ 548] time: 812.9604, train_loss: -53.58766937, val_loss: -53.67346191\n",
      "Epoch: [53] [ 530/ 548] time: 813.2040, train_loss: -46.36281586, val_loss: -54.15335464\n",
      "Epoch: [53] [ 540/ 548] time: 813.4476, train_loss: -53.45195770, val_loss: -53.49900818\n",
      "Epoch: [54] [   0/ 548] time: 813.6450, train_loss: -54.20159912, val_loss: -52.92245483\n",
      "Epoch: [54] [  10/ 548] time: 813.8945, train_loss: -55.85581207, val_loss: -53.99356842\n",
      "Epoch: [54] [  20/ 548] time: 814.1589, train_loss: -54.17648315, val_loss: -52.72871780\n",
      "Epoch: [54] [  30/ 548] time: 814.4042, train_loss: -55.13917542, val_loss: -53.87151718\n",
      "Epoch: [54] [  40/ 548] time: 814.6482, train_loss: -53.72020721, val_loss: -53.03436661\n",
      "Epoch: [54] [  50/ 548] time: 814.8882, train_loss: -52.96892166, val_loss: -53.22440338\n",
      "Epoch: [54] [  60/ 548] time: 815.1308, train_loss: -54.48195648, val_loss: -53.13474274\n",
      "Epoch: [54] [  70/ 548] time: 815.3940, train_loss: -53.55771637, val_loss: -54.16244507\n",
      "Epoch: [54] [  80/ 548] time: 815.6600, train_loss: -53.76224518, val_loss: -53.40113831\n",
      "Epoch: [54] [  90/ 548] time: 815.9301, train_loss: -51.94611359, val_loss: -54.27013397\n",
      "Epoch: [54] [ 100/ 548] time: 816.1768, train_loss: -52.64857864, val_loss: -53.60881805\n",
      "Epoch: [54] [ 110/ 548] time: 816.4300, train_loss: -54.62949371, val_loss: -53.02420807\n",
      "Epoch: [54] [ 120/ 548] time: 816.6983, train_loss: -47.84897614, val_loss: -53.83040619\n",
      "Epoch: [54] [ 130/ 548] time: 816.9513, train_loss: -51.22183228, val_loss: -52.32297516\n",
      "Epoch: [54] [ 140/ 548] time: 817.1996, train_loss: -50.97628021, val_loss: -52.04273987\n",
      "Epoch: [54] [ 150/ 548] time: 817.4587, train_loss: -48.35391235, val_loss: -53.37302399\n",
      "Epoch: [54] [ 160/ 548] time: 817.7176, train_loss: -51.85971832, val_loss: -54.00991058\n",
      "Epoch: [54] [ 170/ 548] time: 818.0014, train_loss: -51.58103561, val_loss: -53.93749237\n",
      "Epoch: [54] [ 180/ 548] time: 818.2889, train_loss: -51.74770737, val_loss: -54.45338058\n",
      "Epoch: [54] [ 190/ 548] time: 818.5708, train_loss: -52.99011612, val_loss: -53.50637817\n",
      "Epoch: [54] [ 200/ 548] time: 818.8706, train_loss: -41.10481644, val_loss: -52.66262436\n",
      "Epoch: [54] [ 210/ 548] time: 819.1363, train_loss: -53.03452682, val_loss: -53.59793091\n",
      "Epoch: [54] [ 220/ 548] time: 819.3896, train_loss: -54.44290543, val_loss: -53.39071655\n",
      "Epoch: [54] [ 230/ 548] time: 819.6380, train_loss: -56.27881241, val_loss: -53.35941696\n",
      "Epoch: [54] [ 240/ 548] time: 819.8937, train_loss: -53.41132736, val_loss: -52.85898972\n",
      "Epoch: [54] [ 250/ 548] time: 820.1492, train_loss: -9.53512955, val_loss: -53.02262115\n",
      "Epoch: [54] [ 260/ 548] time: 820.3964, train_loss: -55.10545731, val_loss: -52.67696762\n",
      "Epoch: [54] [ 270/ 548] time: 820.6519, train_loss: -50.42981720, val_loss: -51.81552887\n",
      "Epoch: [54] [ 280/ 548] time: 820.9003, train_loss: -52.29091644, val_loss: -51.94246674\n",
      "Epoch: [54] [ 290/ 548] time: 821.1418, train_loss: -49.72930908, val_loss: -48.88596344\n",
      "Epoch: [54] [ 300/ 548] time: 821.3900, train_loss: -43.73723602, val_loss: -50.91966248\n",
      "Epoch: [54] [ 310/ 548] time: 821.6319, train_loss: -36.53555679, val_loss: -53.05107117\n",
      "Epoch: [54] [ 320/ 548] time: 821.8733, train_loss: -49.46421051, val_loss: -51.05839539\n",
      "Epoch: [54] [ 330/ 548] time: 822.1060, train_loss: -52.32334137, val_loss: -51.20913315\n",
      "Epoch: [54] [ 340/ 548] time: 822.3427, train_loss: -47.29180908, val_loss: -49.98238373\n",
      "Epoch: [54] [ 350/ 548] time: 822.5872, train_loss: -45.50922394, val_loss: -52.05840302\n",
      "Epoch: [54] [ 360/ 548] time: 822.8277, train_loss: -50.02896500, val_loss: -52.40992355\n",
      "Epoch: [54] [ 370/ 548] time: 823.0632, train_loss: -49.12574005, val_loss: -52.57107162\n",
      "Epoch: [54] [ 380/ 548] time: 823.2988, train_loss: -46.06422424, val_loss: -51.72704697\n",
      "Epoch: [54] [ 390/ 548] time: 823.5333, train_loss: -49.54569626, val_loss: -52.89321518\n",
      "Epoch: [54] [ 400/ 548] time: 823.7714, train_loss: -50.28500366, val_loss: -53.27434158\n",
      "Saving checkpoint\n",
      "Epoch: [54] [ 410/ 548] time: 825.0883, train_loss: -41.39048386, val_loss: -53.55698013\n",
      "Epoch: [54] [ 420/ 548] time: 825.3201, train_loss: -53.58375168, val_loss: -52.91958237\n",
      "Epoch: [54] [ 430/ 548] time: 825.5630, train_loss: -48.57560730, val_loss: -52.92708588\n",
      "Epoch: [54] [ 440/ 548] time: 825.8084, train_loss: -53.07073593, val_loss: -51.98594284\n",
      "Epoch: [54] [ 450/ 548] time: 826.0378, train_loss: -43.66068268, val_loss: -51.98221588\n",
      "Epoch: [54] [ 460/ 548] time: 826.2698, train_loss: -52.50032043, val_loss: -52.23984909\n",
      "Epoch: [54] [ 470/ 548] time: 826.5154, train_loss: -50.98120880, val_loss: -51.53305817\n",
      "Epoch: [54] [ 480/ 548] time: 826.7559, train_loss: -48.78840637, val_loss: -52.01089478\n",
      "Epoch: [54] [ 490/ 548] time: 826.9941, train_loss: -44.70895386, val_loss: -52.69760513\n",
      "Epoch: [54] [ 500/ 548] time: 827.2356, train_loss: -50.92492676, val_loss: -52.08692932\n",
      "Epoch: [54] [ 510/ 548] time: 827.4862, train_loss: -40.16338348, val_loss: -53.33759308\n",
      "Epoch: [54] [ 520/ 548] time: 827.7357, train_loss: -53.40771866, val_loss: -51.52015305\n",
      "Epoch: [54] [ 530/ 548] time: 827.9843, train_loss: -52.40641022, val_loss: -51.33549881\n",
      "Epoch: [54] [ 540/ 548] time: 828.2443, train_loss: -47.44687653, val_loss: -50.10633087\n",
      "Epoch: [55] [   0/ 548] time: 828.4446, train_loss: -54.34647369, val_loss: -50.80338669\n",
      "Epoch: [55] [  10/ 548] time: 828.6957, train_loss: -51.62945557, val_loss: -51.65884399\n",
      "Epoch: [55] [  20/ 548] time: 828.9460, train_loss: -47.05232239, val_loss: -53.13069153\n",
      "Epoch: [55] [  30/ 548] time: 829.1915, train_loss: -47.40729141, val_loss: -53.61818695\n",
      "Epoch: [55] [  40/ 548] time: 829.4473, train_loss: -52.16930389, val_loss: -51.71906281\n",
      "Epoch: [55] [  50/ 548] time: 829.7082, train_loss: -34.08206177, val_loss: -51.93874359\n",
      "Epoch: [55] [  60/ 548] time: 830.0095, train_loss: -48.17959595, val_loss: -52.33657074\n",
      "Epoch: [55] [  70/ 548] time: 830.2783, train_loss: -46.93604660, val_loss: -52.69067383\n",
      "Epoch: [55] [  80/ 548] time: 830.5540, train_loss: -48.12554169, val_loss: -52.80632782\n",
      "Epoch: [55] [  90/ 548] time: 830.8195, train_loss: -52.94094849, val_loss: -51.70078659\n",
      "Epoch: [55] [ 100/ 548] time: 831.0806, train_loss: -53.86087799, val_loss: -52.48425293\n",
      "Epoch: [55] [ 110/ 548] time: 831.3530, train_loss: -48.81085968, val_loss: -53.12612915\n",
      "Epoch: [55] [ 120/ 548] time: 831.6068, train_loss: -55.57113647, val_loss: -52.19844818\n",
      "Epoch: [55] [ 130/ 548] time: 831.8519, train_loss: -54.58124542, val_loss: -53.11952209\n",
      "Epoch: [55] [ 140/ 548] time: 832.0997, train_loss: -53.13074875, val_loss: -54.01786041\n",
      "Epoch: [55] [ 150/ 548] time: 832.3450, train_loss: -55.34442139, val_loss: -54.28149033\n",
      "Epoch: [55] [ 160/ 548] time: 832.5864, train_loss: -50.23701477, val_loss: -53.31682205\n",
      "Epoch: [55] [ 170/ 548] time: 832.8318, train_loss: -51.33547211, val_loss: -53.75516510\n",
      "Epoch: [55] [ 180/ 548] time: 833.0708, train_loss: -11.28976440, val_loss: -53.78108597\n",
      "Epoch: [55] [ 190/ 548] time: 833.3200, train_loss: -52.10253906, val_loss: -52.23595047\n",
      "Epoch: [55] [ 200/ 548] time: 833.5620, train_loss: -48.52511978, val_loss: -52.81356812\n",
      "Epoch: [55] [ 210/ 548] time: 833.8061, train_loss: -50.84140778, val_loss: -53.07645416\n",
      "Epoch: [55] [ 220/ 548] time: 834.0574, train_loss: -53.48245239, val_loss: -51.09470367\n",
      "Epoch: [55] [ 230/ 548] time: 834.2965, train_loss: -51.34579468, val_loss: -51.96555328\n",
      "Epoch: [55] [ 240/ 548] time: 834.5349, train_loss: -40.77110291, val_loss: -53.19166946\n",
      "Epoch: [55] [ 250/ 548] time: 834.7786, train_loss: -38.71354675, val_loss: -52.49160767\n",
      "Epoch: [55] [ 260/ 548] time: 835.0173, train_loss: -52.46476746, val_loss: -53.59387970\n",
      "Epoch: [55] [ 270/ 548] time: 835.2543, train_loss: -44.90135956, val_loss: -53.65549850\n",
      "Epoch: [55] [ 280/ 548] time: 835.4891, train_loss: -42.09848022, val_loss: -53.15276337\n",
      "Epoch: [55] [ 290/ 548] time: 835.7304, train_loss: -50.93905258, val_loss: -52.50376511\n",
      "Epoch: [55] [ 300/ 548] time: 835.9860, train_loss: -45.44674301, val_loss: -51.81954956\n",
      "Epoch: [55] [ 310/ 548] time: 836.2499, train_loss: -42.40389252, val_loss: -51.87721252\n",
      "Epoch: [55] [ 320/ 548] time: 836.5351, train_loss: -44.54159546, val_loss: -52.49800873\n",
      "Epoch: [55] [ 330/ 548] time: 836.8271, train_loss: -44.94240952, val_loss: -52.88645172\n",
      "Epoch: [55] [ 340/ 548] time: 837.0838, train_loss: -52.69346619, val_loss: -52.13876724\n",
      "Epoch: [55] [ 350/ 548] time: 837.3455, train_loss: -49.34444046, val_loss: -53.82710648\n",
      "Epoch: [55] [ 360/ 548] time: 837.6052, train_loss: -53.93820953, val_loss: -53.26187515\n",
      "Epoch: [55] [ 370/ 548] time: 837.8603, train_loss: -55.30194473, val_loss: -53.44847488\n",
      "Epoch: [55] [ 380/ 548] time: 838.1146, train_loss: -49.19605255, val_loss: -53.84034729\n",
      "Epoch: [55] [ 390/ 548] time: 838.3671, train_loss: -50.73689651, val_loss: -51.04760361\n",
      "Epoch: [55] [ 400/ 548] time: 838.6166, train_loss: -49.76189804, val_loss: -49.62592316\n",
      "Epoch: [55] [ 410/ 548] time: 838.8571, train_loss: -49.28041840, val_loss: -51.85839844\n",
      "Epoch: [55] [ 420/ 548] time: 839.0989, train_loss: -41.21389008, val_loss: -52.88292313\n",
      "Epoch: [55] [ 430/ 548] time: 839.3415, train_loss: -42.96216583, val_loss: -52.00067139\n",
      "Epoch: [55] [ 440/ 548] time: 839.5796, train_loss: -42.53411865, val_loss: -46.81804657\n",
      "Epoch: [55] [ 450/ 548] time: 839.8186, train_loss: -48.85831451, val_loss: -50.96721649\n",
      "Epoch: [55] [ 460/ 548] time: 840.0508, train_loss: -53.25813675, val_loss: -51.92697144\n",
      "Epoch: [55] [ 470/ 548] time: 840.2830, train_loss: -54.53121185, val_loss: -50.79022217\n",
      "Epoch: [55] [ 480/ 548] time: 840.5219, train_loss: -54.80110931, val_loss: -49.18397522\n",
      "Epoch: [55] [ 490/ 548] time: 840.7547, train_loss: -48.57819366, val_loss: -45.79434967\n",
      "Epoch: [55] [ 500/ 548] time: 840.9862, train_loss: -49.87042618, val_loss: -48.13263702\n",
      "Epoch: [55] [ 510/ 548] time: 841.2239, train_loss: -51.03435516, val_loss: -50.23573303\n",
      "Epoch: [55] [ 520/ 548] time: 841.4607, train_loss: -31.97444916, val_loss: -40.85464859\n",
      "Epoch: [55] [ 530/ 548] time: 841.7127, train_loss: -46.17583466, val_loss: -43.24768829\n",
      "Epoch: [55] [ 540/ 548] time: 841.9834, train_loss: -46.58020782, val_loss: -45.22101593\n",
      "Epoch: [56] [   0/ 548] time: 842.2207, train_loss: -43.45966339, val_loss: -45.24282074\n",
      "Epoch: [56] [  10/ 548] time: 842.4947, train_loss: -38.45016098, val_loss: -38.61182404\n",
      "Epoch: [56] [  20/ 548] time: 842.7700, train_loss: -29.86359406, val_loss: -33.98807144\n",
      "Epoch: [56] [  30/ 548] time: 843.0158, train_loss: -33.06634521, val_loss: -41.40957642\n",
      "Epoch: [56] [  40/ 548] time: 843.2585, train_loss: -38.20654678, val_loss: -47.28318024\n",
      "Epoch: [56] [  50/ 548] time: 843.4959, train_loss: -46.35668945, val_loss: -49.24288940\n",
      "Epoch: [56] [  60/ 548] time: 843.7366, train_loss: -45.70560074, val_loss: -48.87643814\n",
      "Epoch: [56] [  70/ 548] time: 843.9767, train_loss: -48.71889114, val_loss: -48.54130554\n",
      "Epoch: [56] [  80/ 548] time: 844.2275, train_loss: -37.42768478, val_loss: -50.69636536\n",
      "Epoch: [56] [  90/ 548] time: 844.4790, train_loss: -53.95074844, val_loss: -50.48614502\n",
      "Epoch: [56] [ 100/ 548] time: 844.7303, train_loss: -51.13953400, val_loss: -51.53810120\n",
      "Epoch: [56] [ 110/ 548] time: 844.9968, train_loss: -51.51600647, val_loss: -52.14369202\n",
      "Epoch: [56] [ 120/ 548] time: 845.2444, train_loss: -55.33362961, val_loss: -52.76479721\n",
      "Epoch: [56] [ 130/ 548] time: 845.5607, train_loss: -51.43563461, val_loss: -50.84345245\n",
      "Epoch: [56] [ 140/ 548] time: 845.8069, train_loss: -50.81940460, val_loss: -51.40636826\n",
      "Epoch: [56] [ 150/ 548] time: 846.0593, train_loss: -54.63988495, val_loss: -51.21724701\n",
      "Epoch: [56] [ 160/ 548] time: 846.3095, train_loss: -35.21290970, val_loss: -52.06925964\n",
      "Epoch: [56] [ 170/ 548] time: 846.5626, train_loss: -52.50378418, val_loss: -48.88029480\n",
      "Epoch: [56] [ 180/ 548] time: 846.8105, train_loss: -45.88867950, val_loss: -49.92848969\n",
      "Epoch: [56] [ 190/ 548] time: 847.0571, train_loss: -52.90415955, val_loss: -50.03107834\n",
      "Epoch: [56] [ 200/ 548] time: 847.3025, train_loss: -44.17895508, val_loss: -52.02396393\n",
      "Epoch: [56] [ 210/ 548] time: 847.5476, train_loss: -49.92600250, val_loss: -52.59573746\n",
      "Epoch: [56] [ 220/ 548] time: 847.7934, train_loss: -50.08219910, val_loss: -52.29536057\n",
      "Epoch: [56] [ 230/ 548] time: 848.0758, train_loss: -42.83874512, val_loss: -51.32114410\n",
      "Epoch: [56] [ 240/ 548] time: 848.3605, train_loss: -53.11214828, val_loss: -52.35390854\n",
      "Epoch: [56] [ 250/ 548] time: 848.6348, train_loss: -50.72147369, val_loss: -53.25564194\n",
      "Epoch: [56] [ 260/ 548] time: 848.8919, train_loss: -53.71894073, val_loss: -53.45636749\n",
      "Epoch: [56] [ 270/ 548] time: 849.1404, train_loss: -54.14312744, val_loss: -53.17490005\n",
      "Epoch: [56] [ 280/ 548] time: 849.3811, train_loss: -56.09078598, val_loss: -53.22233582\n",
      "Epoch: [56] [ 290/ 548] time: 849.6232, train_loss: -55.64611816, val_loss: -53.61427307\n",
      "Epoch: [56] [ 300/ 548] time: 849.8686, train_loss: -47.72006226, val_loss: -53.24533844\n",
      "Epoch: [56] [ 310/ 548] time: 850.1181, train_loss: -54.64709854, val_loss: -53.20139313\n",
      "Saving checkpoint\n",
      "Epoch: [56] [ 320/ 548] time: 851.4130, train_loss: -52.34057617, val_loss: -53.04312897\n",
      "Epoch: [56] [ 330/ 548] time: 851.6618, train_loss: -51.53137207, val_loss: -52.36328125\n",
      "Epoch: [56] [ 340/ 548] time: 851.8945, train_loss: -54.37604523, val_loss: -53.54896164\n",
      "Epoch: [56] [ 350/ 548] time: 852.1204, train_loss: -46.17689514, val_loss: -53.32824326\n",
      "Epoch: [56] [ 360/ 548] time: 852.3488, train_loss: -51.88421249, val_loss: -53.94563293\n",
      "Epoch: [56] [ 370/ 548] time: 852.5845, train_loss: -55.88481903, val_loss: -54.24873352\n",
      "Epoch: [56] [ 380/ 548] time: 852.8110, train_loss: -56.50680923, val_loss: -54.53661728\n",
      "Epoch: [56] [ 390/ 548] time: 853.0382, train_loss: -54.58943939, val_loss: -54.64608765\n",
      "Epoch: [56] [ 400/ 548] time: 853.2617, train_loss: -56.36973190, val_loss: -54.78193283\n",
      "Epoch: [56] [ 410/ 548] time: 853.4923, train_loss: -51.00131226, val_loss: -54.63066101\n",
      "Epoch: [56] [ 420/ 548] time: 853.7222, train_loss: -52.08617401, val_loss: -54.22823715\n",
      "Epoch: [56] [ 430/ 548] time: 853.9857, train_loss: -50.15989304, val_loss: -53.68777084\n",
      "Epoch: [56] [ 440/ 548] time: 854.2657, train_loss: -50.38741302, val_loss: -54.46268463\n",
      "Epoch: [56] [ 450/ 548] time: 854.5470, train_loss: -54.26899719, val_loss: -53.86067581\n",
      "Epoch: [56] [ 460/ 548] time: 854.8073, train_loss: -52.67565536, val_loss: -53.79362869\n",
      "Epoch: [56] [ 470/ 548] time: 855.0618, train_loss: -47.46282959, val_loss: -53.86022186\n",
      "Epoch: [56] [ 480/ 548] time: 855.3130, train_loss: -55.80784988, val_loss: -54.41059494\n",
      "Epoch: [56] [ 490/ 548] time: 855.5652, train_loss: -52.94284058, val_loss: -51.09510803\n",
      "Epoch: [56] [ 500/ 548] time: 855.8156, train_loss: -22.79130173, val_loss: -53.25138092\n",
      "Epoch: [56] [ 510/ 548] time: 856.0648, train_loss: -46.85292053, val_loss: -53.05572510\n",
      "Epoch: [56] [ 520/ 548] time: 856.3091, train_loss: -44.04345703, val_loss: -53.29590988\n",
      "Epoch: [56] [ 530/ 548] time: 856.5569, train_loss: -52.72406006, val_loss: -52.60897064\n",
      "Epoch: [56] [ 540/ 548] time: 856.8024, train_loss: -52.02031708, val_loss: -53.74996948\n",
      "Epoch: [57] [   0/ 548] time: 856.9953, train_loss: -54.55884552, val_loss: -54.13703156\n",
      "Epoch: [57] [  10/ 548] time: 857.2408, train_loss: -50.86709213, val_loss: -54.11824417\n",
      "Epoch: [57] [  20/ 548] time: 857.4801, train_loss: -51.71371460, val_loss: -54.46573639\n",
      "Epoch: [57] [  30/ 548] time: 857.7223, train_loss: -53.75188065, val_loss: -54.35462570\n",
      "Epoch: [57] [  40/ 548] time: 857.9669, train_loss: -55.33491898, val_loss: -53.36145782\n",
      "Epoch: [57] [  50/ 548] time: 858.2128, train_loss: -47.69092560, val_loss: -54.10080719\n",
      "Epoch: [57] [  60/ 548] time: 858.4486, train_loss: -48.54109573, val_loss: -54.57463074\n",
      "Epoch: [57] [  70/ 548] time: 858.6829, train_loss: -53.28889465, val_loss: -54.56560516\n",
      "Epoch: [57] [  80/ 548] time: 858.9237, train_loss: -56.08229828, val_loss: -53.74117279\n",
      "Epoch: [57] [  90/ 548] time: 859.1674, train_loss: -48.01949692, val_loss: -54.02843857\n",
      "Epoch: [57] [ 100/ 548] time: 859.4058, train_loss: -51.89650726, val_loss: -54.07212067\n",
      "Epoch: [57] [ 110/ 548] time: 859.6457, train_loss: -52.53380585, val_loss: -53.49981689\n",
      "Epoch: [57] [ 120/ 548] time: 859.9178, train_loss: -55.20066452, val_loss: -54.16206741\n",
      "Epoch: [57] [ 130/ 548] time: 860.1946, train_loss: -53.76464081, val_loss: -54.18521500\n",
      "Epoch: [57] [ 140/ 548] time: 860.4651, train_loss: -47.39977264, val_loss: -53.01407242\n",
      "Epoch: [57] [ 150/ 548] time: 860.7279, train_loss: -56.70097733, val_loss: -53.67400360\n",
      "Epoch: [57] [ 160/ 548] time: 860.9694, train_loss: -53.70985413, val_loss: -54.76985168\n",
      "Epoch: [57] [ 170/ 548] time: 861.2131, train_loss: -52.88645172, val_loss: -54.56065369\n",
      "Epoch: [57] [ 180/ 548] time: 861.4585, train_loss: -52.85964966, val_loss: -54.38187790\n",
      "Epoch: [57] [ 190/ 548] time: 861.7102, train_loss: -53.74440384, val_loss: -53.42282486\n",
      "Epoch: [57] [ 200/ 548] time: 861.9576, train_loss: -48.69342804, val_loss: -50.96449280\n",
      "Epoch: [57] [ 210/ 548] time: 862.1995, train_loss: -52.18196106, val_loss: -53.64958954\n",
      "Epoch: [57] [ 220/ 548] time: 862.4395, train_loss: -54.06326294, val_loss: -53.17979431\n",
      "Epoch: [57] [ 230/ 548] time: 862.6977, train_loss: -52.14315033, val_loss: -52.67976761\n",
      "Epoch: [57] [ 240/ 548] time: 862.9415, train_loss: -51.23614502, val_loss: -50.64006042\n",
      "Epoch: [57] [ 250/ 548] time: 863.1809, train_loss: -19.96558380, val_loss: -51.69888306\n",
      "Epoch: [57] [ 260/ 548] time: 863.4198, train_loss: -54.66187668, val_loss: -51.99669647\n",
      "Epoch: [57] [ 270/ 548] time: 863.6646, train_loss: -44.74835205, val_loss: -52.65024948\n",
      "Epoch: [57] [ 280/ 548] time: 863.9028, train_loss: -52.09733582, val_loss: -52.76210403\n",
      "Epoch: [57] [ 290/ 548] time: 864.1381, train_loss: -56.08590317, val_loss: -53.64536667\n",
      "Epoch: [57] [ 300/ 548] time: 864.3832, train_loss: -45.15940857, val_loss: -50.51374435\n",
      "Epoch: [57] [ 310/ 548] time: 864.6251, train_loss: -50.14218521, val_loss: -50.51883316\n",
      "Epoch: [57] [ 320/ 548] time: 864.8670, train_loss: -46.94050217, val_loss: -52.47335052\n",
      "Epoch: [57] [ 330/ 548] time: 865.1190, train_loss: -41.31577301, val_loss: -50.77730942\n",
      "Epoch: [57] [ 340/ 548] time: 865.3649, train_loss: -53.61043549, val_loss: -51.94837189\n",
      "Epoch: [57] [ 350/ 548] time: 865.6214, train_loss: -49.51622391, val_loss: -50.83802032\n",
      "Epoch: [57] [ 360/ 548] time: 865.9080, train_loss: -48.39805603, val_loss: -52.67646790\n",
      "Epoch: [57] [ 370/ 548] time: 866.1815, train_loss: -49.57160187, val_loss: -52.14988327\n",
      "Epoch: [57] [ 380/ 548] time: 866.4913, train_loss: -55.60713196, val_loss: -53.10816193\n",
      "Epoch: [57] [ 390/ 548] time: 866.7901, train_loss: -51.80137253, val_loss: -52.57510376\n",
      "Epoch: [57] [ 400/ 548] time: 867.0801, train_loss: -42.06996918, val_loss: -52.06927872\n",
      "Epoch: [57] [ 410/ 548] time: 867.3412, train_loss: -49.42545319, val_loss: -52.13700867\n",
      "Epoch: [57] [ 420/ 548] time: 867.6040, train_loss: -48.21805573, val_loss: -53.30222702\n",
      "Epoch: [57] [ 430/ 548] time: 867.8794, train_loss: -45.88248444, val_loss: -53.26794434\n",
      "Epoch: [57] [ 440/ 548] time: 868.1357, train_loss: -49.24884796, val_loss: -52.93300629\n",
      "Epoch: [57] [ 450/ 548] time: 868.3898, train_loss: -52.91083527, val_loss: -52.65056610\n",
      "Epoch: [57] [ 460/ 548] time: 868.6288, train_loss: -29.01519775, val_loss: -49.86893463\n",
      "Epoch: [57] [ 470/ 548] time: 868.8789, train_loss: -46.76693344, val_loss: -47.46420288\n",
      "Epoch: [57] [ 480/ 548] time: 869.1288, train_loss: -20.89994049, val_loss: -43.67594910\n",
      "Epoch: [57] [ 490/ 548] time: 869.3870, train_loss: -50.06083679, val_loss: -43.47855377\n",
      "Epoch: [57] [ 500/ 548] time: 869.6378, train_loss: -40.99299240, val_loss: -47.24372101\n",
      "Epoch: [57] [ 510/ 548] time: 869.8912, train_loss: -46.53568649, val_loss: -46.84864426\n",
      "Epoch: [57] [ 520/ 548] time: 870.1357, train_loss: -47.44133377, val_loss: -49.08891678\n",
      "Epoch: [57] [ 530/ 548] time: 870.3815, train_loss: -46.15814972, val_loss: -49.82894516\n",
      "Epoch: [57] [ 540/ 548] time: 870.6202, train_loss: -44.99786377, val_loss: -47.11909103\n",
      "Epoch: [58] [   0/ 548] time: 870.8181, train_loss: -54.60195923, val_loss: -50.95249176\n",
      "Epoch: [58] [  10/ 548] time: 871.0594, train_loss: -49.15332794, val_loss: -52.02180862\n",
      "Epoch: [58] [  20/ 548] time: 871.2973, train_loss: -54.53284073, val_loss: -51.95261002\n",
      "Epoch: [58] [  30/ 548] time: 871.5418, train_loss: -53.08041382, val_loss: -51.96678162\n",
      "Epoch: [58] [  40/ 548] time: 871.7891, train_loss: -50.44775772, val_loss: -53.08600998\n",
      "Epoch: [58] [  50/ 548] time: 872.0535, train_loss: -42.33798218, val_loss: -53.63906097\n",
      "Epoch: [58] [  60/ 548] time: 872.3422, train_loss: -55.36219025, val_loss: -53.93333054\n",
      "Epoch: [58] [  70/ 548] time: 872.5930, train_loss: -54.08934784, val_loss: -53.40223694\n",
      "Epoch: [58] [  80/ 548] time: 872.8756, train_loss: -55.20162582, val_loss: -53.51571655\n",
      "Epoch: [58] [  90/ 548] time: 873.1628, train_loss: -54.40786362, val_loss: -53.69777679\n",
      "Epoch: [58] [ 100/ 548] time: 873.4245, train_loss: -47.36375427, val_loss: -53.27289200\n",
      "Epoch: [58] [ 110/ 548] time: 873.6749, train_loss: -51.55804062, val_loss: -53.18852997\n",
      "Epoch: [58] [ 120/ 548] time: 873.9147, train_loss: -53.99836349, val_loss: -53.80503082\n",
      "Epoch: [58] [ 130/ 548] time: 874.1628, train_loss: -49.89303589, val_loss: -53.66215515\n",
      "Epoch: [58] [ 140/ 548] time: 874.4024, train_loss: -51.51099396, val_loss: -53.70940781\n",
      "Epoch: [58] [ 150/ 548] time: 874.6353, train_loss: -52.65106201, val_loss: -54.07576370\n",
      "Epoch: [58] [ 160/ 548] time: 874.8648, train_loss: -53.33309937, val_loss: -54.05007935\n",
      "Epoch: [58] [ 170/ 548] time: 875.1160, train_loss: -57.13028717, val_loss: -53.78075790\n",
      "Epoch: [58] [ 180/ 548] time: 875.3923, train_loss: -49.97358704, val_loss: -53.60493469\n",
      "Epoch: [58] [ 190/ 548] time: 875.6611, train_loss: -43.78931427, val_loss: -52.87587357\n",
      "Epoch: [58] [ 200/ 548] time: 875.9101, train_loss: -48.79823303, val_loss: -53.68760681\n",
      "Epoch: [58] [ 210/ 548] time: 876.1521, train_loss: -51.89051056, val_loss: -52.88123322\n",
      "Saving checkpoint\n",
      "Epoch: [58] [ 220/ 548] time: 877.4668, train_loss: -52.83983994, val_loss: -53.30794907\n",
      "Epoch: [58] [ 230/ 548] time: 877.7101, train_loss: -50.46323013, val_loss: -53.17271423\n",
      "Epoch: [58] [ 240/ 548] time: 877.9479, train_loss: -27.08475876, val_loss: -53.71903992\n",
      "Epoch: [58] [ 250/ 548] time: 878.1762, train_loss: -54.85661697, val_loss: -52.93587112\n",
      "Epoch: [58] [ 260/ 548] time: 878.4161, train_loss: -51.06452560, val_loss: -53.06690979\n",
      "Epoch: [58] [ 270/ 548] time: 878.6715, train_loss: -53.74424362, val_loss: -53.12120438\n",
      "Epoch: [58] [ 280/ 548] time: 878.9240, train_loss: -53.49323654, val_loss: -53.13338470\n",
      "Epoch: [58] [ 290/ 548] time: 879.1653, train_loss: -54.60503769, val_loss: -53.64042282\n",
      "Epoch: [58] [ 300/ 548] time: 879.3946, train_loss: -50.00994873, val_loss: -53.40559006\n",
      "Epoch: [58] [ 310/ 548] time: 879.6466, train_loss: -51.86400986, val_loss: -54.56330872\n",
      "Epoch: [58] [ 320/ 548] time: 879.8950, train_loss: -55.37454605, val_loss: -54.33105087\n",
      "Epoch: [58] [ 330/ 548] time: 880.1490, train_loss: -48.37435150, val_loss: -53.78767014\n",
      "Epoch: [58] [ 340/ 548] time: 880.4026, train_loss: -45.39763641, val_loss: -53.91191101\n",
      "Epoch: [58] [ 350/ 548] time: 880.6761, train_loss: -54.52159500, val_loss: -54.26061249\n",
      "Epoch: [58] [ 360/ 548] time: 880.9351, train_loss: -52.60525513, val_loss: -54.05973053\n",
      "Epoch: [58] [ 370/ 548] time: 881.1934, train_loss: -47.93503571, val_loss: -54.42305756\n",
      "Epoch: [58] [ 380/ 548] time: 881.4649, train_loss: -56.81873322, val_loss: -54.56606293\n",
      "Epoch: [58] [ 390/ 548] time: 881.7505, train_loss: -56.51062775, val_loss: -54.57910919\n",
      "Epoch: [58] [ 400/ 548] time: 882.0061, train_loss: -55.44237518, val_loss: -54.28568268\n",
      "Epoch: [58] [ 410/ 548] time: 882.2505, train_loss: -53.68442154, val_loss: -54.28754425\n",
      "Epoch: [58] [ 420/ 548] time: 882.4882, train_loss: -49.47577667, val_loss: -54.00275803\n",
      "Epoch: [58] [ 430/ 548] time: 882.7273, train_loss: -48.40309906, val_loss: -53.34053802\n",
      "Epoch: [58] [ 440/ 548] time: 882.9570, train_loss: -52.65506744, val_loss: -54.28224945\n",
      "Epoch: [58] [ 450/ 548] time: 883.1888, train_loss: -47.12125778, val_loss: -54.05731201\n",
      "Epoch: [58] [ 460/ 548] time: 883.4249, train_loss: -54.58479691, val_loss: -54.60454941\n",
      "Epoch: [58] [ 470/ 548] time: 883.6835, train_loss: -51.68403244, val_loss: -54.58076859\n",
      "Epoch: [58] [ 480/ 548] time: 883.9518, train_loss: -51.51224899, val_loss: -54.85082245\n",
      "Epoch: [58] [ 490/ 548] time: 884.2613, train_loss: -38.80624008, val_loss: -53.67356110\n",
      "Epoch: [58] [ 500/ 548] time: 884.5616, train_loss: -56.24671555, val_loss: -54.03992462\n",
      "Epoch: [58] [ 510/ 548] time: 884.8574, train_loss: -53.75242615, val_loss: -54.47421646\n",
      "Epoch: [58] [ 520/ 548] time: 885.1486, train_loss: -51.84408569, val_loss: -53.70896149\n",
      "Epoch: [58] [ 530/ 548] time: 885.4198, train_loss: -51.16614532, val_loss: -53.93738937\n",
      "Epoch: [58] [ 540/ 548] time: 885.6788, train_loss: -49.61006927, val_loss: -54.68557739\n",
      "Epoch: [59] [   0/ 548] time: 885.8721, train_loss: -48.78785706, val_loss: -54.59919739\n",
      "Epoch: [59] [  10/ 548] time: 886.1184, train_loss: -53.84423065, val_loss: -55.00484085\n",
      "Epoch: [59] [  20/ 548] time: 886.3592, train_loss: -52.10087585, val_loss: -54.44872284\n",
      "Epoch: [59] [  30/ 548] time: 886.6217, train_loss: -53.12442017, val_loss: -54.93992615\n",
      "Epoch: [59] [  40/ 548] time: 886.8647, train_loss: -57.08586502, val_loss: -54.67800903\n",
      "Epoch: [59] [  50/ 548] time: 887.1049, train_loss: -57.66249084, val_loss: -54.68431854\n",
      "Epoch: [59] [  60/ 548] time: 887.3434, train_loss: -47.35406876, val_loss: -54.67724609\n",
      "Epoch: [59] [  70/ 548] time: 887.5816, train_loss: -54.99436951, val_loss: -53.97636414\n",
      "Epoch: [59] [  80/ 548] time: 887.8228, train_loss: -48.34745026, val_loss: -53.36211014\n",
      "Epoch: [59] [  90/ 548] time: 888.0663, train_loss: -55.93531036, val_loss: -55.16552353\n",
      "Epoch: [59] [ 100/ 548] time: 888.3036, train_loss: -54.39626694, val_loss: -54.58865356\n",
      "Epoch: [59] [ 110/ 548] time: 888.5407, train_loss: -54.27632141, val_loss: -53.09598160\n",
      "Epoch: [59] [ 120/ 548] time: 888.7827, train_loss: -57.20109558, val_loss: -53.12222672\n",
      "Epoch: [59] [ 130/ 548] time: 889.0214, train_loss: -48.75698853, val_loss: -52.41925812\n",
      "Epoch: [59] [ 140/ 548] time: 889.2643, train_loss: -50.09452057, val_loss: -52.27988434\n",
      "Epoch: [59] [ 150/ 548] time: 889.5093, train_loss: -49.87896729, val_loss: -52.50968170\n",
      "Epoch: [59] [ 160/ 548] time: 889.7474, train_loss: -31.96571732, val_loss: -53.67537689\n",
      "Epoch: [59] [ 170/ 548] time: 889.9840, train_loss: -51.97867203, val_loss: -52.67387009\n",
      "Epoch: [59] [ 180/ 548] time: 890.2284, train_loss: -50.55740356, val_loss: -54.00991821\n",
      "Epoch: [59] [ 190/ 548] time: 890.4852, train_loss: -53.78145599, val_loss: -51.68522263\n",
      "Epoch: [59] [ 200/ 548] time: 890.7502, train_loss: -51.43252563, val_loss: -51.82078552\n",
      "Epoch: [59] [ 210/ 548] time: 891.0131, train_loss: -47.15390015, val_loss: -52.31416321\n",
      "Epoch: [59] [ 220/ 548] time: 891.2696, train_loss: -51.95114517, val_loss: -52.89763641\n",
      "Epoch: [59] [ 230/ 548] time: 891.5134, train_loss: -52.42649078, val_loss: -52.91011429\n",
      "Epoch: [59] [ 240/ 548] time: 891.7646, train_loss: -52.98794937, val_loss: -52.46909332\n",
      "Epoch: [59] [ 250/ 548] time: 892.0238, train_loss: -55.27352905, val_loss: -53.08024597\n",
      "Epoch: [59] [ 260/ 548] time: 892.2696, train_loss: -46.34925461, val_loss: -50.18803024\n",
      "Epoch: [59] [ 270/ 548] time: 892.5190, train_loss: -57.27668762, val_loss: -53.80260468\n",
      "Epoch: [59] [ 280/ 548] time: 892.7813, train_loss: -48.29220581, val_loss: -51.81873322\n",
      "Epoch: [59] [ 290/ 548] time: 893.0587, train_loss: -51.97119141, val_loss: -52.87372589\n",
      "Epoch: [59] [ 300/ 548] time: 893.3353, train_loss: -46.71001434, val_loss: -53.62303543\n",
      "Epoch: [59] [ 310/ 548] time: 893.5772, train_loss: -54.26978302, val_loss: -53.41057587\n",
      "Epoch: [59] [ 320/ 548] time: 893.8183, train_loss: -46.01507187, val_loss: -53.36798096\n",
      "Epoch: [59] [ 330/ 548] time: 894.0683, train_loss: -53.57405472, val_loss: -53.68211365\n",
      "Epoch: [59] [ 340/ 548] time: 894.3073, train_loss: -53.43608475, val_loss: -52.97134399\n",
      "Epoch: [59] [ 350/ 548] time: 894.5447, train_loss: -54.82658005, val_loss: -53.74223328\n",
      "Epoch: [59] [ 360/ 548] time: 894.7902, train_loss: -49.72932053, val_loss: -53.19728470\n",
      "Epoch: [59] [ 370/ 548] time: 895.0227, train_loss: -29.65686989, val_loss: -52.86434555\n",
      "Epoch: [59] [ 380/ 548] time: 895.2567, train_loss: -48.83132172, val_loss: -53.52737045\n",
      "Epoch: [59] [ 390/ 548] time: 895.4878, train_loss: -57.19323349, val_loss: -53.68686295\n",
      "Epoch: [59] [ 400/ 548] time: 895.7193, train_loss: -54.45399094, val_loss: -53.74081421\n",
      "Epoch: [59] [ 410/ 548] time: 895.9720, train_loss: -54.00606537, val_loss: -54.28591156\n",
      "Epoch: [59] [ 420/ 548] time: 896.2136, train_loss: -57.89981842, val_loss: -54.30660248\n",
      "Epoch: [59] [ 430/ 548] time: 896.4753, train_loss: -53.28978729, val_loss: -54.27732849\n",
      "Epoch: [59] [ 440/ 548] time: 896.7524, train_loss: -50.34448242, val_loss: -55.04652405\n",
      "Epoch: [59] [ 450/ 548] time: 897.0241, train_loss: -58.23669815, val_loss: -54.87337112\n",
      "Epoch: [59] [ 460/ 548] time: 897.3009, train_loss: -43.07143021, val_loss: -55.14456177\n",
      "Epoch: [59] [ 470/ 548] time: 897.5485, train_loss: -54.26767731, val_loss: -54.97610474\n",
      "Epoch: [59] [ 480/ 548] time: 897.8044, train_loss: -52.65205383, val_loss: -54.18605804\n",
      "Epoch: [59] [ 490/ 548] time: 898.0571, train_loss: -52.39760208, val_loss: -54.35871506\n",
      "Epoch: [59] [ 500/ 548] time: 898.3087, train_loss: -50.51178360, val_loss: -54.46487808\n",
      "Epoch: [59] [ 510/ 548] time: 898.5524, train_loss: -55.70419693, val_loss: -55.24837112\n",
      "Epoch: [59] [ 520/ 548] time: 898.8037, train_loss: -53.80080414, val_loss: -53.75174713\n",
      "Epoch: [59] [ 530/ 548] time: 899.0579, train_loss: -49.40311813, val_loss: -52.70684814\n",
      "Epoch: [59] [ 540/ 548] time: 899.3108, train_loss: -50.99876022, val_loss: -53.39922333\n",
      "Epoch: [60] [   0/ 548] time: 899.5156, train_loss: -51.59006500, val_loss: -52.54227448\n",
      "Epoch: [60] [  10/ 548] time: 899.7687, train_loss: -51.51706696, val_loss: -50.89791107\n",
      "Epoch: [60] [  20/ 548] time: 900.0249, train_loss: -51.49972534, val_loss: -52.24671173\n",
      "Epoch: [60] [  30/ 548] time: 900.2747, train_loss: -49.72664642, val_loss: -52.57672119\n",
      "Epoch: [60] [  40/ 548] time: 900.5276, train_loss: -50.98009491, val_loss: -53.84933853\n",
      "Epoch: [60] [  50/ 548] time: 900.7813, train_loss: -47.71854019, val_loss: -52.89684296\n",
      "Epoch: [60] [  60/ 548] time: 901.0466, train_loss: -52.26225281, val_loss: -53.86163712\n",
      "Epoch: [60] [  70/ 548] time: 901.3271, train_loss: -53.31628799, val_loss: -53.27580261\n",
      "Epoch: [60] [  80/ 548] time: 901.5822, train_loss: -44.26055145, val_loss: -53.62523651\n",
      "Epoch: [60] [  90/ 548] time: 901.8618, train_loss: -52.11960220, val_loss: -54.00372696\n",
      "Epoch: [60] [ 100/ 548] time: 902.1219, train_loss: -53.20194244, val_loss: -53.46456528\n",
      "Epoch: [60] [ 110/ 548] time: 902.4271, train_loss: -47.51464844, val_loss: -51.88441849\n",
      "Epoch: [60] [ 120/ 548] time: 902.6994, train_loss: -50.60366821, val_loss: -51.50783539\n",
      "Saving checkpoint\n",
      "Epoch: [60] [ 130/ 548] time: 904.0145, train_loss: -53.94816589, val_loss: -53.03398514\n",
      "Epoch: [60] [ 140/ 548] time: 904.2640, train_loss: -52.61617279, val_loss: -52.44419861\n",
      "Epoch: [60] [ 150/ 548] time: 904.4929, train_loss: -55.00738144, val_loss: -52.90535355\n",
      "Epoch: [60] [ 160/ 548] time: 904.7173, train_loss: -53.64072418, val_loss: -53.67021179\n",
      "Epoch: [60] [ 170/ 548] time: 904.9403, train_loss: -49.75323486, val_loss: -51.65035248\n",
      "Epoch: [60] [ 180/ 548] time: 905.1708, train_loss: -52.26980972, val_loss: -51.54402161\n",
      "Epoch: [60] [ 190/ 548] time: 905.4409, train_loss: -46.72737122, val_loss: -52.92695618\n",
      "Epoch: [60] [ 200/ 548] time: 905.6909, train_loss: -52.97670746, val_loss: -52.36020660\n",
      "Epoch: [60] [ 210/ 548] time: 905.9384, train_loss: -55.65647507, val_loss: -51.67439270\n",
      "Epoch: [60] [ 220/ 548] time: 906.1812, train_loss: -52.78357697, val_loss: -51.78638077\n",
      "Epoch: [60] [ 230/ 548] time: 906.4273, train_loss: -53.23798370, val_loss: -52.23660278\n",
      "Epoch: [60] [ 240/ 548] time: 906.6794, train_loss: -50.75542068, val_loss: -53.16718292\n",
      "Epoch: [60] [ 250/ 548] time: 906.9426, train_loss: -53.21224213, val_loss: -53.71355820\n",
      "Epoch: [60] [ 260/ 548] time: 907.1851, train_loss: -44.98378754, val_loss: -54.03927612\n",
      "Epoch: [60] [ 270/ 548] time: 907.4309, train_loss: -58.37065887, val_loss: -52.33936310\n",
      "Epoch: [60] [ 280/ 548] time: 907.6752, train_loss: -50.69113922, val_loss: -53.59172821\n",
      "Epoch: [60] [ 290/ 548] time: 907.9203, train_loss: -55.91844177, val_loss: -53.87366104\n",
      "Epoch: [60] [ 300/ 548] time: 908.1754, train_loss: -52.68210602, val_loss: -53.76465988\n",
      "Epoch: [60] [ 310/ 548] time: 908.4546, train_loss: -57.16156769, val_loss: -53.02824402\n",
      "Epoch: [60] [ 320/ 548] time: 908.7460, train_loss: -56.23695374, val_loss: -53.32843018\n",
      "Epoch: [60] [ 330/ 548] time: 909.0122, train_loss: -55.98036194, val_loss: -52.84232712\n",
      "Epoch: [60] [ 340/ 548] time: 909.2709, train_loss: -48.89950180, val_loss: -54.57741928\n",
      "Epoch: [60] [ 350/ 548] time: 909.5235, train_loss: -48.13404846, val_loss: -52.90254211\n",
      "Epoch: [60] [ 360/ 548] time: 909.7698, train_loss: -54.04485703, val_loss: -54.75643158\n",
      "Epoch: [60] [ 370/ 548] time: 910.0163, train_loss: -48.29447937, val_loss: -54.34453964\n",
      "Epoch: [60] [ 380/ 548] time: 910.2563, train_loss: -47.81511688, val_loss: -55.16794968\n",
      "Epoch: [60] [ 390/ 548] time: 910.4932, train_loss: -50.01737976, val_loss: -54.48376083\n",
      "Epoch: [60] [ 400/ 548] time: 910.7321, train_loss: -54.89268494, val_loss: -53.29855347\n",
      "Epoch: [60] [ 410/ 548] time: 910.9984, train_loss: -53.71096802, val_loss: -54.29586792\n",
      "Epoch: [60] [ 420/ 548] time: 911.2521, train_loss: -54.60180664, val_loss: -51.38081360\n",
      "Epoch: [60] [ 430/ 548] time: 911.5224, train_loss: -53.05943680, val_loss: -54.88900757\n",
      "Epoch: [60] [ 440/ 548] time: 911.7844, train_loss: -46.52684402, val_loss: -54.89236450\n",
      "Epoch: [60] [ 450/ 548] time: 912.0566, train_loss: -43.43888092, val_loss: -54.97085190\n",
      "Epoch: [60] [ 460/ 548] time: 912.3123, train_loss: -56.03803253, val_loss: -54.49501419\n",
      "Epoch: [60] [ 470/ 548] time: 912.5699, train_loss: -52.92409515, val_loss: -53.61957550\n",
      "Epoch: [60] [ 480/ 548] time: 912.8248, train_loss: -39.15477371, val_loss: -54.69070435\n",
      "Epoch: [60] [ 490/ 548] time: 913.0740, train_loss: -52.63077545, val_loss: -53.99185944\n",
      "Epoch: [60] [ 500/ 548] time: 913.3459, train_loss: -52.93537140, val_loss: -53.33064270\n",
      "Epoch: [60] [ 510/ 548] time: 913.5976, train_loss: -56.11103058, val_loss: -54.04452515\n",
      "Epoch: [60] [ 520/ 548] time: 913.8398, train_loss: -54.49232864, val_loss: -53.94791412\n",
      "Epoch: [60] [ 530/ 548] time: 914.1112, train_loss: -56.02608871, val_loss: -54.45364761\n",
      "Epoch: [60] [ 540/ 548] time: 914.3873, train_loss: -49.83149719, val_loss: -54.54625320\n",
      "Epoch: [61] [   0/ 548] time: 914.6174, train_loss: -49.64302063, val_loss: -55.21743393\n",
      "Epoch: [61] [  10/ 548] time: 914.8896, train_loss: -50.10676193, val_loss: -54.77791977\n",
      "Epoch: [61] [  20/ 548] time: 915.1372, train_loss: -49.13189697, val_loss: -51.11837006\n",
      "Epoch: [61] [  30/ 548] time: 915.3896, train_loss: -48.67367172, val_loss: -51.05583191\n",
      "Epoch: [61] [  40/ 548] time: 915.6517, train_loss: -38.01080322, val_loss: -51.32168198\n",
      "Epoch: [61] [  50/ 548] time: 915.9040, train_loss: -39.83374405, val_loss: -50.75853729\n",
      "Epoch: [61] [  60/ 548] time: 916.1473, train_loss: -45.46549225, val_loss: -50.22036743\n",
      "Epoch: [61] [  70/ 548] time: 916.4151, train_loss: -42.93639755, val_loss: -48.80603027\n",
      "Epoch: [61] [  80/ 548] time: 916.6628, train_loss: -39.71898651, val_loss: -49.64418793\n",
      "Epoch: [61] [  90/ 548] time: 916.9182, train_loss: -33.84402084, val_loss: -50.93302155\n",
      "Epoch: [61] [ 100/ 548] time: 917.1820, train_loss: -48.66891098, val_loss: -50.16868591\n",
      "Epoch: [61] [ 110/ 548] time: 917.4338, train_loss: -52.87957764, val_loss: -51.55764771\n",
      "Epoch: [61] [ 120/ 548] time: 917.7016, train_loss: -42.93141937, val_loss: -50.06162262\n",
      "Epoch: [61] [ 130/ 548] time: 917.9606, train_loss: -44.89153671, val_loss: -52.20289993\n",
      "Epoch: [61] [ 140/ 548] time: 918.2107, train_loss: -45.15852356, val_loss: -49.71465302\n",
      "Epoch: [61] [ 150/ 548] time: 918.4681, train_loss: -53.00691986, val_loss: -52.36348343\n",
      "Epoch: [61] [ 160/ 548] time: 918.7304, train_loss: -54.04658127, val_loss: -53.49608994\n",
      "Epoch: [61] [ 170/ 548] time: 918.9952, train_loss: -57.82893753, val_loss: -52.64422607\n",
      "Epoch: [61] [ 180/ 548] time: 919.2577, train_loss: -55.04973984, val_loss: -53.69017029\n",
      "Epoch: [61] [ 190/ 548] time: 919.5239, train_loss: -47.23593903, val_loss: -55.01767731\n",
      "Epoch: [61] [ 200/ 548] time: 919.7705, train_loss: -50.23512268, val_loss: -53.69300461\n",
      "Epoch: [61] [ 210/ 548] time: 920.0467, train_loss: -44.24682617, val_loss: -54.59532928\n",
      "Epoch: [61] [ 220/ 548] time: 920.3321, train_loss: -50.06412888, val_loss: -54.20298767\n",
      "Epoch: [61] [ 230/ 548] time: 920.6029, train_loss: -55.21943283, val_loss: -52.74120331\n",
      "Epoch: [61] [ 240/ 548] time: 920.8745, train_loss: -55.78696823, val_loss: -54.37661743\n",
      "Epoch: [61] [ 250/ 548] time: 921.1354, train_loss: -53.90481949, val_loss: -54.75516510\n",
      "Epoch: [61] [ 260/ 548] time: 921.3859, train_loss: -48.12564468, val_loss: -55.14630890\n",
      "Epoch: [61] [ 270/ 548] time: 921.6335, train_loss: -53.74839401, val_loss: -54.95426559\n",
      "Epoch: [61] [ 280/ 548] time: 921.8871, train_loss: -51.34808350, val_loss: -54.58613205\n",
      "Epoch: [61] [ 290/ 548] time: 922.1314, train_loss: -48.69550323, val_loss: -53.99083710\n",
      "Epoch: [61] [ 300/ 548] time: 922.3788, train_loss: -55.95464325, val_loss: -53.68018723\n",
      "Epoch: [61] [ 310/ 548] time: 922.6222, train_loss: -55.16016006, val_loss: -54.72805023\n",
      "Epoch: [61] [ 320/ 548] time: 922.8606, train_loss: -58.76045609, val_loss: -55.40646744\n",
      "Epoch: [61] [ 330/ 548] time: 923.1065, train_loss: -55.12630844, val_loss: -55.00677872\n",
      "Epoch: [61] [ 340/ 548] time: 923.3624, train_loss: -51.16691589, val_loss: -54.13620758\n",
      "Epoch: [61] [ 350/ 548] time: 923.6037, train_loss: -48.42982483, val_loss: -54.44930267\n",
      "Epoch: [61] [ 360/ 548] time: 923.8444, train_loss: -54.60731888, val_loss: -53.98667526\n",
      "Epoch: [61] [ 370/ 548] time: 924.0894, train_loss: -57.63058090, val_loss: -55.49742889\n",
      "Epoch: [61] [ 380/ 548] time: 924.3323, train_loss: -57.28409576, val_loss: -55.29107666\n",
      "Epoch: [61] [ 390/ 548] time: 924.5861, train_loss: -53.23610687, val_loss: -55.76114655\n",
      "Epoch: [61] [ 400/ 548] time: 924.8302, train_loss: -58.56179428, val_loss: -56.00726318\n",
      "Epoch: [61] [ 410/ 548] time: 925.0689, train_loss: -55.34072876, val_loss: -54.59808731\n",
      "Epoch: [61] [ 420/ 548] time: 925.3042, train_loss: -48.08448029, val_loss: -55.46897507\n",
      "Epoch: [61] [ 430/ 548] time: 925.5372, train_loss: -54.59112930, val_loss: -54.75679779\n",
      "Epoch: [61] [ 440/ 548] time: 925.7743, train_loss: -50.45436859, val_loss: -54.05389786\n",
      "Epoch: [61] [ 450/ 548] time: 926.0247, train_loss: -56.98574829, val_loss: -54.22068787\n",
      "Epoch: [61] [ 460/ 548] time: 926.2856, train_loss: -54.71785736, val_loss: -53.30594254\n",
      "Epoch: [61] [ 470/ 548] time: 926.5582, train_loss: -51.24302673, val_loss: -54.72643661\n",
      "Epoch: [61] [ 480/ 548] time: 926.8310, train_loss: -51.89623260, val_loss: -52.29800415\n",
      "Epoch: [61] [ 490/ 548] time: 927.0843, train_loss: -49.54413223, val_loss: -54.01811981\n",
      "Epoch: [61] [ 500/ 548] time: 927.3375, train_loss: -56.47256470, val_loss: -53.85995483\n",
      "Epoch: [61] [ 510/ 548] time: 927.5901, train_loss: -49.12466812, val_loss: -53.87324142\n",
      "Epoch: [61] [ 520/ 548] time: 927.8400, train_loss: -48.11043549, val_loss: -53.28660202\n",
      "Epoch: [61] [ 530/ 548] time: 928.0862, train_loss: -54.39165497, val_loss: -54.44285202\n",
      "Epoch: [61] [ 540/ 548] time: 928.3264, train_loss: -54.07243729, val_loss: -54.97828674\n",
      "Epoch: [62] [   0/ 548] time: 928.5209, train_loss: -54.92644882, val_loss: -54.06848907\n",
      "Epoch: [62] [  10/ 548] time: 928.7637, train_loss: -53.69308853, val_loss: -54.64134598\n",
      "Epoch: [62] [  20/ 548] time: 929.0066, train_loss: -47.83010864, val_loss: -54.67924500\n",
      "Saving checkpoint\n",
      "Epoch: [62] [  30/ 548] time: 930.3383, train_loss: -56.14660263, val_loss: -53.75273132\n",
      "Epoch: [62] [  40/ 548] time: 930.5849, train_loss: -49.03054047, val_loss: -53.98731232\n",
      "Epoch: [62] [  50/ 548] time: 930.8219, train_loss: -51.59064484, val_loss: -53.09564209\n",
      "Epoch: [62] [  60/ 548] time: 931.0465, train_loss: -51.58608246, val_loss: -53.51759338\n",
      "Epoch: [62] [  70/ 548] time: 931.2720, train_loss: -54.44921112, val_loss: -53.63168335\n",
      "Epoch: [62] [  80/ 548] time: 931.5037, train_loss: -55.16976929, val_loss: -53.64469910\n",
      "Epoch: [62] [  90/ 548] time: 931.7382, train_loss: -54.29473114, val_loss: -53.96566391\n",
      "Epoch: [62] [ 100/ 548] time: 931.9639, train_loss: -51.03624725, val_loss: -53.20352173\n",
      "Epoch: [62] [ 110/ 548] time: 932.2243, train_loss: -42.01505280, val_loss: -52.91281128\n",
      "Epoch: [62] [ 120/ 548] time: 932.4778, train_loss: -52.49449539, val_loss: -50.25811386\n",
      "Epoch: [62] [ 130/ 548] time: 932.7557, train_loss: -43.09053802, val_loss: -52.63419342\n",
      "Epoch: [62] [ 140/ 548] time: 933.0311, train_loss: -44.62224579, val_loss: -52.05152893\n",
      "Epoch: [62] [ 150/ 548] time: 933.3158, train_loss: -55.71302032, val_loss: -51.98710251\n",
      "Epoch: [62] [ 160/ 548] time: 933.5780, train_loss: -51.97517395, val_loss: -52.25288773\n",
      "Epoch: [62] [ 170/ 548] time: 933.8282, train_loss: -49.96136093, val_loss: -52.23004913\n",
      "Epoch: [62] [ 180/ 548] time: 934.0754, train_loss: -53.90083313, val_loss: -53.01525116\n",
      "Epoch: [62] [ 190/ 548] time: 934.3310, train_loss: -55.55730820, val_loss: -53.17340469\n",
      "Epoch: [62] [ 200/ 548] time: 934.5817, train_loss: -43.56942749, val_loss: -54.10315704\n",
      "Epoch: [62] [ 210/ 548] time: 934.8241, train_loss: -44.95792389, val_loss: -54.67782593\n",
      "Epoch: [62] [ 220/ 548] time: 935.0738, train_loss: -55.23706818, val_loss: -53.33163834\n",
      "Epoch: [62] [ 230/ 548] time: 935.3297, train_loss: -53.58808899, val_loss: -53.61935043\n",
      "Epoch: [62] [ 240/ 548] time: 935.6252, train_loss: -57.54762650, val_loss: -54.01129532\n",
      "Epoch: [62] [ 250/ 548] time: 935.8791, train_loss: -45.41384506, val_loss: -54.66777039\n",
      "Epoch: [62] [ 260/ 548] time: 936.1374, train_loss: -52.47931671, val_loss: -55.24306488\n",
      "Epoch: [62] [ 270/ 548] time: 936.3925, train_loss: -54.37186432, val_loss: -54.00502014\n",
      "Epoch: [62] [ 280/ 548] time: 936.6382, train_loss: -55.13265610, val_loss: -54.62499237\n",
      "Epoch: [62] [ 290/ 548] time: 936.8960, train_loss: -54.95460510, val_loss: -52.95327759\n",
      "Epoch: [62] [ 300/ 548] time: 937.1471, train_loss: -54.85770035, val_loss: -52.10842514\n",
      "Epoch: [62] [ 310/ 548] time: 937.3908, train_loss: -54.12526321, val_loss: -52.89709091\n",
      "Epoch: [62] [ 320/ 548] time: 937.6400, train_loss: -53.59880829, val_loss: -54.18388367\n",
      "Epoch: [62] [ 330/ 548] time: 937.8907, train_loss: -50.62350464, val_loss: -52.84920502\n",
      "Epoch: [62] [ 340/ 548] time: 938.1485, train_loss: -51.28470612, val_loss: -53.50104141\n",
      "Epoch: [62] [ 350/ 548] time: 938.4187, train_loss: -56.38251877, val_loss: -54.84173965\n",
      "Epoch: [62] [ 360/ 548] time: 938.6869, train_loss: -49.47153091, val_loss: -53.82446289\n",
      "Epoch: [62] [ 370/ 548] time: 938.9538, train_loss: -51.22357178, val_loss: -53.18099213\n",
      "Epoch: [62] [ 380/ 548] time: 939.2388, train_loss: -41.35508347, val_loss: -53.45773697\n",
      "Epoch: [62] [ 390/ 548] time: 939.4923, train_loss: -52.84147644, val_loss: -54.05865860\n",
      "Epoch: [62] [ 400/ 548] time: 939.7378, train_loss: -44.73298264, val_loss: -53.14457703\n",
      "Epoch: [62] [ 410/ 548] time: 939.9869, train_loss: -53.23360443, val_loss: -51.28677368\n",
      "Epoch: [62] [ 420/ 548] time: 940.2367, train_loss: -45.86363220, val_loss: -52.35925674\n",
      "Epoch: [62] [ 430/ 548] time: 940.4814, train_loss: -37.77112961, val_loss: -53.35646439\n",
      "Epoch: [62] [ 440/ 548] time: 940.7235, train_loss: -48.74772263, val_loss: -52.21499634\n",
      "Epoch: [62] [ 450/ 548] time: 940.9875, train_loss: -55.84651566, val_loss: -51.64648056\n",
      "Epoch: [62] [ 460/ 548] time: 941.2722, train_loss: -49.93214035, val_loss: -46.26954651\n",
      "Epoch: [62] [ 470/ 548] time: 941.5926, train_loss: -46.43171310, val_loss: -49.29367828\n",
      "Epoch: [62] [ 480/ 548] time: 941.8740, train_loss: -23.10577011, val_loss: -43.86421204\n",
      "Epoch: [62] [ 490/ 548] time: 942.1393, train_loss: -46.35379791, val_loss: -46.47356415\n",
      "Epoch: [62] [ 500/ 548] time: 942.4109, train_loss: -23.21097565, val_loss: -47.47735214\n",
      "Epoch: [62] [ 510/ 548] time: 942.6677, train_loss: -9.51834869, val_loss: -45.92802429\n",
      "Epoch: [62] [ 520/ 548] time: 942.9223, train_loss: -35.44514465, val_loss: -35.06577682\n",
      "Epoch: [62] [ 530/ 548] time: 943.1652, train_loss: -40.82190704, val_loss: -48.52664566\n",
      "Epoch: [62] [ 540/ 548] time: 943.4174, train_loss: -50.29174423, val_loss: -44.58837891\n",
      "Epoch: [63] [   0/ 548] time: 943.6118, train_loss: -50.68903351, val_loss: -47.28385925\n",
      "Epoch: [63] [  10/ 548] time: 943.8574, train_loss: -48.76218414, val_loss: -50.47072601\n",
      "Epoch: [63] [  20/ 548] time: 944.1019, train_loss: -56.85004807, val_loss: -51.20246887\n",
      "Epoch: [63] [  30/ 548] time: 944.3524, train_loss: -53.71130371, val_loss: -53.38513947\n",
      "Epoch: [63] [  40/ 548] time: 944.6141, train_loss: -55.25912476, val_loss: -51.45352554\n",
      "Epoch: [63] [  50/ 548] time: 944.8821, train_loss: -49.68302536, val_loss: -51.32434464\n",
      "Epoch: [63] [  60/ 548] time: 945.1485, train_loss: -52.68020630, val_loss: -52.30172348\n",
      "Epoch: [63] [  70/ 548] time: 945.4037, train_loss: -51.12570190, val_loss: -51.28611755\n",
      "Epoch: [63] [  80/ 548] time: 945.6460, train_loss: -50.21369934, val_loss: -50.32511902\n",
      "Epoch: [63] [  90/ 548] time: 945.8880, train_loss: -25.51162720, val_loss: -51.54658890\n",
      "Epoch: [63] [ 100/ 548] time: 946.1293, train_loss: -49.60327530, val_loss: -50.67414474\n",
      "Epoch: [63] [ 110/ 548] time: 946.3848, train_loss: -43.51294708, val_loss: -52.17497253\n",
      "Epoch: [63] [ 120/ 548] time: 946.6286, train_loss: -54.83584213, val_loss: -52.10911560\n",
      "Epoch: [63] [ 130/ 548] time: 946.8814, train_loss: -44.56026840, val_loss: -52.27817917\n",
      "Epoch: [63] [ 140/ 548] time: 947.1257, train_loss: -55.69937134, val_loss: -53.10001755\n",
      "Epoch: [63] [ 150/ 548] time: 947.3697, train_loss: -49.40030289, val_loss: -51.44766235\n",
      "Epoch: [63] [ 160/ 548] time: 947.6227, train_loss: -56.24042130, val_loss: -53.41402435\n",
      "Epoch: [63] [ 170/ 548] time: 947.8701, train_loss: -54.07790375, val_loss: -53.64056396\n",
      "Epoch: [63] [ 180/ 548] time: 948.1137, train_loss: -53.66563416, val_loss: -53.75089645\n",
      "Epoch: [63] [ 190/ 548] time: 948.3579, train_loss: -52.13199615, val_loss: -53.51533890\n",
      "Epoch: [63] [ 200/ 548] time: 948.5988, train_loss: -44.45601654, val_loss: -52.63032913\n",
      "Epoch: [63] [ 210/ 548] time: 948.8458, train_loss: -54.36397934, val_loss: -54.09432602\n",
      "Epoch: [63] [ 220/ 548] time: 949.0832, train_loss: -54.28997803, val_loss: -54.29184723\n",
      "Epoch: [63] [ 230/ 548] time: 949.3263, train_loss: -54.99738312, val_loss: -54.38243866\n",
      "Epoch: [63] [ 240/ 548] time: 949.5812, train_loss: -50.80094147, val_loss: -55.39445877\n",
      "Epoch: [63] [ 250/ 548] time: 949.8259, train_loss: -54.12723160, val_loss: -54.22449875\n",
      "Epoch: [63] [ 260/ 548] time: 950.0777, train_loss: -52.04716492, val_loss: -53.83087921\n",
      "Epoch: [63] [ 270/ 548] time: 950.3288, train_loss: -51.79060364, val_loss: -54.52299881\n",
      "Epoch: [63] [ 280/ 548] time: 950.6007, train_loss: -51.37631989, val_loss: -54.06836319\n",
      "Epoch: [63] [ 290/ 548] time: 950.8775, train_loss: -56.90800476, val_loss: -54.24762726\n",
      "Epoch: [63] [ 300/ 548] time: 951.1552, train_loss: -53.08076096, val_loss: -54.57664490\n",
      "Epoch: [63] [ 310/ 548] time: 951.4226, train_loss: -54.29286957, val_loss: -53.71086121\n",
      "Epoch: [63] [ 320/ 548] time: 951.6799, train_loss: -47.67726898, val_loss: -51.72082901\n",
      "Epoch: [63] [ 330/ 548] time: 951.9324, train_loss: -57.01405334, val_loss: -53.79378510\n",
      "Epoch: [63] [ 340/ 548] time: 952.1826, train_loss: -47.49575806, val_loss: -55.36087799\n",
      "Epoch: [63] [ 350/ 548] time: 952.4195, train_loss: -55.27469635, val_loss: -54.33966446\n",
      "Epoch: [63] [ 360/ 548] time: 952.6606, train_loss: -51.68149185, val_loss: -53.91059875\n",
      "Epoch: [63] [ 370/ 548] time: 952.9162, train_loss: -51.50711823, val_loss: -54.75648880\n",
      "Epoch: [63] [ 380/ 548] time: 953.1497, train_loss: -53.95109177, val_loss: -55.20453262\n",
      "Epoch: [63] [ 390/ 548] time: 953.3991, train_loss: -51.60897446, val_loss: -55.91043854\n",
      "Epoch: [63] [ 400/ 548] time: 953.6744, train_loss: -58.09457779, val_loss: -55.10128021\n",
      "Epoch: [63] [ 410/ 548] time: 953.9254, train_loss: -51.17797852, val_loss: -55.55726624\n",
      "Epoch: [63] [ 420/ 548] time: 954.1730, train_loss: -52.38324738, val_loss: -55.56760406\n",
      "Epoch: [63] [ 430/ 548] time: 954.4230, train_loss: -51.25952911, val_loss: -55.91890335\n",
      "Epoch: [63] [ 440/ 548] time: 954.6708, train_loss: -49.26859665, val_loss: -54.20480728\n",
      "Epoch: [63] [ 450/ 548] time: 954.9179, train_loss: -55.90896606, val_loss: -55.54447937\n",
      "Epoch: [63] [ 460/ 548] time: 955.1604, train_loss: -55.50407028, val_loss: -54.72085953\n",
      "Epoch: [63] [ 470/ 548] time: 955.4028, train_loss: -53.21725464, val_loss: -55.72293854\n",
      "Saving checkpoint\n",
      "Epoch: [63] [ 480/ 548] time: 956.6823, train_loss: -57.68482971, val_loss: -56.02643204\n",
      "Epoch: [63] [ 490/ 548] time: 956.9620, train_loss: -34.06963348, val_loss: -55.88750076\n",
      "Epoch: [63] [ 500/ 548] time: 957.2166, train_loss: -46.20840454, val_loss: -55.16355896\n",
      "Epoch: [63] [ 510/ 548] time: 957.4460, train_loss: -54.14512253, val_loss: -55.82875824\n",
      "Epoch: [63] [ 520/ 548] time: 957.6731, train_loss: -55.41014862, val_loss: -55.09065628\n",
      "Epoch: [63] [ 530/ 548] time: 957.9121, train_loss: -56.71147537, val_loss: -55.51548004\n",
      "Epoch: [63] [ 540/ 548] time: 958.1522, train_loss: -51.56166077, val_loss: -55.20598984\n",
      "Epoch: [64] [   0/ 548] time: 958.3400, train_loss: -42.89570236, val_loss: -55.38481522\n",
      "Epoch: [64] [  10/ 548] time: 958.5801, train_loss: -53.94586182, val_loss: -54.80988693\n",
      "Epoch: [64] [  20/ 548] time: 958.8245, train_loss: -55.85761261, val_loss: -55.48529434\n",
      "Epoch: [64] [  30/ 548] time: 959.0655, train_loss: -53.36480713, val_loss: -54.78326416\n",
      "Epoch: [64] [  40/ 548] time: 959.3066, train_loss: -51.57025146, val_loss: -55.68866348\n",
      "Epoch: [64] [  50/ 548] time: 959.5635, train_loss: -57.21089935, val_loss: -55.06243515\n",
      "Epoch: [64] [  60/ 548] time: 959.8107, train_loss: -43.03176880, val_loss: -55.12305069\n",
      "Epoch: [64] [  70/ 548] time: 960.0532, train_loss: -51.35226822, val_loss: -54.86733627\n",
      "Epoch: [64] [  80/ 548] time: 960.3000, train_loss: -50.29755020, val_loss: -55.02987289\n",
      "Epoch: [64] [  90/ 548] time: 960.5462, train_loss: -51.99765015, val_loss: -54.83937836\n",
      "Epoch: [64] [ 100/ 548] time: 960.7840, train_loss: -55.41333008, val_loss: -54.68302155\n",
      "Epoch: [64] [ 110/ 548] time: 961.0246, train_loss: -55.32899857, val_loss: -54.96806335\n",
      "Epoch: [64] [ 120/ 548] time: 961.2647, train_loss: -52.30144119, val_loss: -55.63980865\n",
      "Epoch: [64] [ 130/ 548] time: 961.5066, train_loss: -38.94505310, val_loss: -55.85649109\n",
      "Epoch: [64] [ 140/ 548] time: 961.7491, train_loss: -50.86545563, val_loss: -55.81299591\n",
      "Epoch: [64] [ 150/ 548] time: 962.0101, train_loss: -54.40142441, val_loss: -54.68808365\n",
      "Epoch: [64] [ 160/ 548] time: 962.3029, train_loss: -58.18390274, val_loss: -55.56192780\n",
      "Epoch: [64] [ 170/ 548] time: 962.5719, train_loss: -53.84536362, val_loss: -55.67945099\n",
      "Epoch: [64] [ 180/ 548] time: 962.8449, train_loss: -58.53681183, val_loss: -55.42277145\n",
      "Epoch: [64] [ 190/ 548] time: 963.0811, train_loss: -49.02328873, val_loss: -54.66517639\n",
      "Epoch: [64] [ 200/ 548] time: 963.3188, train_loss: -51.40521240, val_loss: -54.95375061\n",
      "Epoch: [64] [ 210/ 548] time: 963.5551, train_loss: -55.34206772, val_loss: -53.04882812\n",
      "Epoch: [64] [ 220/ 548] time: 963.7959, train_loss: -36.68590927, val_loss: -54.18489838\n",
      "Epoch: [64] [ 230/ 548] time: 964.0328, train_loss: -57.62629318, val_loss: -54.12829208\n",
      "Epoch: [64] [ 240/ 548] time: 964.2695, train_loss: -55.63473511, val_loss: -54.64090729\n",
      "Epoch: [64] [ 250/ 548] time: 964.5155, train_loss: -55.62523270, val_loss: -55.72496796\n",
      "Epoch: [64] [ 260/ 548] time: 964.7701, train_loss: -47.64658356, val_loss: -54.01949310\n",
      "Epoch: [64] [ 270/ 548] time: 965.0177, train_loss: -56.81070328, val_loss: -54.76980591\n",
      "Epoch: [64] [ 280/ 548] time: 965.2660, train_loss: -52.13700867, val_loss: -53.13129044\n",
      "Epoch: [64] [ 290/ 548] time: 965.5554, train_loss: -52.10084534, val_loss: -54.60369873\n",
      "Epoch: [64] [ 300/ 548] time: 965.8053, train_loss: -47.12717438, val_loss: -55.22197723\n",
      "Epoch: [64] [ 310/ 548] time: 966.0545, train_loss: -51.20878601, val_loss: -52.82755280\n",
      "Epoch: [64] [ 320/ 548] time: 966.3210, train_loss: -14.20108032, val_loss: -55.23642731\n",
      "Epoch: [64] [ 330/ 548] time: 966.5863, train_loss: -46.67185211, val_loss: -48.84788132\n",
      "Epoch: [64] [ 340/ 548] time: 966.8529, train_loss: -49.60078430, val_loss: -50.89912033\n",
      "Epoch: [64] [ 350/ 548] time: 967.1136, train_loss: -51.87330627, val_loss: -52.87382507\n",
      "Epoch: [64] [ 360/ 548] time: 967.3676, train_loss: -47.29705048, val_loss: -47.15740204\n",
      "Epoch: [64] [ 370/ 548] time: 967.6334, train_loss: -41.92970276, val_loss: -49.85871887\n",
      "Epoch: [64] [ 380/ 548] time: 967.8954, train_loss: -48.44045258, val_loss: -50.96208954\n",
      "Epoch: [64] [ 390/ 548] time: 968.1790, train_loss: -44.63237762, val_loss: -47.30815887\n",
      "Epoch: [64] [ 400/ 548] time: 968.5094, train_loss: -51.76416779, val_loss: -49.97837448\n",
      "Epoch: [64] [ 410/ 548] time: 968.8471, train_loss: -50.19984818, val_loss: -50.02222824\n",
      "Epoch: [64] [ 420/ 548] time: 969.2097, train_loss: -52.82189560, val_loss: -49.79991150\n",
      "Epoch: [64] [ 430/ 548] time: 969.5768, train_loss: -44.97523499, val_loss: -50.03878784\n",
      "Epoch: [64] [ 440/ 548] time: 969.8874, train_loss: -48.37162781, val_loss: -47.88761139\n",
      "Epoch: [64] [ 450/ 548] time: 970.1993, train_loss: -48.27687073, val_loss: -49.95808792\n",
      "Epoch: [64] [ 460/ 548] time: 970.5173, train_loss: -44.15470886, val_loss: -52.12276459\n",
      "Epoch: [64] [ 470/ 548] time: 970.8587, train_loss: -55.02663803, val_loss: -53.02585220\n",
      "Epoch: [64] [ 480/ 548] time: 971.1595, train_loss: -55.37927246, val_loss: -53.30673218\n",
      "Epoch: [64] [ 490/ 548] time: 971.4809, train_loss: -56.32277298, val_loss: -53.69366074\n",
      "Epoch: [64] [ 500/ 548] time: 971.7976, train_loss: -55.06755829, val_loss: -53.33271790\n",
      "Epoch: [64] [ 510/ 548] time: 972.0906, train_loss: -53.31004333, val_loss: -53.65933228\n",
      "Epoch: [64] [ 520/ 548] time: 972.3861, train_loss: -51.63172150, val_loss: -54.32866287\n",
      "Epoch: [64] [ 530/ 548] time: 972.7293, train_loss: -54.64690781, val_loss: -55.22106171\n",
      "Epoch: [64] [ 540/ 548] time: 973.0144, train_loss: -46.67024612, val_loss: -54.91735077\n",
      "Epoch: [65] [   0/ 548] time: 973.2539, train_loss: -54.94831467, val_loss: -54.65299225\n",
      "Epoch: [65] [  10/ 548] time: 973.5488, train_loss: -51.33920288, val_loss: -54.30440903\n",
      "Epoch: [65] [  20/ 548] time: 973.8251, train_loss: -55.34838867, val_loss: -55.13830185\n",
      "Epoch: [65] [  30/ 548] time: 974.1186, train_loss: -47.20245743, val_loss: -55.64239883\n",
      "Epoch: [65] [  40/ 548] time: 974.3934, train_loss: -54.51974869, val_loss: -55.27153397\n",
      "Epoch: [65] [  50/ 548] time: 974.7048, train_loss: -44.64145279, val_loss: -54.96142960\n",
      "Epoch: [65] [  60/ 548] time: 974.9930, train_loss: -52.39456177, val_loss: -54.92849731\n",
      "Epoch: [65] [  70/ 548] time: 975.2872, train_loss: -51.65036011, val_loss: -54.33512115\n",
      "Epoch: [65] [  80/ 548] time: 975.5783, train_loss: -47.59358215, val_loss: -55.78406906\n",
      "Epoch: [65] [  90/ 548] time: 975.8475, train_loss: -50.77449799, val_loss: -55.69424057\n",
      "Epoch: [65] [ 100/ 548] time: 976.1055, train_loss: -50.01823425, val_loss: -52.26856613\n",
      "Epoch: [65] [ 110/ 548] time: 976.3696, train_loss: -52.74205399, val_loss: -50.74977493\n",
      "Epoch: [65] [ 120/ 548] time: 976.6327, train_loss: -52.34913635, val_loss: -49.12087631\n",
      "Epoch: [65] [ 130/ 548] time: 976.8951, train_loss: -56.44324112, val_loss: -54.01513672\n",
      "Epoch: [65] [ 140/ 548] time: 977.1643, train_loss: -46.01251984, val_loss: -53.06065750\n",
      "Epoch: [65] [ 150/ 548] time: 977.4268, train_loss: -53.64617538, val_loss: -53.68223190\n",
      "Epoch: [65] [ 160/ 548] time: 977.6809, train_loss: -52.64394379, val_loss: -55.03493500\n",
      "Epoch: [65] [ 170/ 548] time: 977.9501, train_loss: -53.32544327, val_loss: -54.37952042\n",
      "Epoch: [65] [ 180/ 548] time: 978.2339, train_loss: -54.27743149, val_loss: -54.05351257\n",
      "Epoch: [65] [ 190/ 548] time: 978.5024, train_loss: -56.24193954, val_loss: -54.56660843\n",
      "Epoch: [65] [ 200/ 548] time: 978.7582, train_loss: -45.16374207, val_loss: -54.95131302\n",
      "Epoch: [65] [ 210/ 548] time: 979.0224, train_loss: -54.06206512, val_loss: -54.77880478\n",
      "Epoch: [65] [ 220/ 548] time: 979.2933, train_loss: -55.53520966, val_loss: -54.77199554\n",
      "Epoch: [65] [ 230/ 548] time: 979.5487, train_loss: -52.71138763, val_loss: -54.60681152\n",
      "Epoch: [65] [ 240/ 548] time: 979.7961, train_loss: -53.48873901, val_loss: -54.05427551\n",
      "Epoch: [65] [ 250/ 548] time: 980.0837, train_loss: -57.31019211, val_loss: -53.64941788\n",
      "Epoch: [65] [ 260/ 548] time: 980.3386, train_loss: -45.30039215, val_loss: -52.33208466\n",
      "Epoch: [65] [ 270/ 548] time: 980.5830, train_loss: -41.55079269, val_loss: -53.90092087\n",
      "Epoch: [65] [ 280/ 548] time: 980.8556, train_loss: -47.43624115, val_loss: -53.95377350\n",
      "Epoch: [65] [ 290/ 548] time: 981.1762, train_loss: -53.73278046, val_loss: -53.60272980\n",
      "Epoch: [65] [ 300/ 548] time: 981.4802, train_loss: -45.97131348, val_loss: -53.81266403\n",
      "Epoch: [65] [ 310/ 548] time: 981.7977, train_loss: -51.78230286, val_loss: -53.33944321\n",
      "Epoch: [65] [ 320/ 548] time: 982.0928, train_loss: -40.93928528, val_loss: -54.01604843\n",
      "Epoch: [65] [ 330/ 548] time: 982.3727, train_loss: -47.32439423, val_loss: -54.19880295\n",
      "Epoch: [65] [ 340/ 548] time: 982.6324, train_loss: -55.58136749, val_loss: -54.52416611\n",
      "Epoch: [65] [ 350/ 548] time: 982.8954, train_loss: -55.95645523, val_loss: -54.51101685\n",
      "Epoch: [65] [ 360/ 548] time: 983.1630, train_loss: -54.69129944, val_loss: -54.68217850\n",
      "Epoch: [65] [ 370/ 548] time: 983.4253, train_loss: -49.84585953, val_loss: -53.71139908\n",
      "Epoch: [65] [ 380/ 548] time: 983.6781, train_loss: -56.67980194, val_loss: -54.70510101\n",
      "Saving checkpoint\n",
      "Epoch: [65] [ 390/ 548] time: 984.9755, train_loss: -54.51765823, val_loss: -54.87916946\n",
      "Epoch: [65] [ 400/ 548] time: 985.2290, train_loss: -54.64403534, val_loss: -54.97614288\n",
      "Epoch: [65] [ 410/ 548] time: 985.4583, train_loss: -56.24100494, val_loss: -55.50984573\n",
      "Epoch: [65] [ 420/ 548] time: 985.6875, train_loss: -53.79079437, val_loss: -55.55823898\n",
      "Epoch: [65] [ 430/ 548] time: 985.9150, train_loss: -58.19170761, val_loss: -54.99291611\n",
      "Epoch: [65] [ 440/ 548] time: 986.1611, train_loss: -52.64684296, val_loss: -55.45819092\n",
      "Epoch: [65] [ 450/ 548] time: 986.3943, train_loss: -48.20554733, val_loss: -55.15454102\n",
      "Epoch: [65] [ 460/ 548] time: 986.6297, train_loss: -47.38874054, val_loss: -53.78088379\n",
      "Epoch: [65] [ 470/ 548] time: 986.8727, train_loss: -52.85347366, val_loss: -54.62631607\n",
      "Epoch: [65] [ 480/ 548] time: 987.1354, train_loss: -56.90946579, val_loss: -54.61842346\n",
      "Epoch: [65] [ 490/ 548] time: 987.4172, train_loss: -37.54940033, val_loss: -55.34128189\n",
      "Epoch: [65] [ 500/ 548] time: 987.6993, train_loss: -43.50212860, val_loss: -54.33329773\n",
      "Epoch: [65] [ 510/ 548] time: 987.9744, train_loss: -51.72856903, val_loss: -54.19258881\n",
      "Epoch: [65] [ 520/ 548] time: 988.2276, train_loss: -54.47462845, val_loss: -53.88045502\n",
      "Epoch: [65] [ 530/ 548] time: 988.4765, train_loss: -51.77839661, val_loss: -54.13226318\n",
      "Epoch: [65] [ 540/ 548] time: 988.7195, train_loss: -39.09259415, val_loss: -50.81964874\n",
      "Epoch: [66] [   0/ 548] time: 988.9130, train_loss: -49.74240494, val_loss: -51.69564438\n",
      "Epoch: [66] [  10/ 548] time: 989.1531, train_loss: -46.70815277, val_loss: -54.14233398\n",
      "Epoch: [66] [  20/ 548] time: 989.4064, train_loss: -50.82641983, val_loss: -53.60278320\n",
      "Epoch: [66] [  30/ 548] time: 989.6532, train_loss: -55.56188202, val_loss: -51.19033813\n",
      "Epoch: [66] [  40/ 548] time: 989.9001, train_loss: -55.60847855, val_loss: -52.41080475\n",
      "Epoch: [66] [  50/ 548] time: 990.1813, train_loss: -43.25618362, val_loss: -54.72159195\n",
      "Epoch: [66] [  60/ 548] time: 990.4648, train_loss: -54.96656799, val_loss: -55.51438141\n",
      "Epoch: [66] [  70/ 548] time: 990.7368, train_loss: -51.18652725, val_loss: -55.51543427\n",
      "Epoch: [66] [  80/ 548] time: 991.0157, train_loss: -46.23319244, val_loss: -54.82582474\n",
      "Epoch: [66] [  90/ 548] time: 991.3216, train_loss: -52.09620667, val_loss: -54.59538269\n",
      "Epoch: [66] [ 100/ 548] time: 991.6478, train_loss: -48.58301544, val_loss: -54.13648605\n",
      "Epoch: [66] [ 110/ 548] time: 991.9811, train_loss: -47.39057159, val_loss: -54.30513763\n",
      "Epoch: [66] [ 120/ 548] time: 992.3461, train_loss: -44.39693451, val_loss: -55.84300995\n",
      "Epoch: [66] [ 130/ 548] time: 992.6499, train_loss: -56.57621384, val_loss: -56.53306198\n",
      "Epoch: [66] [ 140/ 548] time: 992.9708, train_loss: -54.16196823, val_loss: -55.72776031\n",
      "Epoch: [66] [ 150/ 548] time: 993.2843, train_loss: -56.77124405, val_loss: -55.33960342\n",
      "Epoch: [66] [ 160/ 548] time: 993.6272, train_loss: -51.89373016, val_loss: -54.55204391\n",
      "Epoch: [66] [ 170/ 548] time: 993.9877, train_loss: -50.98004532, val_loss: -55.05527115\n",
      "Epoch: [66] [ 180/ 548] time: 994.3093, train_loss: -47.65027618, val_loss: -55.23895645\n",
      "Epoch: [66] [ 190/ 548] time: 994.6121, train_loss: -47.63858032, val_loss: -55.33124161\n",
      "Epoch: [66] [ 200/ 548] time: 994.9079, train_loss: -52.05192566, val_loss: -54.96746826\n",
      "Epoch: [66] [ 210/ 548] time: 995.2097, train_loss: -54.04019928, val_loss: -54.06593323\n",
      "Epoch: [66] [ 220/ 548] time: 995.5375, train_loss: -49.59690094, val_loss: -53.86583328\n",
      "Epoch: [66] [ 230/ 548] time: 995.8345, train_loss: -46.53746796, val_loss: -54.80337143\n",
      "Epoch: [66] [ 240/ 548] time: 996.1397, train_loss: -41.69671631, val_loss: -54.32020569\n",
      "Epoch: [66] [ 250/ 548] time: 996.4133, train_loss: -56.45438766, val_loss: -55.14214325\n",
      "Epoch: [66] [ 260/ 548] time: 996.7142, train_loss: -53.75064850, val_loss: -54.59312439\n",
      "Epoch: [66] [ 270/ 548] time: 997.0039, train_loss: -52.87565613, val_loss: -54.11751556\n",
      "Epoch: [66] [ 280/ 548] time: 997.2874, train_loss: -57.72541809, val_loss: -53.59738922\n",
      "Epoch: [66] [ 290/ 548] time: 997.5545, train_loss: -50.95441437, val_loss: -55.08973694\n",
      "Epoch: [66] [ 300/ 548] time: 997.8230, train_loss: -52.76718903, val_loss: -54.86762238\n",
      "Epoch: [66] [ 310/ 548] time: 998.0798, train_loss: -55.19142151, val_loss: -54.87412262\n",
      "Epoch: [66] [ 320/ 548] time: 998.3550, train_loss: -52.19318008, val_loss: -56.07445908\n",
      "Epoch: [66] [ 330/ 548] time: 998.6055, train_loss: -57.85322952, val_loss: -53.87964630\n",
      "Epoch: [66] [ 340/ 548] time: 998.8566, train_loss: -51.42295074, val_loss: -48.86021805\n",
      "Epoch: [66] [ 350/ 548] time: 999.1036, train_loss: -32.62371063, val_loss: -42.93325043\n",
      "Epoch: [66] [ 360/ 548] time: 999.3612, train_loss: -42.15178680, val_loss: -34.94696426\n",
      "Epoch: [66] [ 370/ 548] time: 999.6438, train_loss: -27.28522873, val_loss: -45.75624466\n",
      "Epoch: [66] [ 380/ 548] time: 999.9247, train_loss: -34.61050415, val_loss: -40.82243347\n",
      "Epoch: [66] [ 390/ 548] time: 1000.2057, train_loss: -50.64266968, val_loss: -47.61798477\n",
      "Epoch: [66] [ 400/ 548] time: 1000.4578, train_loss: -36.41240311, val_loss: -42.64433289\n",
      "Epoch: [66] [ 410/ 548] time: 1000.7255, train_loss: -53.35991669, val_loss: -48.05265808\n",
      "Epoch: [66] [ 420/ 548] time: 1000.9896, train_loss: -47.27862167, val_loss: -46.44883347\n",
      "Epoch: [66] [ 430/ 548] time: 1001.2357, train_loss: -50.99893570, val_loss: -52.14878082\n",
      "Epoch: [66] [ 440/ 548] time: 1001.5657, train_loss: -47.02678680, val_loss: -48.52629471\n",
      "Epoch: [66] [ 450/ 548] time: 1001.8232, train_loss: -55.18013382, val_loss: -49.80990601\n",
      "Epoch: [66] [ 460/ 548] time: 1002.0897, train_loss: -47.79439163, val_loss: -52.40612030\n",
      "Epoch: [66] [ 470/ 548] time: 1002.3575, train_loss: -57.03763580, val_loss: -53.09723663\n",
      "Epoch: [66] [ 480/ 548] time: 1002.6324, train_loss: -43.12728882, val_loss: -54.02477646\n",
      "Epoch: [66] [ 490/ 548] time: 1002.8824, train_loss: -42.84870148, val_loss: -52.19885254\n",
      "Epoch: [66] [ 500/ 548] time: 1003.1241, train_loss: -49.46167755, val_loss: -49.74827576\n",
      "Epoch: [66] [ 510/ 548] time: 1003.3768, train_loss: -55.61118698, val_loss: -53.39466095\n",
      "Epoch: [66] [ 520/ 548] time: 1003.6429, train_loss: -52.67206192, val_loss: -49.51258087\n",
      "Epoch: [66] [ 530/ 548] time: 1003.8924, train_loss: -53.80751038, val_loss: -53.05655670\n",
      "Epoch: [66] [ 540/ 548] time: 1004.1336, train_loss: -50.73139572, val_loss: -50.46493912\n",
      "Epoch: [67] [   0/ 548] time: 1004.3223, train_loss: -53.96607590, val_loss: -52.76580048\n",
      "Epoch: [67] [  10/ 548] time: 1004.5834, train_loss: -53.47701645, val_loss: -52.39235306\n",
      "Epoch: [67] [  20/ 548] time: 1004.8313, train_loss: -50.50434494, val_loss: -52.36906052\n",
      "Epoch: [67] [  30/ 548] time: 1005.0828, train_loss: -49.55746460, val_loss: -50.22062683\n",
      "Epoch: [67] [  40/ 548] time: 1005.3556, train_loss: -57.68941116, val_loss: -53.11317062\n",
      "Epoch: [67] [  50/ 548] time: 1005.6405, train_loss: -10.74287415, val_loss: -51.76718903\n",
      "Epoch: [67] [  60/ 548] time: 1005.9343, train_loss: -42.73272705, val_loss: -53.36244583\n",
      "Epoch: [67] [  70/ 548] time: 1006.2182, train_loss: -52.42173767, val_loss: -53.01907349\n",
      "Epoch: [67] [  80/ 548] time: 1006.5232, train_loss: -51.63170242, val_loss: -53.77411652\n",
      "Epoch: [67] [  90/ 548] time: 1006.8070, train_loss: -47.08116913, val_loss: -54.76308441\n",
      "Epoch: [67] [ 100/ 548] time: 1007.1401, train_loss: -54.66201782, val_loss: -54.43884659\n",
      "Epoch: [67] [ 110/ 548] time: 1007.4133, train_loss: -45.02188110, val_loss: -54.73239517\n",
      "Epoch: [67] [ 120/ 548] time: 1007.6664, train_loss: -54.81082535, val_loss: -55.53743362\n",
      "Epoch: [67] [ 130/ 548] time: 1007.9424, train_loss: -57.28005600, val_loss: -54.67327499\n",
      "Epoch: [67] [ 140/ 548] time: 1008.2082, train_loss: -55.82699203, val_loss: -53.94284821\n",
      "Epoch: [67] [ 150/ 548] time: 1008.4762, train_loss: -54.79431152, val_loss: -55.35561752\n",
      "Epoch: [67] [ 160/ 548] time: 1008.7287, train_loss: -57.57589722, val_loss: -55.03650284\n",
      "Epoch: [67] [ 170/ 548] time: 1009.0494, train_loss: -43.76406097, val_loss: -55.52904892\n",
      "Epoch: [67] [ 180/ 548] time: 1009.3318, train_loss: -53.56568146, val_loss: -55.63127899\n",
      "Epoch: [67] [ 190/ 548] time: 1009.6009, train_loss: -48.38442230, val_loss: -55.79384232\n",
      "Epoch: [67] [ 200/ 548] time: 1009.8663, train_loss: -51.95580292, val_loss: -55.26354218\n",
      "Epoch: [67] [ 210/ 548] time: 1010.1357, train_loss: -54.46477127, val_loss: -55.85707474\n",
      "Epoch: [67] [ 220/ 548] time: 1010.4104, train_loss: -50.88777161, val_loss: -56.00402832\n",
      "Epoch: [67] [ 230/ 548] time: 1010.6652, train_loss: -58.63624191, val_loss: -55.22237015\n",
      "Epoch: [67] [ 240/ 548] time: 1010.9416, train_loss: -46.84835052, val_loss: -55.80466843\n",
      "Epoch: [67] [ 250/ 548] time: 1011.2146, train_loss: -58.58294296, val_loss: -55.15180588\n",
      "Epoch: [67] [ 260/ 548] time: 1011.4903, train_loss: -54.79217529, val_loss: -55.65801239\n",
      "Epoch: [67] [ 270/ 548] time: 1011.8477, train_loss: -54.08367157, val_loss: -55.86737442\n",
      "Epoch: [67] [ 280/ 548] time: 1012.2580, train_loss: -56.22245026, val_loss: -55.91323471\n",
      "Saving checkpoint\n",
      "Epoch: [67] [ 290/ 548] time: 1014.1994, train_loss: -55.10526657, val_loss: -56.10819626\n",
      "Epoch: [67] [ 300/ 548] time: 1014.5717, train_loss: -57.28189850, val_loss: -55.75788116\n",
      "Epoch: [67] [ 310/ 548] time: 1014.9009, train_loss: -57.85650253, val_loss: -56.04783249\n",
      "Epoch: [67] [ 320/ 548] time: 1015.1849, train_loss: -55.11802673, val_loss: -55.37208557\n",
      "Epoch: [67] [ 330/ 548] time: 1015.4994, train_loss: -49.41248322, val_loss: -55.85048294\n",
      "Epoch: [67] [ 340/ 548] time: 1015.7962, train_loss: -56.89628983, val_loss: -55.87744904\n",
      "Epoch: [67] [ 350/ 548] time: 1016.0949, train_loss: -51.25539398, val_loss: -55.98073578\n",
      "Epoch: [67] [ 360/ 548] time: 1016.3784, train_loss: -52.40284348, val_loss: -53.69581604\n",
      "Epoch: [67] [ 370/ 548] time: 1016.6616, train_loss: -58.44315338, val_loss: -53.40037537\n",
      "Epoch: [67] [ 380/ 548] time: 1016.9503, train_loss: -42.43379211, val_loss: -54.88931274\n",
      "Epoch: [67] [ 390/ 548] time: 1017.2532, train_loss: -53.61978149, val_loss: -54.30406570\n",
      "Epoch: [67] [ 400/ 548] time: 1017.5209, train_loss: -40.43173218, val_loss: -55.33506393\n",
      "Epoch: [67] [ 410/ 548] time: 1017.7877, train_loss: -56.14280701, val_loss: -54.91111755\n",
      "Epoch: [67] [ 420/ 548] time: 1018.0642, train_loss: -55.30821991, val_loss: -55.26000595\n",
      "Epoch: [67] [ 430/ 548] time: 1018.3712, train_loss: -57.18643951, val_loss: -55.17251587\n",
      "Epoch: [67] [ 440/ 548] time: 1018.6658, train_loss: -52.75679016, val_loss: -54.54802704\n",
      "Epoch: [67] [ 450/ 548] time: 1018.9667, train_loss: -28.36042023, val_loss: -55.53041077\n",
      "Epoch: [67] [ 460/ 548] time: 1019.2361, train_loss: -51.58736801, val_loss: -55.42236328\n",
      "Epoch: [67] [ 470/ 548] time: 1019.5098, train_loss: -52.64194107, val_loss: -55.77004242\n",
      "Epoch: [67] [ 480/ 548] time: 1019.7733, train_loss: -56.54817963, val_loss: -54.57371902\n",
      "Epoch: [67] [ 490/ 548] time: 1020.0467, train_loss: -56.06455994, val_loss: -56.09276962\n",
      "Epoch: [67] [ 500/ 548] time: 1020.3160, train_loss: -56.68393707, val_loss: -55.48648834\n",
      "Epoch: [67] [ 510/ 548] time: 1020.5725, train_loss: -56.09016800, val_loss: -56.55950546\n",
      "Epoch: [67] [ 520/ 548] time: 1020.8362, train_loss: -54.09381104, val_loss: -56.14648438\n",
      "Epoch: [67] [ 530/ 548] time: 1021.0866, train_loss: -57.72414780, val_loss: -54.35562515\n",
      "Epoch: [67] [ 540/ 548] time: 1021.3567, train_loss: -55.72571564, val_loss: -54.32023621\n",
      "Epoch: [68] [   0/ 548] time: 1021.5728, train_loss: -56.08333206, val_loss: -55.59370041\n",
      "Epoch: [68] [  10/ 548] time: 1021.8383, train_loss: -53.01430893, val_loss: -55.14315414\n",
      "Epoch: [68] [  20/ 548] time: 1022.1098, train_loss: -52.78322601, val_loss: -53.79425430\n",
      "Epoch: [68] [  30/ 548] time: 1022.3886, train_loss: -58.15856934, val_loss: -54.05857086\n",
      "Epoch: [68] [  40/ 548] time: 1022.6400, train_loss: -53.03335571, val_loss: -55.76610947\n",
      "Epoch: [68] [  50/ 548] time: 1022.9033, train_loss: -49.50703812, val_loss: -55.09117126\n",
      "Epoch: [68] [  60/ 548] time: 1023.1631, train_loss: -52.52277756, val_loss: -54.41026688\n",
      "Epoch: [68] [  70/ 548] time: 1023.4262, train_loss: -56.67875290, val_loss: -55.15485382\n",
      "Epoch: [68] [  80/ 548] time: 1023.6833, train_loss: -46.25742340, val_loss: -54.81920624\n",
      "Epoch: [68] [  90/ 548] time: 1023.9495, train_loss: -59.38256073, val_loss: -55.48992157\n",
      "Epoch: [68] [ 100/ 548] time: 1024.2251, train_loss: -50.80161667, val_loss: -55.14678574\n",
      "Epoch: [68] [ 110/ 548] time: 1024.4985, train_loss: -47.15416336, val_loss: -54.61825562\n",
      "Epoch: [68] [ 120/ 548] time: 1024.7964, train_loss: -48.71868134, val_loss: -53.44750214\n",
      "Epoch: [68] [ 130/ 548] time: 1025.1010, train_loss: -50.60659027, val_loss: -54.99771118\n",
      "Epoch: [68] [ 140/ 548] time: 1025.4005, train_loss: -54.16333389, val_loss: -54.12160492\n",
      "Epoch: [68] [ 150/ 548] time: 1025.6916, train_loss: -51.10378647, val_loss: -52.22151566\n",
      "Epoch: [68] [ 160/ 548] time: 1025.9630, train_loss: -46.10892487, val_loss: -53.74074554\n",
      "Epoch: [68] [ 170/ 548] time: 1026.2488, train_loss: -44.72053528, val_loss: -49.47720337\n",
      "Epoch: [68] [ 180/ 548] time: 1026.5865, train_loss: -47.07012939, val_loss: -49.71910095\n",
      "Epoch: [68] [ 190/ 548] time: 1026.9147, train_loss: -49.97383881, val_loss: -52.96630096\n",
      "Epoch: [68] [ 200/ 548] time: 1027.2602, train_loss: -53.89955902, val_loss: -50.13442993\n",
      "Epoch: [68] [ 210/ 548] time: 1027.5658, train_loss: -39.02790833, val_loss: -48.31702805\n",
      "Epoch: [68] [ 220/ 548] time: 1027.8699, train_loss: -48.21167755, val_loss: -48.90804291\n",
      "Epoch: [68] [ 230/ 548] time: 1028.2073, train_loss: -52.40073776, val_loss: -47.62481689\n",
      "Epoch: [68] [ 240/ 548] time: 1028.5258, train_loss: -44.03479004, val_loss: -49.63639832\n",
      "Epoch: [68] [ 250/ 548] time: 1028.8624, train_loss: -36.02350616, val_loss: -52.06897354\n",
      "Epoch: [68] [ 260/ 548] time: 1029.1768, train_loss: -47.40284348, val_loss: -49.20490265\n",
      "Epoch: [68] [ 270/ 548] time: 1029.4791, train_loss: -49.88425064, val_loss: -49.59608459\n",
      "Epoch: [68] [ 280/ 548] time: 1029.7532, train_loss: -52.60852051, val_loss: -50.67274094\n",
      "Epoch: [68] [ 290/ 548] time: 1030.0227, train_loss: -49.59121704, val_loss: -50.57086563\n",
      "Epoch: [68] [ 300/ 548] time: 1030.2964, train_loss: -50.14772415, val_loss: -49.64176941\n",
      "Epoch: [68] [ 310/ 548] time: 1030.5751, train_loss: -43.64166641, val_loss: -52.68304443\n",
      "Epoch: [68] [ 320/ 548] time: 1030.8471, train_loss: -51.33647537, val_loss: -52.80731201\n",
      "Epoch: [68] [ 330/ 548] time: 1031.1144, train_loss: -52.50875473, val_loss: -52.10868454\n",
      "Epoch: [68] [ 340/ 548] time: 1031.3650, train_loss: -49.87522125, val_loss: -51.97193527\n",
      "Epoch: [68] [ 350/ 548] time: 1031.6201, train_loss: -54.79371643, val_loss: -53.82633209\n",
      "Epoch: [68] [ 360/ 548] time: 1031.8784, train_loss: -51.12924194, val_loss: -53.37549210\n",
      "Epoch: [68] [ 370/ 548] time: 1032.1236, train_loss: -51.78355408, val_loss: -54.28630066\n",
      "Epoch: [68] [ 380/ 548] time: 1032.3616, train_loss: -46.94922256, val_loss: -52.99059677\n",
      "Epoch: [68] [ 390/ 548] time: 1032.6061, train_loss: -56.21060181, val_loss: -54.37866211\n",
      "Epoch: [68] [ 400/ 548] time: 1032.8442, train_loss: -53.16703415, val_loss: -54.69400024\n",
      "Epoch: [68] [ 410/ 548] time: 1033.0767, train_loss: -55.59954453, val_loss: -54.05068970\n",
      "Epoch: [68] [ 420/ 548] time: 1033.3128, train_loss: -41.65804672, val_loss: -53.69905090\n",
      "Epoch: [68] [ 430/ 548] time: 1033.5446, train_loss: -41.78266144, val_loss: -53.95748520\n",
      "Epoch: [68] [ 440/ 548] time: 1033.7781, train_loss: -50.41695404, val_loss: -54.62556076\n",
      "Epoch: [68] [ 450/ 548] time: 1034.0150, train_loss: -53.89269257, val_loss: -52.65395355\n",
      "Epoch: [68] [ 460/ 548] time: 1034.2541, train_loss: -46.46604156, val_loss: -51.68900299\n",
      "Epoch: [68] [ 470/ 548] time: 1034.4977, train_loss: -54.94109726, val_loss: -53.27842712\n",
      "Epoch: [68] [ 480/ 548] time: 1034.7387, train_loss: -50.07549286, val_loss: -53.81287003\n",
      "Epoch: [68] [ 490/ 548] time: 1034.9824, train_loss: -57.00076294, val_loss: -54.16115189\n",
      "Epoch: [68] [ 500/ 548] time: 1035.2298, train_loss: -57.37935638, val_loss: -54.66003418\n",
      "Epoch: [68] [ 510/ 548] time: 1035.4747, train_loss: -47.83386993, val_loss: -55.34373093\n",
      "Epoch: [68] [ 520/ 548] time: 1035.7158, train_loss: -50.51393127, val_loss: -54.30427933\n",
      "Epoch: [68] [ 530/ 548] time: 1035.9620, train_loss: -57.24617767, val_loss: -54.71067810\n",
      "Epoch: [68] [ 540/ 548] time: 1036.2126, train_loss: -46.24682617, val_loss: -54.48107147\n",
      "Epoch: [69] [   0/ 548] time: 1036.4296, train_loss: -47.30558014, val_loss: -54.47543335\n",
      "Epoch: [69] [  10/ 548] time: 1036.7255, train_loss: -57.05308151, val_loss: -54.99194336\n",
      "Epoch: [69] [  20/ 548] time: 1037.0143, train_loss: -49.72616577, val_loss: -55.82753372\n",
      "Epoch: [69] [  30/ 548] time: 1037.3697, train_loss: -55.17178726, val_loss: -55.79118729\n",
      "Epoch: [69] [  40/ 548] time: 1037.7320, train_loss: -56.58551025, val_loss: -55.89857101\n",
      "Epoch: [69] [  50/ 548] time: 1038.0621, train_loss: -52.84770966, val_loss: -56.16783905\n",
      "Epoch: [69] [  60/ 548] time: 1038.3761, train_loss: -54.18955231, val_loss: -55.64327240\n",
      "Epoch: [69] [  70/ 548] time: 1038.7180, train_loss: -44.55361938, val_loss: -55.96018219\n",
      "Epoch: [69] [  80/ 548] time: 1039.0532, train_loss: -51.27183533, val_loss: -55.01769638\n",
      "Epoch: [69] [  90/ 548] time: 1039.3850, train_loss: -51.66223145, val_loss: -55.98314285\n",
      "Epoch: [69] [ 100/ 548] time: 1039.7481, train_loss: -57.31235886, val_loss: -55.08599091\n",
      "Epoch: [69] [ 110/ 548] time: 1040.0622, train_loss: -57.24188232, val_loss: -55.96999359\n",
      "Epoch: [69] [ 120/ 548] time: 1040.4096, train_loss: -52.85433960, val_loss: -54.79793167\n",
      "Epoch: [69] [ 130/ 548] time: 1040.7351, train_loss: -53.29319763, val_loss: -54.74934387\n",
      "Epoch: [69] [ 140/ 548] time: 1041.0438, train_loss: -56.49567032, val_loss: -55.59232330\n",
      "Epoch: [69] [ 150/ 548] time: 1041.3399, train_loss: -47.89117813, val_loss: -54.51987839\n",
      "Epoch: [69] [ 160/ 548] time: 1041.6508, train_loss: -55.54238129, val_loss: -55.70801544\n",
      "Epoch: [69] [ 170/ 548] time: 1041.9549, train_loss: -56.80101395, val_loss: -54.43191528\n",
      "Epoch: [69] [ 180/ 548] time: 1042.2476, train_loss: -47.80268097, val_loss: -55.35792160\n",
      "Saving checkpoint\n",
      "Epoch: [69] [ 190/ 548] time: 1043.6475, train_loss: -57.64374924, val_loss: -53.41384888\n",
      "Epoch: [69] [ 200/ 548] time: 1043.9232, train_loss: -58.41606903, val_loss: -54.27828598\n",
      "Epoch: [69] [ 210/ 548] time: 1044.2094, train_loss: -36.85979080, val_loss: -53.61422729\n",
      "Epoch: [69] [ 220/ 548] time: 1044.4770, train_loss: -49.65956879, val_loss: -51.24211884\n",
      "Epoch: [69] [ 230/ 548] time: 1044.7569, train_loss: -52.67848587, val_loss: -52.16719818\n",
      "Epoch: [69] [ 240/ 548] time: 1045.0414, train_loss: -56.11879730, val_loss: -53.69614410\n",
      "Epoch: [69] [ 250/ 548] time: 1045.3129, train_loss: -55.72194672, val_loss: -53.71751404\n",
      "Epoch: [69] [ 260/ 548] time: 1045.5865, train_loss: -55.58068848, val_loss: -53.43984222\n",
      "Epoch: [69] [ 270/ 548] time: 1045.8609, train_loss: -49.60232544, val_loss: -54.66542435\n",
      "Epoch: [69] [ 280/ 548] time: 1046.1438, train_loss: -54.43313599, val_loss: -55.32845306\n",
      "Epoch: [69] [ 290/ 548] time: 1046.4154, train_loss: -42.71460724, val_loss: -55.80783844\n",
      "Epoch: [69] [ 300/ 548] time: 1046.6931, train_loss: -59.00844955, val_loss: -55.72244263\n",
      "Epoch: [69] [ 310/ 548] time: 1046.9701, train_loss: -50.70967484, val_loss: -55.38607407\n",
      "Epoch: [69] [ 320/ 548] time: 1047.2619, train_loss: -54.73459244, val_loss: -55.35429001\n",
      "Epoch: [69] [ 330/ 548] time: 1047.5446, train_loss: -58.26671982, val_loss: -56.10083389\n",
      "Epoch: [69] [ 340/ 548] time: 1047.8308, train_loss: -50.16146851, val_loss: -55.42210388\n",
      "Epoch: [69] [ 350/ 548] time: 1048.1273, train_loss: -52.46247101, val_loss: -54.86910248\n",
      "Epoch: [69] [ 360/ 548] time: 1048.4457, train_loss: -56.56863403, val_loss: -56.36598206\n",
      "Epoch: [69] [ 370/ 548] time: 1048.7730, train_loss: -50.20422363, val_loss: -56.11029816\n",
      "Epoch: [69] [ 380/ 548] time: 1049.0929, train_loss: -36.73701477, val_loss: -55.78757858\n",
      "Epoch: [69] [ 390/ 548] time: 1049.3604, train_loss: -53.40204239, val_loss: -55.28497314\n",
      "Epoch: [69] [ 400/ 548] time: 1049.6236, train_loss: -49.12458038, val_loss: -56.29021072\n",
      "Epoch: [69] [ 410/ 548] time: 1049.8805, train_loss: -42.22906494, val_loss: -56.12850571\n",
      "Epoch: [69] [ 420/ 548] time: 1050.1349, train_loss: -52.89739990, val_loss: -55.45726776\n",
      "Epoch: [69] [ 430/ 548] time: 1050.3897, train_loss: -55.84202576, val_loss: -55.66167831\n",
      "Epoch: [69] [ 440/ 548] time: 1050.6445, train_loss: -54.05726624, val_loss: -55.31818771\n",
      "Epoch: [69] [ 450/ 548] time: 1050.9064, train_loss: -50.17726135, val_loss: -55.26205826\n",
      "Epoch: [69] [ 460/ 548] time: 1051.1690, train_loss: -55.01390839, val_loss: -54.22693634\n",
      "Epoch: [69] [ 470/ 548] time: 1051.4235, train_loss: -49.26016998, val_loss: -55.47295761\n",
      "Epoch: [69] [ 480/ 548] time: 1051.7087, train_loss: -42.06949615, val_loss: -56.30322266\n",
      "Epoch: [69] [ 490/ 548] time: 1051.9654, train_loss: -49.80205536, val_loss: -54.47757721\n",
      "Epoch: [69] [ 500/ 548] time: 1052.2497, train_loss: -55.28984451, val_loss: -54.91167831\n",
      "Epoch: [69] [ 510/ 548] time: 1052.4978, train_loss: -56.71295929, val_loss: -55.29769897\n",
      "Epoch: [69] [ 520/ 548] time: 1052.7552, train_loss: -57.45967102, val_loss: -55.88296509\n",
      "Epoch: [69] [ 530/ 548] time: 1053.0180, train_loss: -56.59321594, val_loss: -55.72486877\n",
      "Epoch: [69] [ 540/ 548] time: 1053.2893, train_loss: -53.18776703, val_loss: -53.66492462\n",
      "Epoch: [70] [   0/ 548] time: 1053.5044, train_loss: -54.92764282, val_loss: -54.21466064\n",
      "Epoch: [70] [  10/ 548] time: 1053.7715, train_loss: -50.87377548, val_loss: -54.90282822\n",
      "Epoch: [70] [  20/ 548] time: 1054.0450, train_loss: -50.63890076, val_loss: -55.32829285\n",
      "Epoch: [70] [  30/ 548] time: 1054.3476, train_loss: -50.18289948, val_loss: -55.08063507\n",
      "Epoch: [70] [  40/ 548] time: 1054.6505, train_loss: -57.54684448, val_loss: -54.55818558\n",
      "Epoch: [70] [  50/ 548] time: 1054.9585, train_loss: -48.97421646, val_loss: -55.03056335\n",
      "Epoch: [70] [  60/ 548] time: 1055.2762, train_loss: -40.63581085, val_loss: -53.16049957\n",
      "Epoch: [70] [  70/ 548] time: 1055.5929, train_loss: -38.41318893, val_loss: -55.69496155\n",
      "Epoch: [70] [  80/ 548] time: 1055.8472, train_loss: -48.85061264, val_loss: -52.45270538\n",
      "Epoch: [70] [  90/ 548] time: 1056.0981, train_loss: -48.98926163, val_loss: -55.22229004\n",
      "Epoch: [70] [ 100/ 548] time: 1056.3499, train_loss: -51.47967529, val_loss: -54.94271088\n",
      "Epoch: [70] [ 110/ 548] time: 1056.6011, train_loss: -59.55317688, val_loss: -54.89917755\n",
      "Epoch: [70] [ 120/ 548] time: 1056.8553, train_loss: -49.78059006, val_loss: -50.16329193\n",
      "Epoch: [70] [ 130/ 548] time: 1057.1080, train_loss: -42.07130432, val_loss: -52.30402374\n",
      "Epoch: [70] [ 140/ 548] time: 1057.3560, train_loss: -52.56877518, val_loss: -52.84964752\n",
      "Epoch: [70] [ 150/ 548] time: 1057.6019, train_loss: -53.26193237, val_loss: -48.14319992\n",
      "Epoch: [70] [ 160/ 548] time: 1057.8426, train_loss: -33.05068970, val_loss: -51.11702728\n",
      "Epoch: [70] [ 170/ 548] time: 1058.0814, train_loss: -41.25244141, val_loss: -49.51853943\n",
      "Epoch: [70] [ 180/ 548] time: 1058.3356, train_loss: -44.26903534, val_loss: -52.53362656\n",
      "Epoch: [70] [ 190/ 548] time: 1058.5855, train_loss: -49.55419159, val_loss: -52.26964188\n",
      "Epoch: [70] [ 200/ 548] time: 1058.8262, train_loss: -20.65762329, val_loss: -54.95261002\n",
      "Epoch: [70] [ 210/ 548] time: 1059.0706, train_loss: -48.01001740, val_loss: -54.44361877\n",
      "Epoch: [70] [ 220/ 548] time: 1059.3159, train_loss: -54.82244492, val_loss: -54.24280548\n",
      "Epoch: [70] [ 230/ 548] time: 1059.5601, train_loss: -49.46406937, val_loss: -54.26295471\n",
      "Epoch: [70] [ 240/ 548] time: 1059.8039, train_loss: -51.74369812, val_loss: -53.09177780\n",
      "Epoch: [70] [ 250/ 548] time: 1060.0750, train_loss: -55.89761353, val_loss: -51.13064575\n",
      "Epoch: [70] [ 260/ 548] time: 1060.3460, train_loss: -55.04719925, val_loss: -53.09272385\n",
      "Epoch: [70] [ 270/ 548] time: 1060.6301, train_loss: -53.47713852, val_loss: -54.04663086\n",
      "Epoch: [70] [ 280/ 548] time: 1060.9297, train_loss: -43.60909271, val_loss: -53.64448547\n",
      "Epoch: [70] [ 290/ 548] time: 1061.2213, train_loss: -56.82931519, val_loss: -54.87728500\n",
      "Epoch: [70] [ 300/ 548] time: 1061.5354, train_loss: -54.97107697, val_loss: -54.28053284\n",
      "Epoch: [70] [ 310/ 548] time: 1061.8497, train_loss: -58.17225266, val_loss: -55.18058777\n",
      "Epoch: [70] [ 320/ 548] time: 1062.1377, train_loss: -53.96232224, val_loss: -54.36826706\n",
      "Epoch: [70] [ 330/ 548] time: 1062.4353, train_loss: -55.36569214, val_loss: -54.98109055\n",
      "Epoch: [70] [ 340/ 548] time: 1062.7231, train_loss: -48.25146866, val_loss: -55.37039948\n",
      "Epoch: [70] [ 350/ 548] time: 1063.0068, train_loss: -49.64180374, val_loss: -54.80029297\n",
      "Epoch: [70] [ 360/ 548] time: 1063.2908, train_loss: -56.99448776, val_loss: -54.46109772\n",
      "Epoch: [70] [ 370/ 548] time: 1063.5507, train_loss: -47.44436646, val_loss: -55.36598587\n",
      "Epoch: [70] [ 380/ 548] time: 1063.8055, train_loss: -52.75593567, val_loss: -54.89855576\n",
      "Epoch: [70] [ 390/ 548] time: 1064.0669, train_loss: -45.88883972, val_loss: -55.23478317\n",
      "Epoch: [70] [ 400/ 548] time: 1064.3405, train_loss: -42.04148865, val_loss: -55.97302246\n",
      "Epoch: [70] [ 410/ 548] time: 1064.6145, train_loss: -54.55695343, val_loss: -56.20295715\n",
      "Epoch: [70] [ 420/ 548] time: 1064.8660, train_loss: -44.98272324, val_loss: -55.61957550\n",
      "Epoch: [70] [ 430/ 548] time: 1065.1120, train_loss: -54.97678375, val_loss: -55.71814346\n",
      "Epoch: [70] [ 440/ 548] time: 1065.3780, train_loss: -57.24327469, val_loss: -56.11475372\n",
      "Epoch: [70] [ 450/ 548] time: 1065.6540, train_loss: -55.57173157, val_loss: -55.76261902\n",
      "Epoch: [70] [ 460/ 548] time: 1065.9222, train_loss: -54.96298599, val_loss: -55.99320984\n",
      "Epoch: [70] [ 470/ 548] time: 1066.1907, train_loss: -55.99060822, val_loss: -56.93278122\n",
      "Epoch: [70] [ 480/ 548] time: 1066.4548, train_loss: -56.99789047, val_loss: -56.13249207\n",
      "Epoch: [70] [ 490/ 548] time: 1066.7429, train_loss: -50.81581116, val_loss: -56.02554321\n",
      "Epoch: [70] [ 500/ 548] time: 1067.0411, train_loss: -52.76188660, val_loss: -54.36801910\n",
      "Epoch: [70] [ 510/ 548] time: 1067.3323, train_loss: -56.30576324, val_loss: -56.28520203\n",
      "Epoch: [70] [ 520/ 548] time: 1067.6343, train_loss: -55.72792816, val_loss: -55.23425293\n",
      "Epoch: [70] [ 530/ 548] time: 1067.9117, train_loss: -59.18428040, val_loss: -54.34767914\n",
      "Epoch: [70] [ 540/ 548] time: 1068.1642, train_loss: -53.75257874, val_loss: -55.43326950\n",
      "Epoch: [71] [   0/ 548] time: 1068.3665, train_loss: -58.72141266, val_loss: -55.69055176\n",
      "Epoch: [71] [  10/ 548] time: 1068.6484, train_loss: -45.07124329, val_loss: -55.18640137\n",
      "Epoch: [71] [  20/ 548] time: 1068.9295, train_loss: -55.92393112, val_loss: -55.43316269\n",
      "Epoch: [71] [  30/ 548] time: 1069.2083, train_loss: -54.71844864, val_loss: -53.41923904\n",
      "Epoch: [71] [  40/ 548] time: 1069.4741, train_loss: -54.78822708, val_loss: -52.38838196\n",
      "Epoch: [71] [  50/ 548] time: 1069.7377, train_loss: -47.77427292, val_loss: -54.58643723\n",
      "Epoch: [71] [  60/ 548] time: 1069.9831, train_loss: -54.95256805, val_loss: -53.24295425\n",
      "Epoch: [71] [  70/ 548] time: 1070.2598, train_loss: -53.92721558, val_loss: -53.69570923\n",
      "Epoch: [71] [  80/ 548] time: 1070.5324, train_loss: -49.16765213, val_loss: -54.28900528\n",
      "Epoch: [71] [  90/ 548] time: 1070.7989, train_loss: -53.43166351, val_loss: -55.08329391\n",
      "Saving checkpoint\n",
      "Epoch: [71] [ 100/ 548] time: 1072.1777, train_loss: -57.63774109, val_loss: -55.55664444\n",
      "Epoch: [71] [ 110/ 548] time: 1072.4833, train_loss: -53.35472488, val_loss: -53.75463104\n",
      "Epoch: [71] [ 120/ 548] time: 1072.7444, train_loss: -56.30631638, val_loss: -54.59721375\n",
      "Epoch: [71] [ 130/ 548] time: 1073.0284, train_loss: -57.38530350, val_loss: -53.07666016\n",
      "Epoch: [71] [ 140/ 548] time: 1073.3252, train_loss: -50.80642700, val_loss: -53.63357162\n",
      "Epoch: [71] [ 150/ 548] time: 1073.6163, train_loss: -47.32318878, val_loss: -54.84771347\n",
      "Epoch: [71] [ 160/ 548] time: 1073.8817, train_loss: -57.78619766, val_loss: -55.29842377\n",
      "Epoch: [71] [ 170/ 548] time: 1074.1640, train_loss: -56.51972961, val_loss: -55.18711472\n",
      "Epoch: [71] [ 180/ 548] time: 1074.4183, train_loss: -58.67505646, val_loss: -55.76177597\n",
      "Epoch: [71] [ 190/ 548] time: 1074.6701, train_loss: -52.17450714, val_loss: -56.00084686\n",
      "Epoch: [71] [ 200/ 548] time: 1074.9162, train_loss: -53.89099884, val_loss: -54.34382248\n",
      "Epoch: [71] [ 210/ 548] time: 1075.1728, train_loss: -43.45197296, val_loss: -54.18652344\n",
      "Epoch: [71] [ 220/ 548] time: 1075.4482, train_loss: -30.02000046, val_loss: -53.73363876\n",
      "Epoch: [71] [ 230/ 548] time: 1075.7162, train_loss: -49.01277542, val_loss: -53.78195572\n",
      "Epoch: [71] [ 240/ 548] time: 1075.9808, train_loss: -54.09137726, val_loss: -52.83807373\n",
      "Epoch: [71] [ 250/ 548] time: 1076.2332, train_loss: -55.94184875, val_loss: -54.49066925\n",
      "Epoch: [71] [ 260/ 548] time: 1076.5083, train_loss: -58.72847366, val_loss: -55.40587616\n",
      "Epoch: [71] [ 270/ 548] time: 1076.7738, train_loss: -57.67304993, val_loss: -54.89687347\n",
      "Epoch: [71] [ 280/ 548] time: 1077.0228, train_loss: -57.50476837, val_loss: -54.49003220\n",
      "Epoch: [71] [ 290/ 548] time: 1077.2703, train_loss: -52.27495575, val_loss: -55.32584381\n",
      "Epoch: [71] [ 300/ 548] time: 1077.5397, train_loss: -54.82277679, val_loss: -55.62818909\n",
      "Epoch: [71] [ 310/ 548] time: 1077.7815, train_loss: -57.89698410, val_loss: -55.35725021\n",
      "Epoch: [71] [ 320/ 548] time: 1078.0190, train_loss: -56.53086853, val_loss: -55.25180054\n",
      "Epoch: [71] [ 330/ 548] time: 1078.2633, train_loss: -54.74648666, val_loss: -54.72827911\n",
      "Epoch: [71] [ 340/ 548] time: 1078.5170, train_loss: -49.93360138, val_loss: -55.50112152\n",
      "Epoch: [71] [ 350/ 548] time: 1078.8070, train_loss: -58.63300323, val_loss: -55.17805862\n",
      "Epoch: [71] [ 360/ 548] time: 1079.1094, train_loss: -18.96964645, val_loss: -56.12514114\n",
      "Epoch: [71] [ 370/ 548] time: 1079.4144, train_loss: -51.71158600, val_loss: -55.71928024\n",
      "Epoch: [71] [ 380/ 548] time: 1079.7003, train_loss: -55.01872635, val_loss: -55.63916779\n",
      "Epoch: [71] [ 390/ 548] time: 1079.9690, train_loss: -54.63847351, val_loss: -56.34236145\n",
      "Epoch: [71] [ 400/ 548] time: 1080.2446, train_loss: -56.02324295, val_loss: -56.49124146\n",
      "Epoch: [71] [ 410/ 548] time: 1080.5007, train_loss: -57.35047913, val_loss: -55.03598404\n",
      "Epoch: [71] [ 420/ 548] time: 1080.7610, train_loss: -53.13879395, val_loss: -56.07806396\n",
      "Epoch: [71] [ 430/ 548] time: 1081.0423, train_loss: -56.60376740, val_loss: -55.03839874\n",
      "Epoch: [71] [ 440/ 548] time: 1081.3194, train_loss: -40.78212357, val_loss: -54.43750381\n",
      "Epoch: [71] [ 450/ 548] time: 1081.5800, train_loss: -39.37006760, val_loss: -49.64126587\n",
      "Epoch: [71] [ 460/ 548] time: 1081.8292, train_loss: -56.29395294, val_loss: -53.12268066\n",
      "Epoch: [71] [ 470/ 548] time: 1082.0973, train_loss: -54.73926163, val_loss: -52.57043457\n",
      "Epoch: [71] [ 480/ 548] time: 1082.4170, train_loss: -54.84974289, val_loss: -54.54357147\n",
      "Epoch: [71] [ 490/ 548] time: 1082.6835, train_loss: -52.45755005, val_loss: -55.33882141\n",
      "Epoch: [71] [ 500/ 548] time: 1082.9495, train_loss: -55.41455460, val_loss: -54.05509186\n",
      "Epoch: [71] [ 510/ 548] time: 1083.2206, train_loss: -42.13790894, val_loss: -52.61655426\n",
      "Epoch: [71] [ 520/ 548] time: 1083.4713, train_loss: -50.17875671, val_loss: -55.02215576\n",
      "Epoch: [71] [ 530/ 548] time: 1083.7117, train_loss: -50.19411469, val_loss: -53.25868988\n",
      "Epoch: [71] [ 540/ 548] time: 1083.9513, train_loss: -49.73574829, val_loss: -54.98647690\n",
      "Epoch: [72] [   0/ 548] time: 1084.1672, train_loss: -45.77951813, val_loss: -54.45832825\n",
      "Epoch: [72] [  10/ 548] time: 1084.4415, train_loss: -47.66917419, val_loss: -52.82894516\n",
      "Epoch: [72] [  20/ 548] time: 1084.7105, train_loss: -55.32980728, val_loss: -51.39362335\n",
      "Epoch: [72] [  30/ 548] time: 1085.0213, train_loss: -52.33127594, val_loss: -50.87225342\n",
      "Epoch: [72] [  40/ 548] time: 1085.3113, train_loss: -49.09804535, val_loss: -53.47376633\n",
      "Epoch: [72] [  50/ 548] time: 1085.7286, train_loss: -48.15249634, val_loss: -52.82856750\n",
      "Epoch: [72] [  60/ 548] time: 1086.1103, train_loss: -53.12781525, val_loss: -51.36273193\n",
      "Epoch: [72] [  70/ 548] time: 1086.4333, train_loss: -46.92285919, val_loss: -53.39942169\n",
      "Epoch: [72] [  80/ 548] time: 1086.7819, train_loss: -50.57671356, val_loss: -48.89039230\n",
      "Epoch: [72] [  90/ 548] time: 1087.1318, train_loss: -50.34266663, val_loss: -50.85992432\n",
      "Epoch: [72] [ 100/ 548] time: 1087.4696, train_loss: -55.44343185, val_loss: -50.39635468\n",
      "Epoch: [72] [ 110/ 548] time: 1087.8289, train_loss: -52.09082794, val_loss: -52.31207275\n",
      "Epoch: [72] [ 120/ 548] time: 1088.1472, train_loss: -33.19314575, val_loss: -54.66192245\n",
      "Epoch: [72] [ 130/ 548] time: 1088.4927, train_loss: -57.85556412, val_loss: -52.54612732\n",
      "Epoch: [72] [ 140/ 548] time: 1088.7942, train_loss: -55.98282242, val_loss: -53.94446564\n",
      "Epoch: [72] [ 150/ 548] time: 1089.1453, train_loss: -52.37927246, val_loss: -52.82121277\n",
      "Epoch: [72] [ 160/ 548] time: 1089.4604, train_loss: -56.68945312, val_loss: -54.55086899\n",
      "Epoch: [72] [ 170/ 548] time: 1089.7602, train_loss: -56.15483093, val_loss: -53.72290039\n",
      "Epoch: [72] [ 180/ 548] time: 1090.0596, train_loss: -47.55590439, val_loss: -51.73190689\n",
      "Epoch: [72] [ 190/ 548] time: 1090.3175, train_loss: -52.42253494, val_loss: -51.70142365\n",
      "Epoch: [72] [ 200/ 548] time: 1090.5769, train_loss: -53.43169403, val_loss: -52.31842041\n",
      "Epoch: [72] [ 210/ 548] time: 1090.8246, train_loss: -55.86852646, val_loss: -52.13174820\n",
      "Epoch: [72] [ 220/ 548] time: 1091.0631, train_loss: -49.63871384, val_loss: -52.48916245\n",
      "Epoch: [72] [ 230/ 548] time: 1091.3184, train_loss: -44.97613907, val_loss: -53.52979279\n",
      "Epoch: [72] [ 240/ 548] time: 1091.5849, train_loss: -48.46165466, val_loss: -52.87762070\n",
      "Epoch: [72] [ 250/ 548] time: 1091.8674, train_loss: -52.91344452, val_loss: -55.15269089\n",
      "Epoch: [72] [ 260/ 548] time: 1092.1509, train_loss: -52.75616837, val_loss: -52.24295044\n",
      "Epoch: [72] [ 270/ 548] time: 1092.4014, train_loss: -47.57467651, val_loss: -54.50903320\n",
      "Epoch: [72] [ 280/ 548] time: 1092.6691, train_loss: -47.43950653, val_loss: -52.51789093\n",
      "Epoch: [72] [ 290/ 548] time: 1092.9325, train_loss: -57.24394989, val_loss: -53.52411652\n",
      "Epoch: [72] [ 300/ 548] time: 1093.1800, train_loss: -55.98569870, val_loss: -54.88914871\n",
      "Epoch: [72] [ 310/ 548] time: 1093.4266, train_loss: -52.21994781, val_loss: -52.70750046\n",
      "Epoch: [72] [ 320/ 548] time: 1093.6669, train_loss: -55.71247864, val_loss: -51.39263916\n",
      "Epoch: [72] [ 330/ 548] time: 1093.9073, train_loss: -52.33020020, val_loss: -53.48515320\n",
      "Epoch: [72] [ 340/ 548] time: 1094.1416, train_loss: -56.72931671, val_loss: -54.07474136\n",
      "Epoch: [72] [ 350/ 548] time: 1094.3729, train_loss: -53.84265137, val_loss: -54.82241058\n",
      "Epoch: [72] [ 360/ 548] time: 1094.6184, train_loss: -56.67692566, val_loss: -54.84700775\n",
      "Epoch: [72] [ 370/ 548] time: 1094.8698, train_loss: -53.03121948, val_loss: -55.16009140\n",
      "Epoch: [72] [ 380/ 548] time: 1095.1098, train_loss: -55.81703568, val_loss: -53.87789536\n",
      "Epoch: [72] [ 390/ 548] time: 1095.3613, train_loss: -57.45931625, val_loss: -53.67199707\n",
      "Epoch: [72] [ 400/ 548] time: 1095.6003, train_loss: -56.97156906, val_loss: -54.60961151\n",
      "Epoch: [72] [ 410/ 548] time: 1095.8454, train_loss: -53.48019409, val_loss: -55.27029419\n",
      "Epoch: [72] [ 420/ 548] time: 1096.0929, train_loss: -55.88381958, val_loss: -55.33253860\n",
      "Epoch: [72] [ 430/ 548] time: 1096.3430, train_loss: -58.75219727, val_loss: -53.68546677\n",
      "Epoch: [72] [ 440/ 548] time: 1096.5840, train_loss: -55.87940598, val_loss: -54.91154480\n",
      "Epoch: [72] [ 450/ 548] time: 1096.8339, train_loss: -49.90444946, val_loss: -54.65599060\n",
      "Epoch: [72] [ 460/ 548] time: 1097.0804, train_loss: -57.20446014, val_loss: -54.56846237\n",
      "Epoch: [72] [ 470/ 548] time: 1097.3437, train_loss: -53.31539154, val_loss: -55.66035461\n",
      "Epoch: [72] [ 480/ 548] time: 1097.6182, train_loss: -57.11535645, val_loss: -55.05934906\n",
      "Epoch: [72] [ 490/ 548] time: 1097.8905, train_loss: -53.03025818, val_loss: -53.98610687\n",
      "Epoch: [72] [ 500/ 548] time: 1098.1627, train_loss: -58.19812012, val_loss: -55.80412292\n",
      "Epoch: [72] [ 510/ 548] time: 1098.4300, train_loss: -54.47426987, val_loss: -56.00549698\n",
      "Epoch: [72] [ 520/ 548] time: 1098.6779, train_loss: -54.90114594, val_loss: -56.44499207\n",
      "Epoch: [72] [ 530/ 548] time: 1098.9285, train_loss: -56.69686127, val_loss: -56.96144867\n",
      "Epoch: [72] [ 540/ 548] time: 1099.1760, train_loss: -57.13158798, val_loss: -56.72364044\n",
      "Saving checkpoint\n",
      "Epoch: [73] [   0/ 548] time: 1100.5511, train_loss: -55.70618439, val_loss: -56.10658646\n",
      "Epoch: [73] [  10/ 548] time: 1100.7956, train_loss: -58.16183853, val_loss: -56.43930435\n",
      "Epoch: [73] [  20/ 548] time: 1101.0446, train_loss: -55.49847794, val_loss: -55.83093262\n",
      "Epoch: [73] [  30/ 548] time: 1101.2767, train_loss: -51.99187469, val_loss: -55.75894165\n",
      "Epoch: [73] [  40/ 548] time: 1101.5439, train_loss: -54.01240921, val_loss: -55.32206726\n",
      "Epoch: [73] [  50/ 548] time: 1101.7794, train_loss: -56.89110184, val_loss: -55.90596390\n",
      "Epoch: [73] [  60/ 548] time: 1102.0161, train_loss: -55.28319931, val_loss: -56.27518463\n",
      "Epoch: [73] [  70/ 548] time: 1102.2574, train_loss: -55.46873856, val_loss: -56.19575882\n",
      "Epoch: [73] [  80/ 548] time: 1102.4869, train_loss: -58.05269623, val_loss: -56.48930740\n",
      "Epoch: [73] [  90/ 548] time: 1102.7180, train_loss: -51.33361053, val_loss: -56.33583069\n",
      "Epoch: [73] [ 100/ 548] time: 1102.9598, train_loss: -54.89287186, val_loss: -55.90607452\n",
      "Epoch: [73] [ 110/ 548] time: 1103.2017, train_loss: -43.53592682, val_loss: -56.37192535\n",
      "Epoch: [73] [ 120/ 548] time: 1103.4559, train_loss: -59.42664337, val_loss: -54.96166992\n",
      "Epoch: [73] [ 130/ 548] time: 1103.7172, train_loss: -46.95685577, val_loss: -56.39022064\n",
      "Epoch: [73] [ 140/ 548] time: 1103.9700, train_loss: -52.71934509, val_loss: -55.50954819\n",
      "Epoch: [73] [ 150/ 548] time: 1104.2435, train_loss: -57.14190674, val_loss: -54.15388489\n",
      "Epoch: [73] [ 160/ 548] time: 1104.5302, train_loss: -55.61890411, val_loss: -55.01749420\n",
      "Epoch: [73] [ 170/ 548] time: 1104.7881, train_loss: -46.95285797, val_loss: -55.90960312\n",
      "Epoch: [73] [ 180/ 548] time: 1105.0407, train_loss: -53.58917618, val_loss: -56.58535004\n",
      "Epoch: [73] [ 190/ 548] time: 1105.2902, train_loss: -52.83770752, val_loss: -57.34506607\n",
      "Epoch: [73] [ 200/ 548] time: 1105.5546, train_loss: -56.22688293, val_loss: -55.79552841\n",
      "Epoch: [73] [ 210/ 548] time: 1105.8121, train_loss: -56.97914886, val_loss: -56.12753296\n",
      "Epoch: [73] [ 220/ 548] time: 1106.0571, train_loss: -57.52336884, val_loss: -55.75336075\n",
      "Epoch: [73] [ 230/ 548] time: 1106.3107, train_loss: -59.41958618, val_loss: -57.27249527\n",
      "Epoch: [73] [ 240/ 548] time: 1106.5620, train_loss: -52.16902924, val_loss: -57.40246582\n",
      "Epoch: [73] [ 250/ 548] time: 1106.8102, train_loss: -57.40668488, val_loss: -56.10466766\n",
      "Epoch: [73] [ 260/ 548] time: 1107.0648, train_loss: -55.76671600, val_loss: -56.72166061\n",
      "Epoch: [73] [ 270/ 548] time: 1107.3207, train_loss: -52.63938522, val_loss: -54.55287933\n",
      "Epoch: [73] [ 280/ 548] time: 1107.5701, train_loss: -52.61961365, val_loss: -54.61912537\n",
      "Epoch: [73] [ 290/ 548] time: 1107.8108, train_loss: -48.76460648, val_loss: -52.52445602\n",
      "Epoch: [73] [ 300/ 548] time: 1108.0456, train_loss: -53.57835770, val_loss: -52.34260559\n",
      "Epoch: [73] [ 310/ 548] time: 1108.3228, train_loss: -50.82809448, val_loss: -51.58023834\n",
      "Epoch: [73] [ 320/ 548] time: 1108.5706, train_loss: -50.44313049, val_loss: -55.72142792\n",
      "Epoch: [73] [ 330/ 548] time: 1108.8108, train_loss: -53.16405487, val_loss: -54.92469025\n",
      "Epoch: [73] [ 340/ 548] time: 1109.0573, train_loss: -54.17399597, val_loss: -54.94651794\n",
      "Epoch: [73] [ 350/ 548] time: 1109.3093, train_loss: -58.23559570, val_loss: -55.39470673\n",
      "Epoch: [73] [ 360/ 548] time: 1109.5645, train_loss: -56.69412994, val_loss: -54.40097809\n",
      "Epoch: [73] [ 370/ 548] time: 1109.8332, train_loss: -58.16099548, val_loss: -54.64718246\n",
      "Epoch: [73] [ 380/ 548] time: 1110.1316, train_loss: -51.25623322, val_loss: -55.32840347\n",
      "Epoch: [73] [ 390/ 548] time: 1110.4449, train_loss: -52.00647736, val_loss: -56.44653320\n",
      "Epoch: [73] [ 400/ 548] time: 1110.7089, train_loss: -57.82924271, val_loss: -56.27684784\n",
      "Epoch: [73] [ 410/ 548] time: 1110.9676, train_loss: -51.43330002, val_loss: -56.01771164\n",
      "Epoch: [73] [ 420/ 548] time: 1111.2172, train_loss: -54.58980942, val_loss: -56.73424911\n",
      "Epoch: [73] [ 430/ 548] time: 1111.4660, train_loss: -54.42908478, val_loss: -56.10926819\n",
      "Epoch: [73] [ 440/ 548] time: 1111.7133, train_loss: -54.33325195, val_loss: -53.09807587\n",
      "Epoch: [73] [ 450/ 548] time: 1111.9684, train_loss: -56.40071869, val_loss: -51.59672546\n",
      "Epoch: [73] [ 460/ 548] time: 1112.2421, train_loss: -53.27180099, val_loss: -49.37647629\n",
      "Epoch: [73] [ 470/ 548] time: 1112.4877, train_loss: -48.71514893, val_loss: -54.68230820\n",
      "Epoch: [73] [ 480/ 548] time: 1112.7356, train_loss: -50.27023315, val_loss: -53.46430206\n",
      "Epoch: [73] [ 490/ 548] time: 1112.9837, train_loss: -48.59133530, val_loss: -51.59144592\n",
      "Epoch: [73] [ 500/ 548] time: 1113.2304, train_loss: -51.47962570, val_loss: -53.99478912\n",
      "Epoch: [73] [ 510/ 548] time: 1113.4801, train_loss: -50.65024567, val_loss: -54.36296082\n",
      "Epoch: [73] [ 520/ 548] time: 1113.7174, train_loss: -52.75986481, val_loss: -54.33392334\n",
      "Epoch: [73] [ 530/ 548] time: 1113.9556, train_loss: -52.51963425, val_loss: -52.67608643\n",
      "Epoch: [73] [ 540/ 548] time: 1114.1908, train_loss: -48.22803116, val_loss: -55.97245789\n",
      "Epoch: [74] [   0/ 548] time: 1114.3817, train_loss: -42.54630280, val_loss: -55.63948441\n",
      "Epoch: [74] [  10/ 548] time: 1114.6189, train_loss: -49.09533691, val_loss: -53.99036407\n",
      "Epoch: [74] [  20/ 548] time: 1114.8569, train_loss: -51.09394455, val_loss: -53.74478149\n",
      "Epoch: [74] [  30/ 548] time: 1115.0953, train_loss: -53.12113190, val_loss: -54.46448517\n",
      "Epoch: [74] [  40/ 548] time: 1115.3472, train_loss: -55.72182846, val_loss: -55.28186417\n",
      "Epoch: [74] [  50/ 548] time: 1115.6254, train_loss: -49.56639862, val_loss: -55.74611664\n",
      "Epoch: [74] [  60/ 548] time: 1115.8775, train_loss: -44.83843613, val_loss: -55.24352264\n",
      "Epoch: [74] [  70/ 548] time: 1116.1451, train_loss: -57.53303146, val_loss: -56.32155228\n",
      "Epoch: [74] [  80/ 548] time: 1116.4256, train_loss: -59.21992493, val_loss: -55.05010223\n",
      "Epoch: [74] [  90/ 548] time: 1116.7099, train_loss: -54.57431793, val_loss: -56.30026627\n",
      "Epoch: [74] [ 100/ 548] time: 1116.9739, train_loss: -49.18381500, val_loss: -56.19901657\n",
      "Epoch: [74] [ 110/ 548] time: 1117.2348, train_loss: -58.70429993, val_loss: -54.59189606\n",
      "Epoch: [74] [ 120/ 548] time: 1117.4877, train_loss: -55.80334091, val_loss: -54.27651215\n",
      "Epoch: [74] [ 130/ 548] time: 1117.7353, train_loss: -40.20510864, val_loss: -52.38460541\n",
      "Epoch: [74] [ 140/ 548] time: 1117.9780, train_loss: -50.72251129, val_loss: -55.26438522\n",
      "Epoch: [74] [ 150/ 548] time: 1118.2206, train_loss: -52.91759109, val_loss: -55.73699188\n",
      "Epoch: [74] [ 160/ 548] time: 1118.4579, train_loss: -58.44242096, val_loss: -56.17005920\n",
      "Epoch: [74] [ 170/ 548] time: 1118.7038, train_loss: -54.67299271, val_loss: -55.87057114\n",
      "Epoch: [74] [ 180/ 548] time: 1118.9337, train_loss: -57.17252350, val_loss: -56.41407013\n",
      "Epoch: [74] [ 190/ 548] time: 1119.1679, train_loss: -50.58441925, val_loss: -54.77216339\n",
      "Epoch: [74] [ 200/ 548] time: 1119.4046, train_loss: -54.48200226, val_loss: -55.89073563\n",
      "Epoch: [74] [ 210/ 548] time: 1119.6376, train_loss: -49.41917419, val_loss: -56.81405258\n",
      "Epoch: [74] [ 220/ 548] time: 1119.8791, train_loss: -57.93714523, val_loss: -57.19976044\n",
      "Epoch: [74] [ 230/ 548] time: 1120.1170, train_loss: -58.71993256, val_loss: -56.07497025\n",
      "Epoch: [74] [ 240/ 548] time: 1120.3603, train_loss: -52.22005463, val_loss: -55.67296982\n",
      "Epoch: [74] [ 250/ 548] time: 1120.6002, train_loss: -61.06164551, val_loss: -56.66293335\n",
      "Epoch: [74] [ 260/ 548] time: 1120.8384, train_loss: -56.61527252, val_loss: -56.26444626\n",
      "Epoch: [74] [ 270/ 548] time: 1121.0730, train_loss: -56.16534042, val_loss: -56.94329453\n",
      "Epoch: [74] [ 280/ 548] time: 1121.3222, train_loss: -57.34788132, val_loss: -56.57908249\n",
      "Epoch: [74] [ 290/ 548] time: 1121.5651, train_loss: -58.48209763, val_loss: -57.06074905\n",
      "Epoch: [74] [ 300/ 548] time: 1121.8122, train_loss: -51.02954865, val_loss: -56.67718887\n",
      "Epoch: [74] [ 310/ 548] time: 1122.0871, train_loss: -59.05679321, val_loss: -55.79612732\n",
      "Epoch: [74] [ 320/ 548] time: 1122.3696, train_loss: -58.18352509, val_loss: -56.08051682\n",
      "Epoch: [74] [ 330/ 548] time: 1122.6467, train_loss: -49.38826752, val_loss: -55.92515182\n",
      "Epoch: [74] [ 340/ 548] time: 1122.9351, train_loss: -52.83690643, val_loss: -55.20268250\n",
      "Epoch: [74] [ 350/ 548] time: 1123.2150, train_loss: -53.11666870, val_loss: -54.30737305\n",
      "Epoch: [74] [ 360/ 548] time: 1123.4983, train_loss: -55.91413116, val_loss: -55.23292160\n",
      "Epoch: [74] [ 370/ 548] time: 1123.7811, train_loss: -38.68488693, val_loss: -56.39745712\n",
      "Epoch: [74] [ 380/ 548] time: 1124.0876, train_loss: -54.21030045, val_loss: -55.29026794\n",
      "Epoch: [74] [ 390/ 548] time: 1124.4544, train_loss: -57.95789337, val_loss: -54.68114090\n",
      "Epoch: [74] [ 400/ 548] time: 1124.7945, train_loss: -48.00319672, val_loss: -55.64405060\n",
      "Epoch: [74] [ 410/ 548] time: 1125.1499, train_loss: -48.70208740, val_loss: -55.35357666\n",
      "Epoch: [74] [ 420/ 548] time: 1125.5177, train_loss: -54.74755859, val_loss: -49.07295609\n",
      "Epoch: [74] [ 430/ 548] time: 1125.8742, train_loss: -52.62799835, val_loss: -54.27044678\n",
      "Epoch: [74] [ 440/ 548] time: 1126.2278, train_loss: -44.68225479, val_loss: -51.09303665\n",
      "Saving checkpoint\n",
      "Epoch: [74] [ 450/ 548] time: 1127.8670, train_loss: -44.85688019, val_loss: -48.45275879\n",
      "Epoch: [74] [ 460/ 548] time: 1128.1445, train_loss: -47.45059204, val_loss: -42.19620514\n",
      "Epoch: [74] [ 470/ 548] time: 1128.4452, train_loss: -11.70396042, val_loss: 14.06146240\n",
      "Epoch: [74] [ 480/ 548] time: 1128.7164, train_loss: 11.32837677, val_loss: -16.69788742\n",
      "Epoch: [74] [ 490/ 548] time: 1128.9813, train_loss: 216.41716003, val_loss: 35.47364807\n",
      "Epoch: [74] [ 500/ 548] time: 1129.2351, train_loss: -21.12038422, val_loss: 96.73581696\n",
      "Epoch: [74] [ 510/ 548] time: 1129.4849, train_loss: 111.66051483, val_loss: -15.57102203\n",
      "Epoch: [74] [ 520/ 548] time: 1129.7372, train_loss: -38.10955048, val_loss: -31.35879135\n",
      "Epoch: [74] [ 530/ 548] time: 1129.9860, train_loss: -41.55291748, val_loss: -24.11116791\n",
      "Epoch: [74] [ 540/ 548] time: 1130.2404, train_loss: -38.11800766, val_loss: -34.23948669\n",
      "Epoch: [75] [   0/ 548] time: 1130.4629, train_loss: -22.76805496, val_loss: -43.96630859\n",
      "Epoch: [75] [  10/ 548] time: 1130.7258, train_loss: -21.57412720, val_loss: -46.45185089\n",
      "Epoch: [75] [  20/ 548] time: 1131.0003, train_loss: -35.36512375, val_loss: -34.26186752\n",
      "Epoch: [75] [  30/ 548] time: 1131.2697, train_loss: -53.63490295, val_loss: -46.05026245\n",
      "Epoch: [75] [  40/ 548] time: 1131.5572, train_loss: -43.90946960, val_loss: -48.50218964\n",
      "Epoch: [75] [  50/ 548] time: 1131.8285, train_loss: -57.23498917, val_loss: -50.43544006\n",
      "Epoch: [75] [  60/ 548] time: 1132.1669, train_loss: -22.27540207, val_loss: -50.41357422\n",
      "Epoch: [75] [  70/ 548] time: 1132.4729, train_loss: -44.49653625, val_loss: -50.03197479\n",
      "Epoch: [75] [  80/ 548] time: 1132.7398, train_loss: -25.40747833, val_loss: -51.79347229\n",
      "Epoch: [75] [  90/ 548] time: 1132.9949, train_loss: -44.04916000, val_loss: -52.81719971\n",
      "Epoch: [75] [ 100/ 548] time: 1133.2528, train_loss: -49.71588135, val_loss: -52.95967484\n",
      "Epoch: [75] [ 110/ 548] time: 1133.5008, train_loss: -49.27278137, val_loss: -53.03456497\n",
      "Epoch: [75] [ 120/ 548] time: 1133.7672, train_loss: -52.48547363, val_loss: -53.23359299\n",
      "Epoch: [75] [ 130/ 548] time: 1134.0430, train_loss: -50.11122131, val_loss: -53.28684235\n",
      "Epoch: [75] [ 140/ 548] time: 1134.3177, train_loss: -53.52923965, val_loss: -53.18791962\n",
      "Epoch: [75] [ 150/ 548] time: 1134.5784, train_loss: -51.99406815, val_loss: -54.02907944\n",
      "Epoch: [75] [ 160/ 548] time: 1134.8223, train_loss: -48.83905029, val_loss: -54.12957001\n",
      "Epoch: [75] [ 170/ 548] time: 1135.0690, train_loss: -56.81203079, val_loss: -53.86518478\n",
      "Epoch: [75] [ 180/ 548] time: 1135.3262, train_loss: -53.67455673, val_loss: -54.31602097\n",
      "Epoch: [75] [ 190/ 548] time: 1135.5671, train_loss: -56.57570267, val_loss: -53.38746643\n",
      "Epoch: [75] [ 200/ 548] time: 1135.8055, train_loss: -55.21527481, val_loss: -53.85297394\n",
      "Epoch: [75] [ 210/ 548] time: 1136.0394, train_loss: -54.31945419, val_loss: -53.66947556\n",
      "Epoch: [75] [ 220/ 548] time: 1136.2846, train_loss: -56.01175308, val_loss: -53.27606964\n",
      "Epoch: [75] [ 230/ 548] time: 1136.5313, train_loss: -45.96795654, val_loss: -54.49271393\n",
      "Epoch: [75] [ 240/ 548] time: 1136.7675, train_loss: -53.32838058, val_loss: -54.37616348\n",
      "Epoch: [75] [ 250/ 548] time: 1137.0061, train_loss: -52.62536621, val_loss: -52.90859604\n",
      "Epoch: [75] [ 260/ 548] time: 1137.2481, train_loss: -53.00119781, val_loss: -53.92450333\n",
      "Epoch: [75] [ 270/ 548] time: 1137.4900, train_loss: -55.29064560, val_loss: -54.46185684\n",
      "Epoch: [75] [ 280/ 548] time: 1137.7443, train_loss: -53.37324524, val_loss: -54.75909805\n",
      "Epoch: [75] [ 290/ 548] time: 1137.9908, train_loss: -56.39750671, val_loss: -53.57777786\n",
      "Epoch: [75] [ 300/ 548] time: 1138.2436, train_loss: -57.79999161, val_loss: -53.92099380\n",
      "Epoch: [75] [ 310/ 548] time: 1138.4989, train_loss: -49.83935928, val_loss: -54.21364594\n",
      "Epoch: [75] [ 320/ 548] time: 1138.7575, train_loss: -56.70889282, val_loss: -54.49314499\n",
      "Epoch: [75] [ 330/ 548] time: 1139.0143, train_loss: -55.60147095, val_loss: -53.84529877\n",
      "Epoch: [75] [ 340/ 548] time: 1139.2718, train_loss: -53.36052322, val_loss: -54.96167755\n",
      "Epoch: [75] [ 350/ 548] time: 1139.5245, train_loss: -55.95890045, val_loss: -54.93277740\n",
      "Epoch: [75] [ 360/ 548] time: 1139.8005, train_loss: -45.55063248, val_loss: -54.47573090\n",
      "Epoch: [75] [ 370/ 548] time: 1140.0804, train_loss: -55.09598541, val_loss: -54.47695160\n",
      "Epoch: [75] [ 380/ 548] time: 1140.3674, train_loss: -54.95537567, val_loss: -55.10802841\n",
      "Epoch: [75] [ 390/ 548] time: 1140.6469, train_loss: -50.97872925, val_loss: -54.74054337\n",
      "Epoch: [75] [ 400/ 548] time: 1140.9028, train_loss: -53.00659180, val_loss: -55.23349762\n",
      "Epoch: [75] [ 410/ 548] time: 1141.1664, train_loss: -55.72766495, val_loss: -55.42193604\n",
      "Epoch: [75] [ 420/ 548] time: 1141.4280, train_loss: -57.70740509, val_loss: -55.15803909\n",
      "Epoch: [75] [ 430/ 548] time: 1141.7015, train_loss: -57.71346283, val_loss: -55.01152420\n",
      "Epoch: [75] [ 440/ 548] time: 1141.9499, train_loss: -55.51453781, val_loss: -55.33504486\n",
      "Epoch: [75] [ 450/ 548] time: 1142.2156, train_loss: -55.76492691, val_loss: -55.68811035\n",
      "Epoch: [75] [ 460/ 548] time: 1142.4665, train_loss: -54.83004379, val_loss: -55.80612946\n",
      "Epoch: [75] [ 470/ 548] time: 1142.7153, train_loss: -51.71098328, val_loss: -54.62869644\n",
      "Epoch: [75] [ 480/ 548] time: 1142.9644, train_loss: -57.69570923, val_loss: -55.15264893\n",
      "Epoch: [75] [ 490/ 548] time: 1143.2103, train_loss: -58.28027725, val_loss: -55.20471191\n",
      "Epoch: [75] [ 500/ 548] time: 1143.4560, train_loss: -53.83221817, val_loss: -55.67525482\n",
      "Epoch: [75] [ 510/ 548] time: 1143.6952, train_loss: -55.79000854, val_loss: -55.81427765\n",
      "Epoch: [75] [ 520/ 548] time: 1143.9377, train_loss: -47.40081787, val_loss: -55.65881348\n",
      "Epoch: [75] [ 530/ 548] time: 1144.1779, train_loss: -49.25793457, val_loss: -56.36494446\n",
      "Epoch: [75] [ 540/ 548] time: 1144.4213, train_loss: -53.87512970, val_loss: -54.83002090\n",
      "Epoch: [76] [   0/ 548] time: 1144.6092, train_loss: -57.30376434, val_loss: -55.59273911\n",
      "Epoch: [76] [  10/ 548] time: 1144.8411, train_loss: -48.46186066, val_loss: -55.57048416\n",
      "Epoch: [76] [  20/ 548] time: 1145.0793, train_loss: -45.56346130, val_loss: -55.16707993\n",
      "Epoch: [76] [  30/ 548] time: 1145.3320, train_loss: -56.07393646, val_loss: -55.24040604\n",
      "Epoch: [76] [  40/ 548] time: 1145.5982, train_loss: -53.34355164, val_loss: -55.62257004\n",
      "Epoch: [76] [  50/ 548] time: 1145.8620, train_loss: -58.73169708, val_loss: -55.75270844\n",
      "Epoch: [76] [  60/ 548] time: 1146.1255, train_loss: -52.03923035, val_loss: -56.02686691\n",
      "Epoch: [76] [  70/ 548] time: 1146.4039, train_loss: -53.53139877, val_loss: -55.15348053\n",
      "Epoch: [76] [  80/ 548] time: 1146.6951, train_loss: -56.33480072, val_loss: -55.35597992\n",
      "Epoch: [76] [  90/ 548] time: 1146.9725, train_loss: -54.85416412, val_loss: -55.26023865\n",
      "Epoch: [76] [ 100/ 548] time: 1147.2651, train_loss: -53.51581955, val_loss: -55.55498505\n",
      "Epoch: [76] [ 110/ 548] time: 1147.5433, train_loss: -53.76718521, val_loss: -55.56897736\n",
      "Epoch: [76] [ 120/ 548] time: 1147.8069, train_loss: -58.42201614, val_loss: -55.63840866\n",
      "Epoch: [76] [ 130/ 548] time: 1148.0630, train_loss: -52.63757324, val_loss: -54.85514069\n",
      "Epoch: [76] [ 140/ 548] time: 1148.3434, train_loss: -55.98854828, val_loss: -55.21650696\n",
      "Epoch: [76] [ 150/ 548] time: 1148.6235, train_loss: -51.73981857, val_loss: -54.79041290\n",
      "Epoch: [76] [ 160/ 548] time: 1148.8899, train_loss: -51.28343964, val_loss: -56.00358582\n",
      "Epoch: [76] [ 170/ 548] time: 1149.1604, train_loss: -47.94982910, val_loss: -55.62821579\n",
      "Epoch: [76] [ 180/ 548] time: 1149.4163, train_loss: -54.11872101, val_loss: -55.81805038\n",
      "Epoch: [76] [ 190/ 548] time: 1149.6780, train_loss: -54.12131500, val_loss: -55.86460495\n",
      "Epoch: [76] [ 200/ 548] time: 1149.9446, train_loss: -54.52116776, val_loss: -56.11425018\n",
      "Epoch: [76] [ 210/ 548] time: 1150.1901, train_loss: -52.26916885, val_loss: -56.50517273\n",
      "Epoch: [76] [ 220/ 548] time: 1150.4376, train_loss: -54.92880630, val_loss: -55.88640976\n",
      "Epoch: [76] [ 230/ 548] time: 1150.6781, train_loss: -54.13281631, val_loss: -55.89670563\n",
      "Epoch: [76] [ 240/ 548] time: 1150.9212, train_loss: -56.76564789, val_loss: -55.94884491\n",
      "Epoch: [76] [ 250/ 548] time: 1151.1646, train_loss: -43.51705170, val_loss: -56.49470139\n",
      "Epoch: [76] [ 260/ 548] time: 1151.4142, train_loss: -55.25122833, val_loss: -55.56599426\n",
      "Epoch: [76] [ 270/ 548] time: 1151.6555, train_loss: -46.62286377, val_loss: -55.23210144\n",
      "Epoch: [76] [ 280/ 548] time: 1151.9191, train_loss: -53.90048218, val_loss: -55.83134842\n",
      "Epoch: [76] [ 290/ 548] time: 1152.1929, train_loss: -56.96625519, val_loss: -56.13351440\n",
      "Epoch: [76] [ 300/ 548] time: 1152.4756, train_loss: -55.20875931, val_loss: -56.23451614\n",
      "Epoch: [76] [ 310/ 548] time: 1152.7514, train_loss: -55.69539642, val_loss: -56.02376175\n",
      "Epoch: [76] [ 320/ 548] time: 1153.0040, train_loss: -57.21282196, val_loss: -56.20766449\n",
      "Epoch: [76] [ 330/ 548] time: 1153.2467, train_loss: -58.12378311, val_loss: -56.42888641\n",
      "Epoch: [76] [ 340/ 548] time: 1153.4898, train_loss: -55.21863556, val_loss: -56.51840973\n",
      "Epoch: [76] [ 350/ 548] time: 1153.7354, train_loss: -54.18563080, val_loss: -56.45439148\n",
      "Saving checkpoint\n",
      "Epoch: [76] [ 360/ 548] time: 1155.1170, train_loss: -55.30039978, val_loss: -55.92033005\n",
      "Epoch: [76] [ 370/ 548] time: 1155.3934, train_loss: -52.65950775, val_loss: -55.68130875\n",
      "Epoch: [76] [ 380/ 548] time: 1155.6687, train_loss: -52.15110016, val_loss: -55.13531113\n",
      "Epoch: [76] [ 390/ 548] time: 1155.9160, train_loss: -55.60961151, val_loss: -56.41999817\n",
      "Epoch: [76] [ 400/ 548] time: 1156.1915, train_loss: -55.09826279, val_loss: -56.46292877\n",
      "Epoch: [76] [ 410/ 548] time: 1156.4405, train_loss: -49.83158112, val_loss: -55.45908737\n",
      "Epoch: [76] [ 420/ 548] time: 1156.7034, train_loss: -56.47320175, val_loss: -55.09692001\n",
      "Epoch: [76] [ 430/ 548] time: 1156.9811, train_loss: -53.04499054, val_loss: -55.28273773\n",
      "Epoch: [76] [ 440/ 548] time: 1157.2647, train_loss: -59.18235779, val_loss: -55.40898514\n",
      "Epoch: [76] [ 450/ 548] time: 1157.5503, train_loss: -48.66168213, val_loss: -54.94001007\n",
      "Epoch: [76] [ 460/ 548] time: 1157.8181, train_loss: -53.46745300, val_loss: -54.53407288\n",
      "Epoch: [76] [ 470/ 548] time: 1158.1058, train_loss: -57.32246017, val_loss: -54.11813736\n",
      "Epoch: [76] [ 480/ 548] time: 1158.4194, train_loss: -46.84739304, val_loss: -55.24106979\n",
      "Epoch: [76] [ 490/ 548] time: 1158.6986, train_loss: -51.42890930, val_loss: -55.33423996\n",
      "Epoch: [76] [ 500/ 548] time: 1158.9615, train_loss: -57.72359467, val_loss: -56.19699097\n",
      "Epoch: [76] [ 510/ 548] time: 1159.2246, train_loss: -54.31015778, val_loss: -56.59076691\n",
      "Epoch: [76] [ 520/ 548] time: 1159.4892, train_loss: -54.89396667, val_loss: -55.69480133\n",
      "Epoch: [76] [ 530/ 548] time: 1159.7376, train_loss: -55.32545471, val_loss: -56.70485306\n",
      "Epoch: [76] [ 540/ 548] time: 1160.0059, train_loss: -52.58961105, val_loss: -56.31620026\n",
      "Epoch: [77] [   0/ 548] time: 1160.2262, train_loss: -52.61558533, val_loss: -55.30831909\n",
      "Epoch: [77] [  10/ 548] time: 1160.4811, train_loss: -26.70117569, val_loss: -56.95925140\n",
      "Epoch: [77] [  20/ 548] time: 1160.7474, train_loss: -56.90673065, val_loss: -56.20040894\n",
      "Epoch: [77] [  30/ 548] time: 1161.0064, train_loss: -56.79221725, val_loss: -55.54241180\n",
      "Epoch: [77] [  40/ 548] time: 1161.2488, train_loss: -50.70713806, val_loss: -55.59296036\n",
      "Epoch: [77] [  50/ 548] time: 1161.4914, train_loss: -58.54593658, val_loss: -55.39873505\n",
      "Epoch: [77] [  60/ 548] time: 1161.7581, train_loss: -55.25858307, val_loss: -55.87633896\n",
      "Epoch: [77] [  70/ 548] time: 1162.0209, train_loss: -55.02076721, val_loss: -55.86606598\n",
      "Epoch: [77] [  80/ 548] time: 1162.3053, train_loss: -49.94968414, val_loss: -56.01132965\n",
      "Epoch: [77] [  90/ 548] time: 1162.5760, train_loss: -54.79140472, val_loss: -55.85582733\n",
      "Epoch: [77] [ 100/ 548] time: 1162.8487, train_loss: -43.32407761, val_loss: -56.33872604\n",
      "Epoch: [77] [ 110/ 548] time: 1163.1724, train_loss: -58.21669006, val_loss: -55.78530502\n",
      "Epoch: [77] [ 120/ 548] time: 1163.5471, train_loss: -56.26105499, val_loss: -56.37649155\n",
      "Epoch: [77] [ 130/ 548] time: 1163.9379, train_loss: -54.17922974, val_loss: -56.45319748\n",
      "Epoch: [77] [ 140/ 548] time: 1164.3129, train_loss: -51.09298706, val_loss: -56.90756226\n",
      "Epoch: [77] [ 150/ 548] time: 1164.6775, train_loss: -46.68422699, val_loss: -56.76433563\n",
      "Epoch: [77] [ 160/ 548] time: 1165.0338, train_loss: -58.80100632, val_loss: -55.86910629\n",
      "Epoch: [77] [ 170/ 548] time: 1165.4033, train_loss: -57.01807022, val_loss: -56.60437393\n",
      "Epoch: [77] [ 180/ 548] time: 1165.7596, train_loss: -54.71899796, val_loss: -56.38935089\n",
      "Epoch: [77] [ 190/ 548] time: 1166.0932, train_loss: -54.29948425, val_loss: -55.42436218\n",
      "Epoch: [77] [ 200/ 548] time: 1166.4229, train_loss: -49.13855743, val_loss: -56.04016495\n",
      "Epoch: [77] [ 210/ 548] time: 1166.7614, train_loss: -50.92852402, val_loss: -56.92480850\n",
      "Epoch: [77] [ 220/ 548] time: 1167.0969, train_loss: -58.87116241, val_loss: -56.44939423\n",
      "Epoch: [77] [ 230/ 548] time: 1167.4207, train_loss: -55.85892487, val_loss: -57.09377289\n",
      "Epoch: [77] [ 240/ 548] time: 1167.6724, train_loss: -58.03553391, val_loss: -57.10446548\n",
      "Epoch: [77] [ 250/ 548] time: 1167.9223, train_loss: -56.62183380, val_loss: -57.49021530\n",
      "Epoch: [77] [ 260/ 548] time: 1168.1719, train_loss: -58.63836670, val_loss: -57.26565552\n",
      "Epoch: [77] [ 270/ 548] time: 1168.4218, train_loss: -56.38953018, val_loss: -57.52912903\n",
      "Epoch: [77] [ 280/ 548] time: 1168.6614, train_loss: -54.65202713, val_loss: -56.54565048\n",
      "Epoch: [77] [ 290/ 548] time: 1168.8976, train_loss: -54.00788116, val_loss: -56.92001724\n",
      "Epoch: [77] [ 300/ 548] time: 1169.1390, train_loss: -53.18148804, val_loss: -56.45666122\n",
      "Epoch: [77] [ 310/ 548] time: 1169.3803, train_loss: -56.20870972, val_loss: -56.35317993\n",
      "Epoch: [77] [ 320/ 548] time: 1169.6178, train_loss: -59.78623199, val_loss: -56.31468201\n",
      "Epoch: [77] [ 330/ 548] time: 1169.8760, train_loss: -36.69901276, val_loss: -56.68227005\n",
      "Epoch: [77] [ 340/ 548] time: 1170.1263, train_loss: -45.45648193, val_loss: -55.81675720\n",
      "Epoch: [77] [ 350/ 548] time: 1170.3788, train_loss: -56.71955872, val_loss: -54.90540695\n",
      "Epoch: [77] [ 360/ 548] time: 1170.6539, train_loss: -55.18750381, val_loss: -55.45592499\n",
      "Epoch: [77] [ 370/ 548] time: 1170.9459, train_loss: -57.40498352, val_loss: -54.09154892\n",
      "Epoch: [77] [ 380/ 548] time: 1171.2212, train_loss: -55.65776825, val_loss: -55.56119919\n",
      "Epoch: [77] [ 390/ 548] time: 1171.4994, train_loss: -55.62486267, val_loss: -55.54523087\n",
      "Epoch: [77] [ 400/ 548] time: 1171.7825, train_loss: -54.92506790, val_loss: -55.92220306\n",
      "Epoch: [77] [ 410/ 548] time: 1172.0395, train_loss: -59.49386215, val_loss: -55.13166809\n",
      "Epoch: [77] [ 420/ 548] time: 1172.3375, train_loss: -54.19900131, val_loss: -55.80482864\n",
      "Epoch: [77] [ 430/ 548] time: 1172.5891, train_loss: -55.60445023, val_loss: -55.89884949\n",
      "Epoch: [77] [ 440/ 548] time: 1172.8289, train_loss: -53.12516022, val_loss: -55.82790756\n",
      "Epoch: [77] [ 450/ 548] time: 1173.0896, train_loss: -54.50874329, val_loss: -55.97534561\n",
      "Epoch: [77] [ 460/ 548] time: 1173.3380, train_loss: -56.80165100, val_loss: -56.89555359\n",
      "Epoch: [77] [ 470/ 548] time: 1173.5718, train_loss: -55.87041855, val_loss: -56.73978043\n",
      "Epoch: [77] [ 480/ 548] time: 1173.8063, train_loss: -57.80892181, val_loss: -55.95471191\n",
      "Epoch: [77] [ 490/ 548] time: 1174.0436, train_loss: -56.74551773, val_loss: -56.11223602\n",
      "Epoch: [77] [ 500/ 548] time: 1174.2818, train_loss: -58.70848465, val_loss: -56.31097412\n",
      "Epoch: [77] [ 510/ 548] time: 1174.5266, train_loss: -57.16690826, val_loss: -57.38953781\n",
      "Epoch: [77] [ 520/ 548] time: 1174.7831, train_loss: -52.13901520, val_loss: -56.35689545\n",
      "Epoch: [77] [ 530/ 548] time: 1175.0315, train_loss: -54.63192368, val_loss: -57.21728516\n",
      "Epoch: [77] [ 540/ 548] time: 1175.2757, train_loss: -57.96247864, val_loss: -56.61287308\n",
      "Epoch: [78] [   0/ 548] time: 1175.5109, train_loss: -56.40198517, val_loss: -56.67922211\n",
      "Epoch: [78] [  10/ 548] time: 1175.7564, train_loss: -52.75890732, val_loss: -55.95723724\n",
      "Epoch: [78] [  20/ 548] time: 1176.0097, train_loss: -56.69202042, val_loss: -56.55607605\n",
      "Epoch: [78] [  30/ 548] time: 1176.2831, train_loss: -57.26653671, val_loss: -56.20875549\n",
      "Epoch: [78] [  40/ 548] time: 1176.5439, train_loss: -56.57170486, val_loss: -56.95590973\n",
      "Epoch: [78] [  50/ 548] time: 1176.8051, train_loss: -55.66202927, val_loss: -57.22228622\n",
      "Epoch: [78] [  60/ 548] time: 1177.0963, train_loss: -52.54203033, val_loss: -56.63765717\n",
      "Epoch: [78] [  70/ 548] time: 1177.3701, train_loss: -52.51536560, val_loss: -57.05706024\n",
      "Epoch: [78] [  80/ 548] time: 1177.6600, train_loss: -54.79675674, val_loss: -56.83700562\n",
      "Epoch: [78] [  90/ 548] time: 1177.9410, train_loss: -52.54581833, val_loss: -55.80130005\n",
      "Epoch: [78] [ 100/ 548] time: 1178.1903, train_loss: -57.08107758, val_loss: -56.33048248\n",
      "Epoch: [78] [ 110/ 548] time: 1178.4400, train_loss: -57.11608505, val_loss: -56.74245834\n",
      "Epoch: [78] [ 120/ 548] time: 1178.6866, train_loss: -55.93403625, val_loss: -56.55770493\n",
      "Epoch: [78] [ 130/ 548] time: 1178.9447, train_loss: -52.81080246, val_loss: -54.99671936\n",
      "Epoch: [78] [ 140/ 548] time: 1179.1989, train_loss: -55.34178925, val_loss: -54.10787201\n",
      "Epoch: [78] [ 150/ 548] time: 1179.4433, train_loss: -53.99853516, val_loss: -54.54195404\n",
      "Epoch: [78] [ 160/ 548] time: 1179.6892, train_loss: -56.96843719, val_loss: -48.27539825\n",
      "Epoch: [78] [ 170/ 548] time: 1179.9388, train_loss: -48.16779327, val_loss: -53.71788025\n",
      "Epoch: [78] [ 180/ 548] time: 1180.1839, train_loss: -53.24145889, val_loss: -54.56514359\n",
      "Epoch: [78] [ 190/ 548] time: 1180.4256, train_loss: -54.59134674, val_loss: -55.59076691\n",
      "Epoch: [78] [ 200/ 548] time: 1180.6722, train_loss: -50.90265656, val_loss: -56.01825714\n",
      "Epoch: [78] [ 210/ 548] time: 1180.9083, train_loss: -56.52348709, val_loss: -56.21846008\n",
      "Epoch: [78] [ 220/ 548] time: 1181.1511, train_loss: -55.90251541, val_loss: -56.06015015\n",
      "Epoch: [78] [ 230/ 548] time: 1181.3967, train_loss: -48.90219116, val_loss: -56.18032837\n",
      "Epoch: [78] [ 240/ 548] time: 1181.6359, train_loss: -55.48961258, val_loss: -55.59645462\n",
      "Epoch: [78] [ 250/ 548] time: 1181.8685, train_loss: -55.02158737, val_loss: -56.60434723\n",
      "Saving checkpoint\n",
      "Epoch: [78] [ 260/ 548] time: 1183.1769, train_loss: -56.47472382, val_loss: -56.91389465\n",
      "Epoch: [78] [ 270/ 548] time: 1183.4635, train_loss: -55.29895782, val_loss: -56.78040314\n",
      "Epoch: [78] [ 280/ 548] time: 1183.7806, train_loss: -56.63397980, val_loss: -57.12912750\n",
      "Epoch: [78] [ 290/ 548] time: 1184.0414, train_loss: -57.71990204, val_loss: -55.71307755\n",
      "Epoch: [78] [ 300/ 548] time: 1184.3073, train_loss: -56.26784897, val_loss: -56.86234283\n",
      "Epoch: [78] [ 310/ 548] time: 1184.5758, train_loss: -59.08049393, val_loss: -56.05334091\n",
      "Epoch: [78] [ 320/ 548] time: 1184.8202, train_loss: -53.99457932, val_loss: -56.22218704\n",
      "Epoch: [78] [ 330/ 548] time: 1185.0720, train_loss: -59.28196716, val_loss: -55.00876236\n",
      "Epoch: [78] [ 340/ 548] time: 1185.3218, train_loss: -56.81126404, val_loss: -56.15518951\n",
      "Epoch: [78] [ 350/ 548] time: 1185.5785, train_loss: -50.52944565, val_loss: -54.74205780\n",
      "Epoch: [78] [ 360/ 548] time: 1185.8286, train_loss: -48.85874939, val_loss: -54.75775146\n",
      "Epoch: [78] [ 370/ 548] time: 1186.0697, train_loss: -51.43912506, val_loss: -55.59053802\n",
      "Epoch: [78] [ 380/ 548] time: 1186.3200, train_loss: -53.95604706, val_loss: -56.81296539\n",
      "Epoch: [78] [ 390/ 548] time: 1186.5924, train_loss: -55.79932022, val_loss: -56.18774033\n",
      "Epoch: [78] [ 400/ 548] time: 1186.8406, train_loss: -49.02254105, val_loss: -55.67843628\n",
      "Epoch: [78] [ 410/ 548] time: 1187.0972, train_loss: -47.66823578, val_loss: -55.40335846\n",
      "Epoch: [78] [ 420/ 548] time: 1187.3482, train_loss: -51.63373566, val_loss: -54.38684464\n",
      "Epoch: [78] [ 430/ 548] time: 1187.5939, train_loss: -40.49670410, val_loss: -51.90169525\n",
      "Epoch: [78] [ 440/ 548] time: 1187.8450, train_loss: -52.72091675, val_loss: -53.45735931\n",
      "Epoch: [78] [ 450/ 548] time: 1188.0886, train_loss: -42.47014999, val_loss: -52.14093781\n",
      "Epoch: [78] [ 460/ 548] time: 1188.3205, train_loss: -46.98495865, val_loss: -48.04259491\n",
      "Epoch: [78] [ 470/ 548] time: 1188.5539, train_loss: -51.75544739, val_loss: -53.11226273\n",
      "Epoch: [78] [ 480/ 548] time: 1188.7930, train_loss: -53.16933823, val_loss: -55.33716202\n",
      "Epoch: [78] [ 490/ 548] time: 1189.0280, train_loss: -51.56819153, val_loss: -55.40351486\n",
      "Epoch: [78] [ 500/ 548] time: 1189.2921, train_loss: -55.39305496, val_loss: -54.00741959\n",
      "Epoch: [78] [ 510/ 548] time: 1189.6055, train_loss: -55.75117111, val_loss: -55.71207428\n",
      "Epoch: [78] [ 520/ 548] time: 1189.8946, train_loss: -56.03199387, val_loss: -53.57010651\n",
      "Epoch: [78] [ 530/ 548] time: 1190.1954, train_loss: -50.67358398, val_loss: -55.20790100\n",
      "Epoch: [78] [ 540/ 548] time: 1190.4504, train_loss: -56.70549774, val_loss: -55.99431610\n",
      "Epoch: [79] [   0/ 548] time: 1190.6507, train_loss: -55.43656540, val_loss: -55.36690521\n",
      "Epoch: [79] [  10/ 548] time: 1190.8987, train_loss: -57.03413391, val_loss: -55.51383972\n",
      "Epoch: [79] [  20/ 548] time: 1191.1473, train_loss: -56.81723022, val_loss: -56.41590881\n",
      "Epoch: [79] [  30/ 548] time: 1191.4042, train_loss: -54.77616501, val_loss: -56.44013596\n",
      "Epoch: [79] [  40/ 548] time: 1191.6796, train_loss: -58.02596283, val_loss: -56.29232025\n",
      "Epoch: [79] [  50/ 548] time: 1191.9410, train_loss: -49.71655273, val_loss: -56.62734604\n",
      "Epoch: [79] [  60/ 548] time: 1192.1949, train_loss: -52.71747208, val_loss: -56.54419327\n",
      "Epoch: [79] [  70/ 548] time: 1192.4551, train_loss: -55.05997086, val_loss: -56.63528442\n",
      "Epoch: [79] [  80/ 548] time: 1192.7126, train_loss: -52.12304306, val_loss: -56.47656250\n",
      "Epoch: [79] [  90/ 548] time: 1192.9694, train_loss: -47.71446991, val_loss: -56.42295456\n",
      "Epoch: [79] [ 100/ 548] time: 1193.2389, train_loss: -53.92404938, val_loss: -57.00717163\n",
      "Epoch: [79] [ 110/ 548] time: 1193.5103, train_loss: -54.54029083, val_loss: -55.20978165\n",
      "Epoch: [79] [ 120/ 548] time: 1193.7528, train_loss: -53.30385590, val_loss: -56.60504532\n",
      "Epoch: [79] [ 130/ 548] time: 1193.9950, train_loss: -54.36194992, val_loss: -56.78507614\n",
      "Epoch: [79] [ 140/ 548] time: 1194.2393, train_loss: -49.45018387, val_loss: -56.84231186\n",
      "Epoch: [79] [ 150/ 548] time: 1194.4837, train_loss: -56.10249329, val_loss: -57.15273285\n",
      "Epoch: [79] [ 160/ 548] time: 1194.7275, train_loss: -55.66761017, val_loss: -55.70748138\n",
      "Epoch: [79] [ 170/ 548] time: 1194.9875, train_loss: -56.82314682, val_loss: -55.76601410\n",
      "Epoch: [79] [ 180/ 548] time: 1195.2579, train_loss: -52.04418945, val_loss: -57.08881378\n",
      "Epoch: [79] [ 190/ 548] time: 1195.5868, train_loss: -54.40761948, val_loss: -56.38693237\n",
      "Epoch: [79] [ 200/ 548] time: 1195.8874, train_loss: -53.42634964, val_loss: -56.61611557\n",
      "Epoch: [79] [ 210/ 548] time: 1196.1699, train_loss: -59.02274323, val_loss: -57.03307343\n",
      "Epoch: [79] [ 220/ 548] time: 1196.5426, train_loss: -60.14208603, val_loss: -56.83798981\n",
      "Epoch: [79] [ 230/ 548] time: 1196.9057, train_loss: -59.58164215, val_loss: -56.76277161\n",
      "Epoch: [79] [ 240/ 548] time: 1197.2427, train_loss: -57.87407303, val_loss: -57.50846863\n",
      "Epoch: [79] [ 250/ 548] time: 1197.6028, train_loss: -55.78333664, val_loss: -56.66676331\n",
      "Epoch: [79] [ 260/ 548] time: 1197.9790, train_loss: -56.56113434, val_loss: -56.74388504\n",
      "Epoch: [79] [ 270/ 548] time: 1198.3124, train_loss: -57.78524780, val_loss: -56.99442291\n",
      "Epoch: [79] [ 280/ 548] time: 1198.6474, train_loss: -52.91872406, val_loss: -56.75590134\n",
      "Epoch: [79] [ 290/ 548] time: 1198.9735, train_loss: -54.18815613, val_loss: -57.37155533\n",
      "Epoch: [79] [ 300/ 548] time: 1199.3171, train_loss: -57.84370041, val_loss: -56.84426880\n",
      "Epoch: [79] [ 310/ 548] time: 1199.6550, train_loss: -59.82271957, val_loss: -56.94488907\n",
      "Epoch: [79] [ 320/ 548] time: 1199.9927, train_loss: -58.25109482, val_loss: -56.77622223\n",
      "Epoch: [79] [ 330/ 548] time: 1200.2794, train_loss: -53.43339157, val_loss: -55.05024719\n",
      "Epoch: [79] [ 340/ 548] time: 1200.5375, train_loss: -42.37010193, val_loss: -54.06701660\n",
      "Epoch: [79] [ 350/ 548] time: 1200.7805, train_loss: -52.19561768, val_loss: -54.28681183\n",
      "Epoch: [79] [ 360/ 548] time: 1201.0206, train_loss: -43.40266037, val_loss: -53.90155792\n",
      "Epoch: [79] [ 370/ 548] time: 1201.2538, train_loss: -49.46325302, val_loss: -51.73416901\n",
      "Epoch: [79] [ 380/ 548] time: 1201.5021, train_loss: -53.91651535, val_loss: -55.91836548\n",
      "Epoch: [79] [ 390/ 548] time: 1201.7360, train_loss: -40.43985748, val_loss: -53.64056778\n",
      "Epoch: [79] [ 400/ 548] time: 1201.9986, train_loss: -38.61779022, val_loss: -45.77914429\n",
      "Epoch: [79] [ 410/ 548] time: 1202.2975, train_loss: -47.74973297, val_loss: -50.97930527\n",
      "Epoch: [79] [ 420/ 548] time: 1202.5677, train_loss: -40.14811707, val_loss: -49.04122543\n",
      "Epoch: [79] [ 430/ 548] time: 1202.8285, train_loss: -50.45261002, val_loss: -53.09100342\n",
      "Epoch: [79] [ 440/ 548] time: 1203.0638, train_loss: -48.55300522, val_loss: -52.12316132\n",
      "Epoch: [79] [ 450/ 548] time: 1203.3055, train_loss: -54.50638199, val_loss: -54.30197906\n",
      "Epoch: [79] [ 460/ 548] time: 1203.5456, train_loss: -55.83867264, val_loss: -54.43060684\n",
      "Epoch: [79] [ 470/ 548] time: 1203.7865, train_loss: -52.21772766, val_loss: -52.92920685\n",
      "Epoch: [79] [ 480/ 548] time: 1204.0313, train_loss: -54.47466278, val_loss: -54.70189667\n",
      "Epoch: [79] [ 490/ 548] time: 1204.2726, train_loss: -53.11745834, val_loss: -53.73021698\n",
      "Epoch: [79] [ 500/ 548] time: 1204.5090, train_loss: -48.13646698, val_loss: -53.23557663\n",
      "Epoch: [79] [ 510/ 548] time: 1204.7488, train_loss: -51.48290253, val_loss: -53.40560913\n",
      "Epoch: [79] [ 520/ 548] time: 1204.9871, train_loss: -53.18693542, val_loss: -54.48458862\n",
      "Epoch: [79] [ 530/ 548] time: 1205.2357, train_loss: -56.12354660, val_loss: -55.23017120\n",
      "Epoch: [79] [ 540/ 548] time: 1205.5334, train_loss: -54.43748474, val_loss: -54.75137329\n",
      "Epoch: [80] [   0/ 548] time: 1205.7400, train_loss: -51.98120880, val_loss: -55.47303772\n",
      "Epoch: [80] [  10/ 548] time: 1205.9886, train_loss: -51.70613480, val_loss: -55.03706741\n",
      "Epoch: [80] [  20/ 548] time: 1206.2281, train_loss: -59.47227478, val_loss: -56.49008942\n",
      "Epoch: [80] [  30/ 548] time: 1206.4712, train_loss: -52.32684708, val_loss: -56.88695145\n",
      "Epoch: [80] [  40/ 548] time: 1206.7132, train_loss: -49.85965729, val_loss: -57.14143372\n",
      "Epoch: [80] [  50/ 548] time: 1206.9470, train_loss: -54.02966309, val_loss: -56.10025787\n",
      "Epoch: [80] [  60/ 548] time: 1207.1857, train_loss: -42.83082199, val_loss: -56.63780594\n",
      "Epoch: [80] [  70/ 548] time: 1207.4628, train_loss: -51.94429779, val_loss: -56.29187775\n",
      "Epoch: [80] [  80/ 548] time: 1207.8018, train_loss: -54.62084198, val_loss: -55.85511398\n",
      "Epoch: [80] [  90/ 548] time: 1208.1834, train_loss: -55.31445312, val_loss: -55.50591660\n",
      "Epoch: [80] [ 100/ 548] time: 1208.5285, train_loss: -56.50893402, val_loss: -55.90077972\n",
      "Epoch: [80] [ 110/ 548] time: 1208.9032, train_loss: -52.99748993, val_loss: -55.78589249\n",
      "Epoch: [80] [ 120/ 548] time: 1209.2733, train_loss: -56.71685410, val_loss: -56.01488876\n",
      "Epoch: [80] [ 130/ 548] time: 1209.6415, train_loss: -53.77180099, val_loss: -56.43526840\n",
      "Epoch: [80] [ 140/ 548] time: 1210.0173, train_loss: -57.90300751, val_loss: -55.33850098\n",
      "Epoch: [80] [ 150/ 548] time: 1210.3427, train_loss: -52.97618103, val_loss: -55.89825058\n",
      "Epoch: [80] [ 160/ 548] time: 1210.6795, train_loss: -39.58020020, val_loss: -54.29475021\n",
      "Saving checkpoint\n",
      "Epoch: [80] [ 170/ 548] time: 1212.1591, train_loss: -51.51172638, val_loss: -56.35138321\n",
      "Epoch: [80] [ 180/ 548] time: 1212.4629, train_loss: -50.45875549, val_loss: -55.92284775\n",
      "Epoch: [80] [ 190/ 548] time: 1212.7325, train_loss: -48.65530396, val_loss: -54.39060211\n",
      "Epoch: [80] [ 200/ 548] time: 1212.9812, train_loss: -58.44534683, val_loss: -55.35293579\n",
      "Epoch: [80] [ 210/ 548] time: 1213.2315, train_loss: -52.65035248, val_loss: -55.16621780\n",
      "Epoch: [80] [ 220/ 548] time: 1213.5044, train_loss: -53.12390137, val_loss: -51.90141296\n",
      "Epoch: [80] [ 230/ 548] time: 1213.7740, train_loss: -41.38872910, val_loss: -49.47443390\n",
      "Epoch: [80] [ 240/ 548] time: 1214.0438, train_loss: -55.00153351, val_loss: -54.14828110\n",
      "Epoch: [80] [ 250/ 548] time: 1214.3222, train_loss: -50.35541534, val_loss: -53.88764191\n",
      "Epoch: [80] [ 260/ 548] time: 1214.5991, train_loss: -52.61017609, val_loss: -55.53059387\n",
      "Epoch: [80] [ 270/ 548] time: 1214.8827, train_loss: -58.81748199, val_loss: -54.49297333\n",
      "Epoch: [80] [ 280/ 548] time: 1215.2019, train_loss: -50.87712860, val_loss: -56.26891708\n",
      "Epoch: [80] [ 290/ 548] time: 1215.5105, train_loss: -50.47568893, val_loss: -56.19183350\n",
      "Epoch: [80] [ 300/ 548] time: 1215.7867, train_loss: -53.78837585, val_loss: -55.35992432\n",
      "Epoch: [80] [ 310/ 548] time: 1216.0683, train_loss: -55.19262314, val_loss: -56.76543808\n",
      "Epoch: [80] [ 320/ 548] time: 1216.3447, train_loss: -57.86969757, val_loss: -56.99369431\n",
      "Epoch: [80] [ 330/ 548] time: 1216.6183, train_loss: -52.77806473, val_loss: -56.00689316\n",
      "Epoch: [80] [ 340/ 548] time: 1216.8983, train_loss: -51.59545135, val_loss: -56.21128845\n",
      "Epoch: [80] [ 350/ 548] time: 1217.1748, train_loss: -55.06429672, val_loss: -56.63118362\n",
      "Epoch: [80] [ 360/ 548] time: 1217.4495, train_loss: -59.31330872, val_loss: -56.44298553\n",
      "Epoch: [80] [ 370/ 548] time: 1217.7211, train_loss: -55.92498779, val_loss: -56.12499619\n",
      "Epoch: [80] [ 380/ 548] time: 1217.9798, train_loss: -56.85887909, val_loss: -56.45339203\n",
      "Epoch: [80] [ 390/ 548] time: 1218.2364, train_loss: -42.52222061, val_loss: -56.15052032\n",
      "Epoch: [80] [ 400/ 548] time: 1218.5045, train_loss: -53.71786499, val_loss: -56.16131210\n",
      "Epoch: [80] [ 410/ 548] time: 1218.7652, train_loss: -42.61141205, val_loss: -55.68954849\n",
      "Epoch: [80] [ 420/ 548] time: 1219.0221, train_loss: -50.95683289, val_loss: -56.27324677\n",
      "Epoch: [80] [ 430/ 548] time: 1219.2797, train_loss: -54.68423462, val_loss: -56.87913895\n",
      "Epoch: [80] [ 440/ 548] time: 1219.5271, train_loss: -56.92857742, val_loss: -56.59938049\n",
      "Epoch: [80] [ 450/ 548] time: 1219.7793, train_loss: -48.31349945, val_loss: -57.02579117\n",
      "Epoch: [80] [ 460/ 548] time: 1220.0323, train_loss: -54.93034363, val_loss: -55.33992767\n",
      "Epoch: [80] [ 470/ 548] time: 1220.2771, train_loss: -59.65140915, val_loss: -54.89130020\n",
      "Epoch: [80] [ 480/ 548] time: 1220.5260, train_loss: -56.73339844, val_loss: -55.97614288\n",
      "Epoch: [80] [ 490/ 548] time: 1220.8057, train_loss: -54.26219940, val_loss: -55.84952164\n",
      "Epoch: [80] [ 500/ 548] time: 1221.0756, train_loss: -56.46352386, val_loss: -55.40624237\n",
      "Epoch: [80] [ 510/ 548] time: 1221.3603, train_loss: -53.77706146, val_loss: -56.46036530\n",
      "Epoch: [80] [ 520/ 548] time: 1221.6543, train_loss: -53.98725891, val_loss: -54.70335388\n",
      "Epoch: [80] [ 530/ 548] time: 1221.9342, train_loss: -54.98653412, val_loss: -56.02743912\n",
      "Epoch: [80] [ 540/ 548] time: 1222.2329, train_loss: -55.15522003, val_loss: -55.98535538\n",
      "Epoch: [81] [   0/ 548] time: 1222.4535, train_loss: -57.75816345, val_loss: -56.24518967\n",
      "Epoch: [81] [  10/ 548] time: 1222.7242, train_loss: -57.31969070, val_loss: -56.33150482\n",
      "Epoch: [81] [  20/ 548] time: 1222.9872, train_loss: -54.87840271, val_loss: -56.65804291\n",
      "Epoch: [81] [  30/ 548] time: 1223.2382, train_loss: -55.48078156, val_loss: -55.69496536\n",
      "Epoch: [81] [  40/ 548] time: 1223.4842, train_loss: -43.95568848, val_loss: -55.63136292\n",
      "Epoch: [81] [  50/ 548] time: 1223.7274, train_loss: -29.05008316, val_loss: -55.38536072\n",
      "Epoch: [81] [  60/ 548] time: 1223.9699, train_loss: -48.40284729, val_loss: -53.44691086\n",
      "Epoch: [81] [  70/ 548] time: 1224.2270, train_loss: -53.50107574, val_loss: -54.03833389\n",
      "Epoch: [81] [  80/ 548] time: 1224.4672, train_loss: -47.47253418, val_loss: -55.38898468\n",
      "Epoch: [81] [  90/ 548] time: 1224.7041, train_loss: -57.08124924, val_loss: -55.93742371\n",
      "Epoch: [81] [ 100/ 548] time: 1224.9376, train_loss: -53.59795380, val_loss: -55.90984726\n",
      "Epoch: [81] [ 110/ 548] time: 1225.1799, train_loss: -50.46219635, val_loss: -56.67424774\n",
      "Epoch: [81] [ 120/ 548] time: 1225.4260, train_loss: -46.56223679, val_loss: -56.46689606\n",
      "Epoch: [81] [ 130/ 548] time: 1225.6881, train_loss: -57.45970154, val_loss: -55.97712326\n",
      "Epoch: [81] [ 140/ 548] time: 1225.9566, train_loss: -56.30177689, val_loss: -55.33488083\n",
      "Epoch: [81] [ 150/ 548] time: 1226.2284, train_loss: -59.83788300, val_loss: -56.59870529\n",
      "Epoch: [81] [ 160/ 548] time: 1226.4956, train_loss: -48.66881943, val_loss: -56.23719788\n",
      "Epoch: [81] [ 170/ 548] time: 1226.7896, train_loss: -52.59888458, val_loss: -52.01057434\n",
      "Epoch: [81] [ 180/ 548] time: 1227.1019, train_loss: -48.27106857, val_loss: -53.84570312\n",
      "Epoch: [81] [ 190/ 548] time: 1227.4099, train_loss: -52.38602448, val_loss: -53.20957184\n",
      "Epoch: [81] [ 200/ 548] time: 1227.7191, train_loss: -39.27950287, val_loss: -53.59695435\n",
      "Epoch: [81] [ 210/ 548] time: 1228.0168, train_loss: -56.30539703, val_loss: -53.06541824\n",
      "Epoch: [81] [ 220/ 548] time: 1228.2815, train_loss: -53.15266800, val_loss: -52.05597305\n",
      "Epoch: [81] [ 230/ 548] time: 1228.5431, train_loss: -58.59687805, val_loss: -55.34052277\n",
      "Epoch: [81] [ 240/ 548] time: 1228.7914, train_loss: -42.11443329, val_loss: -53.48832321\n",
      "Epoch: [81] [ 250/ 548] time: 1229.0570, train_loss: -46.74848175, val_loss: -52.61787033\n",
      "Epoch: [81] [ 260/ 548] time: 1229.3178, train_loss: -55.74763107, val_loss: -53.12638855\n",
      "Epoch: [81] [ 270/ 548] time: 1229.5886, train_loss: -49.86531830, val_loss: -54.36167526\n",
      "Epoch: [81] [ 280/ 548] time: 1229.8463, train_loss: -54.50308228, val_loss: -54.38229752\n",
      "Epoch: [81] [ 290/ 548] time: 1230.1037, train_loss: -49.90030289, val_loss: -55.11015701\n",
      "Epoch: [81] [ 300/ 548] time: 1230.3681, train_loss: -54.28721237, val_loss: -56.11711884\n",
      "Epoch: [81] [ 310/ 548] time: 1230.6565, train_loss: -52.23453140, val_loss: -56.75790787\n",
      "Epoch: [81] [ 320/ 548] time: 1230.9251, train_loss: -55.62883759, val_loss: -56.29266357\n",
      "Epoch: [81] [ 330/ 548] time: 1231.2073, train_loss: -48.77791595, val_loss: -54.38462067\n",
      "Epoch: [81] [ 340/ 548] time: 1231.4956, train_loss: -56.36029816, val_loss: -50.58912659\n",
      "Epoch: [81] [ 350/ 548] time: 1231.7875, train_loss: -55.49957275, val_loss: -52.67169571\n",
      "Epoch: [81] [ 360/ 548] time: 1232.0808, train_loss: -57.22581863, val_loss: -53.91381073\n",
      "Epoch: [81] [ 370/ 548] time: 1232.4140, train_loss: -58.05273819, val_loss: -52.60884857\n",
      "Epoch: [81] [ 380/ 548] time: 1232.7068, train_loss: -56.17619705, val_loss: -53.93690491\n",
      "Epoch: [81] [ 390/ 548] time: 1233.0167, train_loss: -56.10257339, val_loss: -54.15243530\n",
      "Epoch: [81] [ 400/ 548] time: 1233.3359, train_loss: -55.03680420, val_loss: -53.30976105\n",
      "Epoch: [81] [ 410/ 548] time: 1233.6516, train_loss: -52.73637009, val_loss: -54.75164413\n",
      "Epoch: [81] [ 420/ 548] time: 1233.9647, train_loss: -56.14968109, val_loss: -55.18055344\n",
      "Epoch: [81] [ 430/ 548] time: 1234.2710, train_loss: -56.93565369, val_loss: -52.06210327\n",
      "Epoch: [81] [ 440/ 548] time: 1234.5557, train_loss: -52.00517273, val_loss: -54.16928864\n",
      "Epoch: [81] [ 450/ 548] time: 1234.8293, train_loss: -59.66283035, val_loss: -55.53623199\n",
      "Epoch: [81] [ 460/ 548] time: 1235.1180, train_loss: -56.87764359, val_loss: -56.36142731\n",
      "Epoch: [81] [ 470/ 548] time: 1235.4584, train_loss: -55.62381744, val_loss: -55.76435471\n",
      "Epoch: [81] [ 480/ 548] time: 1235.8061, train_loss: -55.09012604, val_loss: -56.70594788\n",
      "Epoch: [81] [ 490/ 548] time: 1236.1571, train_loss: -58.11051941, val_loss: -56.70042419\n",
      "Epoch: [81] [ 500/ 548] time: 1236.4757, train_loss: -56.61095047, val_loss: -56.75773239\n",
      "Epoch: [81] [ 510/ 548] time: 1236.8199, train_loss: -52.00307846, val_loss: -56.48590851\n",
      "Epoch: [81] [ 520/ 548] time: 1237.1629, train_loss: -58.31079865, val_loss: -55.75711060\n",
      "Epoch: [81] [ 530/ 548] time: 1237.5053, train_loss: -52.32801819, val_loss: -56.24667740\n",
      "Epoch: [81] [ 540/ 548] time: 1237.8376, train_loss: -56.65994644, val_loss: -56.20745850\n",
      "Epoch: [82] [   0/ 548] time: 1238.1017, train_loss: -50.11779785, val_loss: -57.14767838\n",
      "Epoch: [82] [  10/ 548] time: 1238.4343, train_loss: -54.47200775, val_loss: -54.34248352\n",
      "Epoch: [82] [  20/ 548] time: 1238.7649, train_loss: -52.84268951, val_loss: -55.34800339\n",
      "Epoch: [82] [  30/ 548] time: 1239.1050, train_loss: -53.10736084, val_loss: -56.24408722\n",
      "Epoch: [82] [  40/ 548] time: 1239.4824, train_loss: -59.12481689, val_loss: -55.73204803\n",
      "Epoch: [82] [  50/ 548] time: 1239.8532, train_loss: -54.02890015, val_loss: -57.27173615\n",
      "Epoch: [82] [  60/ 548] time: 1240.1997, train_loss: -56.44761276, val_loss: -56.31460953\n",
      "Saving checkpoint\n",
      "Epoch: [82] [  70/ 548] time: 1241.9051, train_loss: -60.10799408, val_loss: -56.77293396\n",
      "Epoch: [82] [  80/ 548] time: 1242.1886, train_loss: -57.22713852, val_loss: -56.04386139\n",
      "Epoch: [82] [  90/ 548] time: 1242.4578, train_loss: -56.58260727, val_loss: -55.74197006\n",
      "Epoch: [82] [ 100/ 548] time: 1242.7020, train_loss: -50.59167099, val_loss: -56.99441147\n",
      "Epoch: [82] [ 110/ 548] time: 1242.9544, train_loss: -52.77536774, val_loss: -57.29378128\n",
      "Epoch: [82] [ 120/ 548] time: 1243.2105, train_loss: -57.32028961, val_loss: -56.59608459\n",
      "Epoch: [82] [ 130/ 548] time: 1243.4548, train_loss: -56.20347595, val_loss: -57.28813934\n",
      "Epoch: [82] [ 140/ 548] time: 1243.7170, train_loss: -57.14410782, val_loss: -56.53597260\n",
      "Epoch: [82] [ 150/ 548] time: 1243.9614, train_loss: -53.12192917, val_loss: -57.40879440\n",
      "Epoch: [82] [ 160/ 548] time: 1244.2310, train_loss: -54.40144730, val_loss: -56.76161957\n",
      "Epoch: [82] [ 170/ 548] time: 1244.5031, train_loss: -55.64045715, val_loss: -55.86824799\n",
      "Epoch: [82] [ 180/ 548] time: 1244.7529, train_loss: -58.31162643, val_loss: -57.46485519\n",
      "Epoch: [82] [ 190/ 548] time: 1245.0347, train_loss: -53.05954742, val_loss: -53.91572189\n",
      "Epoch: [82] [ 200/ 548] time: 1245.3770, train_loss: -44.40572739, val_loss: -54.80953217\n",
      "Epoch: [82] [ 210/ 548] time: 1245.7492, train_loss: -55.21044540, val_loss: -55.95349121\n",
      "Epoch: [82] [ 220/ 548] time: 1246.1101, train_loss: -52.78991318, val_loss: -49.97156906\n",
      "Epoch: [82] [ 230/ 548] time: 1246.4859, train_loss: -50.88973236, val_loss: -54.54985046\n",
      "Epoch: [82] [ 240/ 548] time: 1246.8262, train_loss: -48.20905685, val_loss: -54.92445755\n",
      "Epoch: [82] [ 250/ 548] time: 1247.1877, train_loss: -50.26417923, val_loss: -54.02071381\n",
      "Epoch: [82] [ 260/ 548] time: 1247.4852, train_loss: -50.77497864, val_loss: -51.88776398\n",
      "Epoch: [82] [ 270/ 548] time: 1247.7813, train_loss: -51.82841873, val_loss: -55.40840149\n",
      "Epoch: [82] [ 280/ 548] time: 1248.0625, train_loss: -58.19481659, val_loss: -56.97074890\n",
      "Epoch: [82] [ 290/ 548] time: 1248.3569, train_loss: -59.83925629, val_loss: -56.78092957\n",
      "Epoch: [82] [ 300/ 548] time: 1248.6441, train_loss: -56.04332352, val_loss: -56.62736893\n",
      "Epoch: [82] [ 310/ 548] time: 1248.9804, train_loss: -50.85740662, val_loss: -53.39656830\n",
      "Epoch: [82] [ 320/ 548] time: 1249.2933, train_loss: -54.11476135, val_loss: -55.86119080\n",
      "Epoch: [82] [ 330/ 548] time: 1249.6160, train_loss: -53.94971466, val_loss: -54.33837891\n",
      "Epoch: [82] [ 340/ 548] time: 1249.9251, train_loss: -39.93499756, val_loss: -53.34617233\n",
      "Epoch: [82] [ 350/ 548] time: 1250.2495, train_loss: -56.84145355, val_loss: -52.41396713\n",
      "Epoch: [82] [ 360/ 548] time: 1250.5400, train_loss: -52.50141144, val_loss: -54.39928436\n",
      "Epoch: [82] [ 370/ 548] time: 1250.8082, train_loss: -53.97863007, val_loss: -54.50123978\n",
      "Epoch: [82] [ 380/ 548] time: 1251.0638, train_loss: -58.49016571, val_loss: -54.67431259\n",
      "Epoch: [82] [ 390/ 548] time: 1251.3108, train_loss: -55.82192230, val_loss: -56.47734070\n",
      "Epoch: [82] [ 400/ 548] time: 1251.5833, train_loss: -56.94527054, val_loss: -56.70268250\n",
      "Epoch: [82] [ 410/ 548] time: 1251.8646, train_loss: -57.13342667, val_loss: -54.57472992\n",
      "Epoch: [82] [ 420/ 548] time: 1252.1785, train_loss: -57.50223541, val_loss: -56.02273560\n",
      "Epoch: [82] [ 430/ 548] time: 1252.5922, train_loss: -54.78860855, val_loss: -52.40491486\n",
      "Epoch: [82] [ 440/ 548] time: 1252.9293, train_loss: -52.54053116, val_loss: -55.37635422\n",
      "Epoch: [82] [ 450/ 548] time: 1253.2393, train_loss: -54.03197479, val_loss: -54.98101044\n",
      "Epoch: [82] [ 460/ 548] time: 1253.5689, train_loss: -51.89083481, val_loss: -54.40953064\n",
      "Epoch: [82] [ 470/ 548] time: 1253.9347, train_loss: -57.67771912, val_loss: -55.02265549\n",
      "Epoch: [82] [ 480/ 548] time: 1254.2811, train_loss: -55.24857712, val_loss: -54.93012619\n",
      "Epoch: [82] [ 490/ 548] time: 1254.6314, train_loss: -39.20055008, val_loss: -55.13830566\n",
      "Epoch: [82] [ 500/ 548] time: 1254.9733, train_loss: -48.50968933, val_loss: -52.89770889\n",
      "Epoch: [82] [ 510/ 548] time: 1255.3307, train_loss: -45.82223511, val_loss: -52.51547623\n",
      "Epoch: [82] [ 520/ 548] time: 1255.6716, train_loss: -56.75755310, val_loss: -54.87323761\n",
      "Epoch: [82] [ 530/ 548] time: 1256.0040, train_loss: -56.70858002, val_loss: -55.30623627\n",
      "Epoch: [82] [ 540/ 548] time: 1256.3679, train_loss: -53.76092529, val_loss: -56.32149506\n",
      "Epoch: [83] [   0/ 548] time: 1256.6199, train_loss: -48.80886078, val_loss: -56.43732834\n",
      "Epoch: [83] [  10/ 548] time: 1256.9417, train_loss: -56.53852081, val_loss: -55.26443481\n",
      "Epoch: [83] [  20/ 548] time: 1257.2837, train_loss: -51.00165176, val_loss: -54.18035126\n",
      "Epoch: [83] [  30/ 548] time: 1257.6006, train_loss: -51.85481262, val_loss: -52.69610596\n",
      "Epoch: [83] [  40/ 548] time: 1257.8828, train_loss: -54.41504669, val_loss: -53.46862030\n",
      "Epoch: [83] [  50/ 548] time: 1258.1494, train_loss: -50.99932098, val_loss: -53.64566803\n",
      "Epoch: [83] [  60/ 548] time: 1258.4134, train_loss: -45.42693329, val_loss: -55.25138092\n",
      "Epoch: [83] [  70/ 548] time: 1258.6674, train_loss: -53.63617706, val_loss: -53.91214752\n",
      "Epoch: [83] [  80/ 548] time: 1258.9402, train_loss: -56.19555664, val_loss: -54.40243530\n",
      "Epoch: [83] [  90/ 548] time: 1259.2166, train_loss: -53.00268555, val_loss: -55.76559830\n",
      "Epoch: [83] [ 100/ 548] time: 1259.4919, train_loss: -52.49163437, val_loss: -55.02189255\n",
      "Epoch: [83] [ 110/ 548] time: 1259.7498, train_loss: -54.68127441, val_loss: -55.04298401\n",
      "Epoch: [83] [ 120/ 548] time: 1260.0034, train_loss: -51.71903992, val_loss: -55.96709442\n",
      "Epoch: [83] [ 130/ 548] time: 1260.2746, train_loss: -50.42590332, val_loss: -56.58981705\n",
      "Epoch: [83] [ 140/ 548] time: 1260.6283, train_loss: -58.13601303, val_loss: -54.98337936\n",
      "Epoch: [83] [ 150/ 548] time: 1260.9427, train_loss: -45.93616104, val_loss: -55.41467285\n",
      "Epoch: [83] [ 160/ 548] time: 1261.2720, train_loss: -55.18327713, val_loss: -56.09864044\n",
      "Epoch: [83] [ 170/ 548] time: 1261.6014, train_loss: -55.21944427, val_loss: -55.96592331\n",
      "Epoch: [83] [ 180/ 548] time: 1261.9234, train_loss: -49.44039917, val_loss: -54.42922211\n",
      "Epoch: [83] [ 190/ 548] time: 1262.2907, train_loss: -55.40547562, val_loss: -53.65449524\n",
      "Epoch: [83] [ 200/ 548] time: 1262.6405, train_loss: -49.98067856, val_loss: -54.45712662\n",
      "Epoch: [83] [ 210/ 548] time: 1262.9515, train_loss: -53.39158630, val_loss: -55.66275406\n",
      "Epoch: [83] [ 220/ 548] time: 1263.2862, train_loss: -56.98580170, val_loss: -55.19971466\n",
      "Epoch: [83] [ 230/ 548] time: 1263.5982, train_loss: -56.48651886, val_loss: -55.48213577\n",
      "Epoch: [83] [ 240/ 548] time: 1263.9170, train_loss: -56.64936447, val_loss: -56.15326691\n",
      "Epoch: [83] [ 250/ 548] time: 1264.2312, train_loss: -53.05755997, val_loss: -56.86657333\n",
      "Epoch: [83] [ 260/ 548] time: 1264.4935, train_loss: -54.48152924, val_loss: -56.89190292\n",
      "Epoch: [83] [ 270/ 548] time: 1264.7640, train_loss: -55.33694458, val_loss: -57.21128845\n",
      "Epoch: [83] [ 280/ 548] time: 1265.0474, train_loss: -56.74998093, val_loss: -56.84559250\n",
      "Epoch: [83] [ 290/ 548] time: 1265.3357, train_loss: -54.62439728, val_loss: -57.08418274\n",
      "Epoch: [83] [ 300/ 548] time: 1265.6438, train_loss: -54.23614883, val_loss: -55.48744965\n",
      "Epoch: [83] [ 310/ 548] time: 1265.9024, train_loss: -56.91210938, val_loss: -56.92488480\n",
      "Epoch: [83] [ 320/ 548] time: 1266.1747, train_loss: -53.44161987, val_loss: -54.58204651\n",
      "Epoch: [83] [ 330/ 548] time: 1266.4404, train_loss: -53.08393860, val_loss: -55.43846893\n",
      "Epoch: [83] [ 340/ 548] time: 1266.7096, train_loss: -54.10769653, val_loss: -56.38471222\n",
      "Epoch: [83] [ 350/ 548] time: 1266.9607, train_loss: -54.45629120, val_loss: -55.96694946\n",
      "Epoch: [83] [ 360/ 548] time: 1267.2125, train_loss: -54.30325699, val_loss: -55.88823700\n",
      "Epoch: [83] [ 370/ 548] time: 1267.4599, train_loss: -56.34209824, val_loss: -56.42100525\n",
      "Epoch: [83] [ 380/ 548] time: 1267.7035, train_loss: -53.97810364, val_loss: -56.97003937\n",
      "Epoch: [83] [ 390/ 548] time: 1267.9502, train_loss: -58.42674637, val_loss: -57.25460815\n",
      "Epoch: [83] [ 400/ 548] time: 1268.1891, train_loss: -58.00698471, val_loss: -57.44283295\n",
      "Epoch: [83] [ 410/ 548] time: 1268.4219, train_loss: -58.55251694, val_loss: -57.01445770\n",
      "Epoch: [83] [ 420/ 548] time: 1268.6591, train_loss: -59.66097641, val_loss: -56.42723083\n",
      "Epoch: [83] [ 430/ 548] time: 1268.9144, train_loss: -54.68469238, val_loss: -55.12297058\n",
      "Epoch: [83] [ 440/ 548] time: 1269.2103, train_loss: -57.74575806, val_loss: -56.62639999\n",
      "Epoch: [83] [ 450/ 548] time: 1269.5518, train_loss: -53.40188599, val_loss: -56.96566772\n",
      "Epoch: [83] [ 460/ 548] time: 1269.9105, train_loss: -58.56636047, val_loss: -56.52770996\n",
      "Epoch: [83] [ 470/ 548] time: 1270.2489, train_loss: -60.65767670, val_loss: -56.23082733\n",
      "Epoch: [83] [ 480/ 548] time: 1270.5912, train_loss: -56.20933914, val_loss: -56.25966644\n",
      "Epoch: [83] [ 490/ 548] time: 1270.9624, train_loss: -57.45744324, val_loss: -55.42176819\n",
      "Epoch: [83] [ 500/ 548] time: 1271.3213, train_loss: -43.71669388, val_loss: -55.91862869\n",
      "Epoch: [83] [ 510/ 548] time: 1271.6474, train_loss: -60.43285751, val_loss: -55.02063751\n",
      "Saving checkpoint\n",
      "Epoch: [83] [ 520/ 548] time: 1273.3390, train_loss: -55.42308807, val_loss: -54.36750793\n",
      "Epoch: [83] [ 530/ 548] time: 1273.5983, train_loss: -56.76074982, val_loss: -54.93198395\n",
      "Epoch: [83] [ 540/ 548] time: 1273.8634, train_loss: -52.19865417, val_loss: -55.60301590\n",
      "Epoch: [84] [   0/ 548] time: 1274.0633, train_loss: -49.84809875, val_loss: -55.55011368\n",
      "Epoch: [84] [  10/ 548] time: 1274.3178, train_loss: -49.33649063, val_loss: -55.60102463\n",
      "Epoch: [84] [  20/ 548] time: 1274.5665, train_loss: -54.90862274, val_loss: -55.47814178\n",
      "Epoch: [84] [  30/ 548] time: 1274.8104, train_loss: -53.35688019, val_loss: -56.31877518\n",
      "Epoch: [84] [  40/ 548] time: 1275.0573, train_loss: -55.72284698, val_loss: -52.55163956\n",
      "Epoch: [84] [  50/ 548] time: 1275.3068, train_loss: -46.04968262, val_loss: -53.11974335\n",
      "Epoch: [84] [  60/ 548] time: 1275.5467, train_loss: -42.51114273, val_loss: -49.44764328\n",
      "Epoch: [84] [  70/ 548] time: 1275.7935, train_loss: -49.82975769, val_loss: -51.55932617\n",
      "Epoch: [84] [  80/ 548] time: 1276.0427, train_loss: -50.57364655, val_loss: -51.61002731\n",
      "Epoch: [84] [  90/ 548] time: 1276.2963, train_loss: -23.77947998, val_loss: -49.43587112\n",
      "Epoch: [84] [ 100/ 548] time: 1276.5421, train_loss: -54.18008804, val_loss: -50.79689407\n",
      "Epoch: [84] [ 110/ 548] time: 1276.8204, train_loss: -47.08259201, val_loss: -51.51238632\n",
      "Epoch: [84] [ 120/ 548] time: 1277.1646, train_loss: -36.24211884, val_loss: -51.61897659\n",
      "Epoch: [84] [ 130/ 548] time: 1277.4765, train_loss: -48.73236847, val_loss: -51.21510315\n",
      "Epoch: [84] [ 140/ 548] time: 1277.8300, train_loss: -38.46787643, val_loss: -52.51392365\n",
      "Epoch: [84] [ 150/ 548] time: 1278.1575, train_loss: -42.69029236, val_loss: -53.95926285\n",
      "Epoch: [84] [ 160/ 548] time: 1278.5308, train_loss: -37.85448456, val_loss: -54.44056702\n",
      "Epoch: [84] [ 170/ 548] time: 1278.8601, train_loss: -49.58880615, val_loss: -53.19879532\n",
      "Epoch: [84] [ 180/ 548] time: 1279.1966, train_loss: -54.46134949, val_loss: -55.63388824\n",
      "Epoch: [84] [ 190/ 548] time: 1279.5396, train_loss: -55.35115051, val_loss: -48.15435791\n",
      "Epoch: [84] [ 200/ 548] time: 1279.8680, train_loss: -51.96101761, val_loss: -53.32323456\n",
      "Epoch: [84] [ 210/ 548] time: 1280.2097, train_loss: -49.82167816, val_loss: -53.64823151\n",
      "Epoch: [84] [ 220/ 548] time: 1280.5215, train_loss: -49.42974472, val_loss: -52.58869934\n",
      "Epoch: [84] [ 230/ 548] time: 1280.8138, train_loss: -41.99724960, val_loss: -55.24848175\n",
      "Epoch: [84] [ 240/ 548] time: 1281.1217, train_loss: -58.46614838, val_loss: -54.95180130\n",
      "Epoch: [84] [ 250/ 548] time: 1281.3815, train_loss: -55.56264114, val_loss: -55.74951553\n",
      "Epoch: [84] [ 260/ 548] time: 1281.6421, train_loss: -58.95030975, val_loss: -54.79090118\n",
      "Epoch: [84] [ 270/ 548] time: 1281.8987, train_loss: -59.10130310, val_loss: -56.34922791\n",
      "Epoch: [84] [ 280/ 548] time: 1282.1465, train_loss: -58.92117691, val_loss: -56.41998291\n",
      "Epoch: [84] [ 290/ 548] time: 1282.3947, train_loss: -53.39446640, val_loss: -56.72348404\n",
      "Epoch: [84] [ 300/ 548] time: 1282.6347, train_loss: -58.57007599, val_loss: -57.14339066\n",
      "Epoch: [84] [ 310/ 548] time: 1282.8758, train_loss: -54.74134064, val_loss: -56.71947098\n",
      "Epoch: [84] [ 320/ 548] time: 1283.1133, train_loss: -56.30974960, val_loss: -56.36235428\n",
      "Epoch: [84] [ 330/ 548] time: 1283.3491, train_loss: -55.91211700, val_loss: -56.62737656\n",
      "Epoch: [84] [ 340/ 548] time: 1283.6077, train_loss: -54.31697845, val_loss: -57.21885300\n",
      "Epoch: [84] [ 350/ 548] time: 1283.8673, train_loss: -60.03924561, val_loss: -57.41609955\n",
      "Epoch: [84] [ 360/ 548] time: 1284.1512, train_loss: -52.49571991, val_loss: -57.24607849\n",
      "Epoch: [84] [ 370/ 548] time: 1284.4537, train_loss: -59.31879425, val_loss: -57.17359924\n",
      "Epoch: [84] [ 380/ 548] time: 1284.7650, train_loss: -53.06332397, val_loss: -57.74802780\n",
      "Epoch: [84] [ 390/ 548] time: 1285.0469, train_loss: -52.94465637, val_loss: -56.48903656\n",
      "Epoch: [84] [ 400/ 548] time: 1285.3277, train_loss: -56.61804199, val_loss: -56.50353622\n",
      "Epoch: [84] [ 410/ 548] time: 1285.5907, train_loss: -56.88874817, val_loss: -56.16841888\n",
      "Epoch: [84] [ 420/ 548] time: 1285.8575, train_loss: -57.22481537, val_loss: -56.07694244\n",
      "Epoch: [84] [ 430/ 548] time: 1286.1111, train_loss: -55.60295486, val_loss: -56.87907028\n",
      "Epoch: [84] [ 440/ 548] time: 1286.3646, train_loss: -58.22072601, val_loss: -57.24441147\n",
      "Epoch: [84] [ 450/ 548] time: 1286.6048, train_loss: -58.41366959, val_loss: -56.93440628\n",
      "Epoch: [84] [ 460/ 548] time: 1286.8506, train_loss: -57.43161392, val_loss: -56.36157227\n",
      "Epoch: [84] [ 470/ 548] time: 1287.1001, train_loss: -54.07530594, val_loss: -56.71750641\n",
      "Epoch: [84] [ 480/ 548] time: 1287.3865, train_loss: -58.24989700, val_loss: -56.56521606\n",
      "Epoch: [84] [ 490/ 548] time: 1287.6527, train_loss: -54.63597488, val_loss: -56.03274155\n",
      "Epoch: [84] [ 500/ 548] time: 1287.9034, train_loss: -53.92556763, val_loss: -56.10580826\n",
      "Epoch: [84] [ 510/ 548] time: 1288.1555, train_loss: -57.84094620, val_loss: -55.97473145\n",
      "Epoch: [84] [ 520/ 548] time: 1288.4271, train_loss: -51.78361511, val_loss: -56.69724274\n",
      "Epoch: [84] [ 530/ 548] time: 1288.6756, train_loss: -55.78294754, val_loss: -55.86796570\n",
      "Epoch: [84] [ 540/ 548] time: 1288.9472, train_loss: -53.80442810, val_loss: -57.00653458\n",
      "Epoch: [85] [   0/ 548] time: 1289.1674, train_loss: -53.50010681, val_loss: -56.01135254\n",
      "Epoch: [85] [  10/ 548] time: 1289.4174, train_loss: -52.46532822, val_loss: -56.27498627\n",
      "Epoch: [85] [  20/ 548] time: 1289.6721, train_loss: -43.63777161, val_loss: -56.25549316\n",
      "Epoch: [85] [  30/ 548] time: 1289.9254, train_loss: -59.89593124, val_loss: -56.74948120\n",
      "Epoch: [85] [  40/ 548] time: 1290.1877, train_loss: -56.10556412, val_loss: -56.84462738\n",
      "Epoch: [85] [  50/ 548] time: 1290.4917, train_loss: -46.01858139, val_loss: -56.42854309\n",
      "Epoch: [85] [  60/ 548] time: 1290.7674, train_loss: -51.74267578, val_loss: -56.14832306\n",
      "Epoch: [85] [  70/ 548] time: 1291.0400, train_loss: -56.10158157, val_loss: -55.53052902\n",
      "Epoch: [85] [  80/ 548] time: 1291.2906, train_loss: -55.62521362, val_loss: -56.29237366\n",
      "Epoch: [85] [  90/ 548] time: 1291.5321, train_loss: -60.42815781, val_loss: -55.69551468\n",
      "Epoch: [85] [ 100/ 548] time: 1291.7731, train_loss: -57.13133621, val_loss: -54.63068390\n",
      "Epoch: [85] [ 110/ 548] time: 1292.0194, train_loss: -58.29117966, val_loss: -56.51461792\n",
      "Epoch: [85] [ 120/ 548] time: 1292.3148, train_loss: -56.62331009, val_loss: -55.69746017\n",
      "Epoch: [85] [ 130/ 548] time: 1292.5692, train_loss: -21.63351059, val_loss: -56.15792465\n",
      "Epoch: [85] [ 140/ 548] time: 1292.8143, train_loss: -56.75698090, val_loss: -53.54399872\n",
      "Epoch: [85] [ 150/ 548] time: 1293.0499, train_loss: -52.92465591, val_loss: -55.69887543\n",
      "Epoch: [85] [ 160/ 548] time: 1293.2826, train_loss: -51.19200897, val_loss: -55.70745850\n",
      "Epoch: [85] [ 170/ 548] time: 1293.5159, train_loss: -59.25397110, val_loss: -56.20344543\n",
      "Epoch: [85] [ 180/ 548] time: 1293.7546, train_loss: -52.15847015, val_loss: -56.69730759\n",
      "Epoch: [85] [ 190/ 548] time: 1293.9894, train_loss: -42.54492950, val_loss: -55.31871796\n",
      "Epoch: [85] [ 200/ 548] time: 1294.2223, train_loss: -51.68318558, val_loss: -53.83707428\n",
      "Epoch: [85] [ 210/ 548] time: 1294.4595, train_loss: -52.71994400, val_loss: -54.62123871\n",
      "Epoch: [85] [ 220/ 548] time: 1294.6925, train_loss: -45.26917648, val_loss: -55.90847015\n",
      "Epoch: [85] [ 230/ 548] time: 1294.9277, train_loss: -51.56580734, val_loss: -56.39262772\n",
      "Epoch: [85] [ 240/ 548] time: 1295.1683, train_loss: -55.13863373, val_loss: -55.75991821\n",
      "Epoch: [85] [ 250/ 548] time: 1295.4301, train_loss: -55.98678207, val_loss: -55.64618683\n",
      "Epoch: [85] [ 260/ 548] time: 1295.6898, train_loss: -57.88377762, val_loss: -56.54561996\n",
      "Epoch: [85] [ 270/ 548] time: 1295.9311, train_loss: -47.63082123, val_loss: -56.76931763\n",
      "Epoch: [85] [ 280/ 548] time: 1296.1909, train_loss: -55.30012894, val_loss: -55.31920624\n",
      "Epoch: [85] [ 290/ 548] time: 1296.4726, train_loss: -59.85682297, val_loss: -56.99008179\n",
      "Epoch: [85] [ 300/ 548] time: 1296.7463, train_loss: -52.62835312, val_loss: -56.97744751\n",
      "Epoch: [85] [ 310/ 548] time: 1297.0185, train_loss: -56.23591995, val_loss: -57.09254837\n",
      "Epoch: [85] [ 320/ 548] time: 1297.2729, train_loss: -57.21299744, val_loss: -57.24320984\n",
      "Epoch: [85] [ 330/ 548] time: 1297.5221, train_loss: -54.70877838, val_loss: -56.28018570\n",
      "Epoch: [85] [ 340/ 548] time: 1297.7657, train_loss: -54.89402771, val_loss: -55.37958145\n",
      "Epoch: [85] [ 350/ 548] time: 1298.0073, train_loss: -52.09944534, val_loss: -56.52767563\n",
      "Epoch: [85] [ 360/ 548] time: 1298.2516, train_loss: -59.50491333, val_loss: -55.45382690\n",
      "Epoch: [85] [ 370/ 548] time: 1298.4970, train_loss: -46.99066925, val_loss: -56.87081146\n",
      "Epoch: [85] [ 380/ 548] time: 1298.7482, train_loss: -58.51483154, val_loss: -55.72295380\n",
      "Epoch: [85] [ 390/ 548] time: 1298.9937, train_loss: -50.67929840, val_loss: -55.47581863\n",
      "Epoch: [85] [ 400/ 548] time: 1299.2456, train_loss: -53.13193893, val_loss: -53.21919250\n",
      "Epoch: [85] [ 410/ 548] time: 1299.4972, train_loss: -28.00163269, val_loss: -52.36928940\n",
      "Epoch: [85] [ 420/ 548] time: 1299.7471, train_loss: -48.02053833, val_loss: -52.24927139\n",
      "Saving checkpoint\n",
      "Epoch: [85] [ 430/ 548] time: 1301.0857, train_loss: -49.95877075, val_loss: -49.45930481\n",
      "Epoch: [85] [ 440/ 548] time: 1301.3496, train_loss: -49.92980957, val_loss: -53.84789276\n",
      "Epoch: [85] [ 450/ 548] time: 1301.5814, train_loss: -51.17646790, val_loss: -54.29713440\n",
      "Epoch: [85] [ 460/ 548] time: 1301.8091, train_loss: -56.76559067, val_loss: -54.73600006\n",
      "Epoch: [85] [ 470/ 548] time: 1302.0432, train_loss: -43.42605972, val_loss: -54.21865463\n",
      "Epoch: [85] [ 480/ 548] time: 1302.3211, train_loss: -56.68914032, val_loss: -55.03783798\n",
      "Epoch: [85] [ 490/ 548] time: 1302.6097, train_loss: -46.70303726, val_loss: -55.96867752\n",
      "Epoch: [85] [ 500/ 548] time: 1302.8863, train_loss: -50.69026947, val_loss: -56.54506683\n",
      "Epoch: [85] [ 510/ 548] time: 1303.1455, train_loss: -59.10506058, val_loss: -56.22379684\n",
      "Epoch: [85] [ 520/ 548] time: 1303.3888, train_loss: -58.31567001, val_loss: -52.04560089\n",
      "Epoch: [85] [ 530/ 548] time: 1303.6362, train_loss: -56.24787903, val_loss: -55.61610413\n",
      "Epoch: [85] [ 540/ 548] time: 1303.8874, train_loss: -50.61469650, val_loss: -55.65338898\n",
      "Epoch: [86] [   0/ 548] time: 1304.0924, train_loss: -54.49068069, val_loss: -55.96870804\n",
      "Epoch: [86] [  10/ 548] time: 1304.3464, train_loss: -46.23614883, val_loss: -55.42612076\n",
      "Epoch: [86] [  20/ 548] time: 1304.5935, train_loss: -51.93067169, val_loss: -55.50365448\n",
      "Epoch: [86] [  30/ 548] time: 1304.8452, train_loss: -59.13829803, val_loss: -55.95911789\n",
      "Epoch: [86] [  40/ 548] time: 1305.0934, train_loss: -56.38111496, val_loss: -55.49333191\n",
      "Epoch: [86] [  50/ 548] time: 1305.3426, train_loss: -54.60670471, val_loss: -54.85063934\n",
      "Epoch: [86] [  60/ 548] time: 1305.5854, train_loss: -52.38684845, val_loss: -56.13488770\n",
      "Epoch: [86] [  70/ 548] time: 1305.8272, train_loss: -58.36839676, val_loss: -56.35188293\n",
      "Epoch: [86] [  80/ 548] time: 1306.0668, train_loss: -46.86934280, val_loss: -55.01134872\n",
      "Epoch: [86] [  90/ 548] time: 1306.3088, train_loss: -53.98712158, val_loss: -56.43340302\n",
      "Epoch: [86] [ 100/ 548] time: 1306.5457, train_loss: -52.76195526, val_loss: -54.96280289\n",
      "Epoch: [86] [ 110/ 548] time: 1306.7787, train_loss: -59.32854843, val_loss: -55.06128693\n",
      "Epoch: [86] [ 120/ 548] time: 1307.0168, train_loss: -55.47616196, val_loss: -55.59346008\n",
      "Epoch: [86] [ 130/ 548] time: 1307.2573, train_loss: -52.64517975, val_loss: -56.93008804\n",
      "Epoch: [86] [ 140/ 548] time: 1307.4935, train_loss: -48.96185303, val_loss: -55.05132294\n",
      "Epoch: [86] [ 150/ 548] time: 1307.7345, train_loss: -49.72056580, val_loss: -52.38502121\n",
      "Epoch: [86] [ 160/ 548] time: 1307.9801, train_loss: -42.42137909, val_loss: -53.66876984\n",
      "Epoch: [86] [ 170/ 548] time: 1308.2371, train_loss: -43.79859161, val_loss: -52.81843567\n",
      "Epoch: [86] [ 180/ 548] time: 1308.4970, train_loss: -49.89573669, val_loss: -54.46487808\n",
      "Epoch: [86] [ 190/ 548] time: 1308.7654, train_loss: -56.74104309, val_loss: -53.40193176\n",
      "Epoch: [86] [ 200/ 548] time: 1309.0460, train_loss: -27.75049591, val_loss: -53.82077789\n",
      "Epoch: [86] [ 210/ 548] time: 1309.3001, train_loss: -52.19641113, val_loss: -54.16434097\n",
      "Epoch: [86] [ 220/ 548] time: 1309.5551, train_loss: -49.27062988, val_loss: -54.43680573\n",
      "Epoch: [86] [ 230/ 548] time: 1309.8070, train_loss: -54.49035645, val_loss: -54.46580124\n",
      "Epoch: [86] [ 240/ 548] time: 1310.0532, train_loss: -49.56755447, val_loss: -54.51638031\n",
      "Epoch: [86] [ 250/ 548] time: 1310.3013, train_loss: -55.25147629, val_loss: -52.91165543\n",
      "Epoch: [86] [ 260/ 548] time: 1310.5409, train_loss: -52.44727707, val_loss: -51.81624985\n",
      "Epoch: [86] [ 270/ 548] time: 1310.7810, train_loss: -52.97472382, val_loss: -55.29309464\n",
      "Epoch: [86] [ 280/ 548] time: 1311.0181, train_loss: -60.33158875, val_loss: -56.10113525\n",
      "Epoch: [86] [ 290/ 548] time: 1311.2519, train_loss: -57.17628860, val_loss: -55.89548874\n",
      "Epoch: [86] [ 300/ 548] time: 1311.5034, train_loss: -57.69982529, val_loss: -56.32143784\n",
      "Epoch: [86] [ 310/ 548] time: 1311.7598, train_loss: -55.24364471, val_loss: -56.54999924\n",
      "Epoch: [86] [ 320/ 548] time: 1312.0019, train_loss: -60.43185043, val_loss: -55.44927979\n",
      "Epoch: [86] [ 330/ 548] time: 1312.2565, train_loss: -58.56999588, val_loss: -56.60182571\n",
      "Epoch: [86] [ 340/ 548] time: 1312.5161, train_loss: -58.13632584, val_loss: -56.41448593\n",
      "Epoch: [86] [ 350/ 548] time: 1312.7777, train_loss: -57.04947662, val_loss: -57.31752777\n",
      "Epoch: [86] [ 360/ 548] time: 1313.0237, train_loss: -43.01798630, val_loss: -56.83907700\n",
      "Epoch: [86] [ 370/ 548] time: 1313.2682, train_loss: -58.17222977, val_loss: -57.09032059\n",
      "Epoch: [86] [ 380/ 548] time: 1313.5099, train_loss: -57.90338135, val_loss: -56.25778198\n",
      "Epoch: [86] [ 390/ 548] time: 1313.7558, train_loss: -55.62642670, val_loss: -56.96707535\n",
      "Epoch: [86] [ 400/ 548] time: 1314.0043, train_loss: -58.66912460, val_loss: -56.00731659\n",
      "Epoch: [86] [ 410/ 548] time: 1314.2727, train_loss: -53.44575500, val_loss: -55.03353882\n",
      "Epoch: [86] [ 420/ 548] time: 1314.5410, train_loss: -52.99361420, val_loss: -53.79965210\n",
      "Epoch: [86] [ 430/ 548] time: 1314.8143, train_loss: -50.55093765, val_loss: -54.58206558\n",
      "Epoch: [86] [ 440/ 548] time: 1315.0844, train_loss: -54.78405380, val_loss: -50.33889008\n",
      "Epoch: [86] [ 450/ 548] time: 1315.3309, train_loss: -56.77550888, val_loss: -54.25722885\n",
      "Epoch: [86] [ 460/ 548] time: 1315.5883, train_loss: -52.09233856, val_loss: -47.35298538\n",
      "Epoch: [86] [ 470/ 548] time: 1315.8636, train_loss: -47.63232422, val_loss: -51.86816025\n",
      "Epoch: [86] [ 480/ 548] time: 1316.1327, train_loss: -48.95870972, val_loss: -51.98608780\n",
      "Epoch: [86] [ 490/ 548] time: 1316.4111, train_loss: -52.57758331, val_loss: -44.45765686\n",
      "Epoch: [86] [ 500/ 548] time: 1316.6808, train_loss: -47.83319855, val_loss: -47.51139069\n",
      "Epoch: [86] [ 510/ 548] time: 1316.9417, train_loss: -51.81196213, val_loss: -49.77210236\n",
      "Epoch: [86] [ 520/ 548] time: 1317.2075, train_loss: -46.93594742, val_loss: -44.94966125\n",
      "Epoch: [86] [ 530/ 548] time: 1317.4835, train_loss: -52.84468842, val_loss: -51.11342239\n",
      "Epoch: [86] [ 540/ 548] time: 1317.7516, train_loss: -49.99479294, val_loss: -50.21577835\n",
      "Epoch: [87] [   0/ 548] time: 1317.9834, train_loss: -54.93664169, val_loss: -51.94924545\n",
      "Epoch: [87] [  10/ 548] time: 1318.2639, train_loss: -26.71688843, val_loss: -48.60136032\n",
      "Epoch: [87] [  20/ 548] time: 1318.5464, train_loss: -54.07889557, val_loss: -49.25674438\n",
      "Epoch: [87] [  30/ 548] time: 1318.8118, train_loss: -48.59723663, val_loss: -50.80277252\n",
      "Epoch: [87] [  40/ 548] time: 1319.0692, train_loss: -43.81831741, val_loss: -54.19954681\n",
      "Epoch: [87] [  50/ 548] time: 1319.3211, train_loss: -48.64891052, val_loss: -50.92863846\n",
      "Epoch: [87] [  60/ 548] time: 1319.5966, train_loss: -53.31526184, val_loss: -53.47602081\n",
      "Epoch: [87] [  70/ 548] time: 1319.8627, train_loss: -51.45247650, val_loss: -53.93703079\n",
      "Epoch: [87] [  80/ 548] time: 1320.1346, train_loss: -45.83830261, val_loss: -55.10840225\n",
      "Epoch: [87] [  90/ 548] time: 1320.4355, train_loss: -53.60394669, val_loss: -54.42968750\n",
      "Epoch: [87] [ 100/ 548] time: 1320.7317, train_loss: -49.52716446, val_loss: -55.36007690\n",
      "Epoch: [87] [ 110/ 548] time: 1321.0127, train_loss: -55.40703583, val_loss: -55.77914047\n",
      "Epoch: [87] [ 120/ 548] time: 1321.2818, train_loss: -57.04746628, val_loss: -56.50480652\n",
      "Epoch: [87] [ 130/ 548] time: 1321.5371, train_loss: -57.48513412, val_loss: -57.28677368\n",
      "Epoch: [87] [ 140/ 548] time: 1321.7923, train_loss: -55.64801025, val_loss: -55.80767822\n",
      "Epoch: [87] [ 150/ 548] time: 1322.0419, train_loss: -57.07322311, val_loss: -57.04618835\n",
      "Epoch: [87] [ 160/ 548] time: 1322.3310, train_loss: -59.42394257, val_loss: -55.81560898\n",
      "Epoch: [87] [ 170/ 548] time: 1322.6006, train_loss: -58.18006897, val_loss: -56.33050537\n",
      "Epoch: [87] [ 180/ 548] time: 1322.8717, train_loss: -43.38650894, val_loss: -56.75957489\n",
      "Epoch: [87] [ 190/ 548] time: 1323.1437, train_loss: -57.80019379, val_loss: -56.74131012\n",
      "Epoch: [87] [ 200/ 548] time: 1323.4123, train_loss: -56.58925629, val_loss: -57.30032349\n",
      "Epoch: [87] [ 210/ 548] time: 1323.6801, train_loss: -57.81118774, val_loss: -56.13497543\n",
      "Epoch: [87] [ 220/ 548] time: 1323.9581, train_loss: -55.82486343, val_loss: -55.85308838\n",
      "Epoch: [87] [ 230/ 548] time: 1324.2272, train_loss: -57.44235229, val_loss: -56.79102325\n",
      "Epoch: [87] [ 240/ 548] time: 1324.4853, train_loss: -54.51197052, val_loss: -55.68113327\n",
      "Epoch: [87] [ 250/ 548] time: 1324.7512, train_loss: -57.07789993, val_loss: -54.29641724\n",
      "Epoch: [87] [ 260/ 548] time: 1325.0072, train_loss: -59.15096283, val_loss: -54.85079193\n",
      "Epoch: [87] [ 270/ 548] time: 1325.2566, train_loss: -46.43054199, val_loss: -56.64310455\n",
      "Epoch: [87] [ 280/ 548] time: 1325.5466, train_loss: -47.48600006, val_loss: -55.64083099\n",
      "Epoch: [87] [ 290/ 548] time: 1325.8146, train_loss: -53.14315796, val_loss: -55.74482346\n",
      "Epoch: [87] [ 300/ 548] time: 1326.0685, train_loss: -58.36127472, val_loss: -56.54521561\n",
      "Epoch: [87] [ 310/ 548] time: 1326.3377, train_loss: -59.76937485, val_loss: -56.24847794\n",
      "Epoch: [87] [ 320/ 548] time: 1326.6050, train_loss: -53.62012863, val_loss: -57.33682251\n",
      "Saving checkpoint\n",
      "Epoch: [87] [ 330/ 548] time: 1328.0158, train_loss: -48.27044296, val_loss: -57.07519913\n",
      "Epoch: [87] [ 340/ 548] time: 1328.3616, train_loss: -55.67924881, val_loss: -56.74880600\n",
      "Epoch: [87] [ 350/ 548] time: 1328.6971, train_loss: -50.36799240, val_loss: -55.67335129\n",
      "Epoch: [87] [ 360/ 548] time: 1329.0187, train_loss: -56.06950760, val_loss: -56.91067505\n",
      "Epoch: [87] [ 370/ 548] time: 1329.3360, train_loss: -50.68548965, val_loss: -56.74425507\n",
      "Epoch: [87] [ 380/ 548] time: 1329.6862, train_loss: -42.00885773, val_loss: -56.51174164\n",
      "Epoch: [87] [ 390/ 548] time: 1330.0044, train_loss: -56.57309341, val_loss: -56.98437881\n",
      "Epoch: [87] [ 400/ 548] time: 1330.3456, train_loss: -57.57731628, val_loss: -57.00180435\n",
      "Epoch: [87] [ 410/ 548] time: 1330.6581, train_loss: -58.27957535, val_loss: -56.83398056\n",
      "Epoch: [87] [ 420/ 548] time: 1330.9674, train_loss: -45.22426605, val_loss: -55.39090729\n",
      "Epoch: [87] [ 430/ 548] time: 1331.2621, train_loss: -58.75564575, val_loss: -55.90415955\n",
      "Epoch: [87] [ 440/ 548] time: 1331.5239, train_loss: -58.24845123, val_loss: -52.12738037\n",
      "Epoch: [87] [ 450/ 548] time: 1331.7860, train_loss: -52.96994019, val_loss: -55.56322098\n",
      "Epoch: [87] [ 460/ 548] time: 1332.0481, train_loss: -53.81373596, val_loss: -56.26980209\n",
      "Epoch: [87] [ 470/ 548] time: 1332.3227, train_loss: -56.76627731, val_loss: -56.06940460\n",
      "Epoch: [87] [ 480/ 548] time: 1332.6139, train_loss: -58.92433929, val_loss: -56.60974121\n",
      "Epoch: [87] [ 490/ 548] time: 1332.8816, train_loss: -60.85263443, val_loss: -57.34122467\n",
      "Epoch: [87] [ 500/ 548] time: 1333.1323, train_loss: -44.91715622, val_loss: -53.48833847\n",
      "Epoch: [87] [ 510/ 548] time: 1333.3954, train_loss: -50.87580109, val_loss: -56.87352753\n",
      "Epoch: [87] [ 520/ 548] time: 1333.6361, train_loss: -59.81317139, val_loss: -56.46419907\n",
      "Epoch: [87] [ 530/ 548] time: 1333.8769, train_loss: -49.16658020, val_loss: -57.33597183\n",
      "Epoch: [87] [ 540/ 548] time: 1334.1137, train_loss: -59.71986008, val_loss: -57.31351471\n",
      "Epoch: [88] [   0/ 548] time: 1334.2981, train_loss: -56.00899506, val_loss: -57.17160416\n",
      "Epoch: [88] [  10/ 548] time: 1334.5402, train_loss: -56.80286789, val_loss: -57.16921234\n",
      "Epoch: [88] [  20/ 548] time: 1334.7961, train_loss: -53.67259598, val_loss: -56.59733200\n",
      "Epoch: [88] [  30/ 548] time: 1335.0484, train_loss: -46.76530838, val_loss: -54.06389999\n",
      "Epoch: [88] [  40/ 548] time: 1335.2858, train_loss: -53.83267975, val_loss: -55.37791061\n",
      "Epoch: [88] [  50/ 548] time: 1335.5225, train_loss: -53.05853271, val_loss: -56.74563217\n",
      "Epoch: [88] [  60/ 548] time: 1335.7573, train_loss: -60.29203796, val_loss: -56.40687943\n",
      "Epoch: [88] [  70/ 548] time: 1335.9990, train_loss: -54.18605423, val_loss: -55.64524460\n",
      "Epoch: [88] [  80/ 548] time: 1336.2389, train_loss: -59.32741547, val_loss: -57.39544296\n",
      "Epoch: [88] [  90/ 548] time: 1336.4812, train_loss: -53.87083435, val_loss: -56.07771683\n",
      "Epoch: [88] [ 100/ 548] time: 1336.7509, train_loss: -52.76027298, val_loss: -56.12269211\n",
      "Epoch: [88] [ 110/ 548] time: 1337.0187, train_loss: -58.14680862, val_loss: -57.11451721\n",
      "Epoch: [88] [ 120/ 548] time: 1337.2751, train_loss: -51.80645752, val_loss: -57.69091034\n",
      "Epoch: [88] [ 130/ 548] time: 1337.5189, train_loss: -54.43443298, val_loss: -57.34922409\n",
      "Epoch: [88] [ 140/ 548] time: 1337.7786, train_loss: -59.15415192, val_loss: -57.10256958\n",
      "Epoch: [88] [ 150/ 548] time: 1338.0527, train_loss: -52.40195465, val_loss: -57.36935043\n",
      "Epoch: [88] [ 160/ 548] time: 1338.3225, train_loss: -52.99338531, val_loss: -56.38069534\n",
      "Epoch: [88] [ 170/ 548] time: 1338.5849, train_loss: -53.11507416, val_loss: -56.05998993\n",
      "Epoch: [88] [ 180/ 548] time: 1338.8440, train_loss: -57.64897537, val_loss: -53.55965424\n",
      "Epoch: [88] [ 190/ 548] time: 1339.0931, train_loss: -60.91810226, val_loss: -55.72566605\n",
      "Epoch: [88] [ 200/ 548] time: 1339.3463, train_loss: -55.81574249, val_loss: -57.00439453\n",
      "Epoch: [88] [ 210/ 548] time: 1339.5952, train_loss: -50.43939209, val_loss: -55.81291580\n",
      "Epoch: [88] [ 220/ 548] time: 1339.8436, train_loss: -52.08354187, val_loss: -57.12176132\n",
      "Epoch: [88] [ 230/ 548] time: 1340.0924, train_loss: -45.52915192, val_loss: -57.56028748\n",
      "Epoch: [88] [ 240/ 548] time: 1340.3364, train_loss: -56.20020676, val_loss: -53.45730972\n",
      "Epoch: [88] [ 250/ 548] time: 1340.5728, train_loss: -52.56626892, val_loss: -55.08847046\n",
      "Epoch: [88] [ 260/ 548] time: 1340.8183, train_loss: -54.68743896, val_loss: -55.06308746\n",
      "Epoch: [88] [ 270/ 548] time: 1341.0757, train_loss: -56.97755051, val_loss: -56.58787918\n",
      "Epoch: [88] [ 280/ 548] time: 1341.3178, train_loss: -51.78372574, val_loss: -56.25693893\n",
      "Epoch: [88] [ 290/ 548] time: 1341.5558, train_loss: -49.01113510, val_loss: -56.47216034\n",
      "Epoch: [88] [ 300/ 548] time: 1341.7911, train_loss: -57.58184052, val_loss: -55.98195648\n",
      "Epoch: [88] [ 310/ 548] time: 1342.0259, train_loss: -56.53149033, val_loss: -56.16255188\n",
      "Epoch: [88] [ 320/ 548] time: 1342.2787, train_loss: -46.01797485, val_loss: -55.11741257\n",
      "Epoch: [88] [ 330/ 548] time: 1342.5261, train_loss: -46.06517792, val_loss: -50.78643036\n",
      "Epoch: [88] [ 340/ 548] time: 1342.7734, train_loss: -53.26696014, val_loss: -52.35371780\n",
      "Epoch: [88] [ 350/ 548] time: 1343.0170, train_loss: -55.88960266, val_loss: -55.63064957\n",
      "Epoch: [88] [ 360/ 548] time: 1343.2625, train_loss: -58.36244583, val_loss: -55.45934677\n",
      "Epoch: [88] [ 370/ 548] time: 1343.5010, train_loss: -50.56300354, val_loss: -55.45551300\n",
      "Epoch: [88] [ 380/ 548] time: 1343.7415, train_loss: -46.72609711, val_loss: -55.64657974\n",
      "Epoch: [88] [ 390/ 548] time: 1344.0137, train_loss: -56.60827637, val_loss: -54.00658798\n",
      "Epoch: [88] [ 400/ 548] time: 1344.2851, train_loss: -46.85456848, val_loss: -55.96422577\n",
      "Epoch: [88] [ 410/ 548] time: 1344.5540, train_loss: -52.56003189, val_loss: -53.73489761\n",
      "Epoch: [88] [ 420/ 548] time: 1344.8164, train_loss: -55.31674957, val_loss: -55.73526382\n",
      "Epoch: [88] [ 430/ 548] time: 1345.0529, train_loss: -57.30199814, val_loss: -56.52966309\n",
      "Epoch: [88] [ 440/ 548] time: 1345.2908, train_loss: -59.50016785, val_loss: -55.68492889\n",
      "Epoch: [88] [ 450/ 548] time: 1345.5327, train_loss: -52.12230682, val_loss: -55.72093201\n",
      "Epoch: [88] [ 460/ 548] time: 1345.7660, train_loss: -60.33267212, val_loss: -56.89810944\n",
      "Epoch: [88] [ 470/ 548] time: 1346.0052, train_loss: -57.52418900, val_loss: -55.96533966\n",
      "Epoch: [88] [ 480/ 548] time: 1346.2416, train_loss: -52.69244385, val_loss: -56.04296112\n",
      "Epoch: [88] [ 490/ 548] time: 1346.4725, train_loss: -58.36006927, val_loss: -56.59898376\n",
      "Epoch: [88] [ 500/ 548] time: 1346.7123, train_loss: -50.75739288, val_loss: -55.75680923\n",
      "Epoch: [88] [ 510/ 548] time: 1346.9487, train_loss: -55.42473221, val_loss: -55.60754776\n",
      "Epoch: [88] [ 520/ 548] time: 1347.1857, train_loss: -53.69538879, val_loss: -54.70428467\n",
      "Epoch: [88] [ 530/ 548] time: 1347.4265, train_loss: -53.30049896, val_loss: -53.15373611\n",
      "Epoch: [88] [ 540/ 548] time: 1347.6768, train_loss: -55.02798080, val_loss: -54.43585968\n",
      "Epoch: [89] [   0/ 548] time: 1347.8696, train_loss: -49.77215958, val_loss: -51.76261139\n",
      "Epoch: [89] [  10/ 548] time: 1348.1153, train_loss: -49.38617706, val_loss: -53.43768311\n",
      "Epoch: [89] [  20/ 548] time: 1348.3579, train_loss: -52.19313049, val_loss: -54.05994415\n",
      "Epoch: [89] [  30/ 548] time: 1348.6146, train_loss: -53.12961578, val_loss: -55.53834915\n",
      "Epoch: [89] [  40/ 548] time: 1348.8541, train_loss: -55.81097794, val_loss: -55.27305603\n",
      "Epoch: [89] [  50/ 548] time: 1349.0921, train_loss: -56.93059158, val_loss: -56.79805374\n",
      "Epoch: [89] [  60/ 548] time: 1349.3336, train_loss: -58.20783234, val_loss: -57.13716507\n",
      "Epoch: [89] [  70/ 548] time: 1349.5747, train_loss: -54.54263687, val_loss: -56.53157425\n",
      "Epoch: [89] [  80/ 548] time: 1349.8097, train_loss: -52.88327789, val_loss: -56.81777954\n",
      "Epoch: [89] [  90/ 548] time: 1350.0810, train_loss: -60.33650208, val_loss: -57.99517822\n",
      "Epoch: [89] [ 100/ 548] time: 1350.3654, train_loss: -57.79757690, val_loss: -57.36161041\n",
      "Epoch: [89] [ 110/ 548] time: 1350.6334, train_loss: -53.36055756, val_loss: -57.13774490\n",
      "Epoch: [89] [ 120/ 548] time: 1350.9126, train_loss: -53.49063873, val_loss: -57.59084320\n",
      "Epoch: [89] [ 130/ 548] time: 1351.1548, train_loss: -49.65931702, val_loss: -58.00803757\n",
      "Epoch: [89] [ 140/ 548] time: 1351.3928, train_loss: -54.82319641, val_loss: -57.22571182\n",
      "Epoch: [89] [ 150/ 548] time: 1351.6317, train_loss: -55.61943054, val_loss: -57.16523743\n",
      "Epoch: [89] [ 160/ 548] time: 1351.8700, train_loss: -50.74124146, val_loss: -56.56095886\n",
      "Epoch: [89] [ 170/ 548] time: 1352.1479, train_loss: -54.71497345, val_loss: -56.91735840\n",
      "Epoch: [89] [ 180/ 548] time: 1352.4039, train_loss: -56.63595581, val_loss: -57.43491745\n",
      "Epoch: [89] [ 190/ 548] time: 1352.6620, train_loss: -52.95274353, val_loss: -56.26568604\n",
      "Epoch: [89] [ 200/ 548] time: 1352.9024, train_loss: -54.63687515, val_loss: -56.57460022\n",
      "Epoch: [89] [ 210/ 548] time: 1353.1392, train_loss: -50.08104706, val_loss: -56.23010254\n",
      "Epoch: [89] [ 220/ 548] time: 1353.3790, train_loss: -56.11687088, val_loss: -56.74502182\n",
      "Saving checkpoint\n",
      "Epoch: [89] [ 230/ 548] time: 1354.6517, train_loss: -53.13898849, val_loss: -56.04243469\n",
      "Epoch: [89] [ 240/ 548] time: 1354.9087, train_loss: -54.96419907, val_loss: -52.50342941\n",
      "Epoch: [89] [ 250/ 548] time: 1355.1531, train_loss: -44.04428864, val_loss: -53.89213181\n",
      "Epoch: [89] [ 260/ 548] time: 1355.4039, train_loss: -50.84825897, val_loss: -53.73660278\n",
      "Epoch: [89] [ 270/ 548] time: 1355.6514, train_loss: -54.36026001, val_loss: -53.72367859\n",
      "Epoch: [89] [ 280/ 548] time: 1355.8851, train_loss: -51.02453995, val_loss: -53.66542053\n",
      "Epoch: [89] [ 290/ 548] time: 1356.1399, train_loss: -56.83619690, val_loss: -54.75260162\n",
      "Epoch: [89] [ 300/ 548] time: 1356.3861, train_loss: -57.40542221, val_loss: -54.74711990\n",
      "Epoch: [89] [ 310/ 548] time: 1356.6423, train_loss: -57.72874832, val_loss: -56.17653656\n",
      "Epoch: [89] [ 320/ 548] time: 1356.8668, train_loss: -53.73800278, val_loss: -56.95700073\n",
      "Epoch: [89] [ 330/ 548] time: 1357.0983, train_loss: -42.14587784, val_loss: -54.14599609\n",
      "Epoch: [89] [ 340/ 548] time: 1357.3379, train_loss: -59.66043091, val_loss: -56.31108856\n",
      "Epoch: [89] [ 350/ 548] time: 1357.5797, train_loss: -52.00158691, val_loss: -56.96755981\n",
      "Epoch: [89] [ 360/ 548] time: 1357.8342, train_loss: -54.14949799, val_loss: -57.02633286\n",
      "Epoch: [89] [ 370/ 548] time: 1358.0812, train_loss: -59.19714737, val_loss: -56.64967346\n",
      "Epoch: [89] [ 380/ 548] time: 1358.3271, train_loss: -57.94199371, val_loss: -57.20753860\n",
      "Epoch: [89] [ 390/ 548] time: 1358.5793, train_loss: -58.32263565, val_loss: -56.59967804\n",
      "Epoch: [89] [ 400/ 548] time: 1358.8236, train_loss: -58.93337250, val_loss: -57.07527924\n",
      "Epoch: [89] [ 410/ 548] time: 1359.0684, train_loss: -59.37463760, val_loss: -55.52833176\n",
      "Epoch: [89] [ 420/ 548] time: 1359.3121, train_loss: -48.31345749, val_loss: -56.57273102\n",
      "Epoch: [89] [ 430/ 548] time: 1359.5505, train_loss: -54.98738480, val_loss: -56.47548676\n",
      "Epoch: [89] [ 440/ 548] time: 1359.7919, train_loss: -56.06793976, val_loss: -56.86941147\n",
      "Epoch: [89] [ 450/ 548] time: 1360.0334, train_loss: -60.19810104, val_loss: -56.94552994\n",
      "Epoch: [89] [ 460/ 548] time: 1360.2792, train_loss: -50.27777100, val_loss: -57.74282455\n",
      "Epoch: [89] [ 470/ 548] time: 1360.5276, train_loss: -59.87374878, val_loss: -57.11309433\n",
      "Epoch: [89] [ 480/ 548] time: 1360.7677, train_loss: -47.76221085, val_loss: -52.62302399\n",
      "Epoch: [89] [ 490/ 548] time: 1361.0086, train_loss: -49.44368362, val_loss: -53.76134491\n",
      "Epoch: [89] [ 500/ 548] time: 1361.2521, train_loss: -56.22113800, val_loss: -51.49317169\n",
      "Epoch: [89] [ 510/ 548] time: 1361.4896, train_loss: -53.56495667, val_loss: -51.85796738\n",
      "Epoch: [89] [ 520/ 548] time: 1361.7401, train_loss: -55.85974884, val_loss: -54.29750824\n",
      "Epoch: [89] [ 530/ 548] time: 1362.0050, train_loss: -52.52621078, val_loss: -56.30960083\n",
      "Epoch: [89] [ 540/ 548] time: 1362.2781, train_loss: -56.45424652, val_loss: -53.42366791\n",
      "Epoch: [90] [   0/ 548] time: 1362.5035, train_loss: -44.96804428, val_loss: -52.64102554\n",
      "Epoch: [90] [  10/ 548] time: 1362.7589, train_loss: -48.53222656, val_loss: -56.00408173\n",
      "Epoch: [90] [  20/ 548] time: 1363.0049, train_loss: -54.86311340, val_loss: -55.70787811\n",
      "Epoch: [90] [  30/ 548] time: 1363.2473, train_loss: -50.00410080, val_loss: -55.46533203\n",
      "Epoch: [90] [  40/ 548] time: 1363.4885, train_loss: -53.36372757, val_loss: -55.09452820\n",
      "Epoch: [90] [  50/ 548] time: 1363.7309, train_loss: -58.70064545, val_loss: -53.63067245\n",
      "Epoch: [90] [  60/ 548] time: 1363.9732, train_loss: -48.82813263, val_loss: -54.42849731\n",
      "Epoch: [90] [  70/ 548] time: 1364.2133, train_loss: -55.94417572, val_loss: -55.81450653\n",
      "Epoch: [90] [  80/ 548] time: 1364.4506, train_loss: -52.09310150, val_loss: -56.57163239\n",
      "Epoch: [90] [  90/ 548] time: 1364.6902, train_loss: -44.56021881, val_loss: -56.69344711\n",
      "Epoch: [90] [ 100/ 548] time: 1364.9212, train_loss: -53.64691544, val_loss: -54.63152695\n",
      "Epoch: [90] [ 110/ 548] time: 1365.1627, train_loss: -59.31922913, val_loss: -54.76823425\n",
      "Epoch: [90] [ 120/ 548] time: 1365.4083, train_loss: -40.27402496, val_loss: -56.98065186\n",
      "Epoch: [90] [ 130/ 548] time: 1365.6488, train_loss: -58.02804947, val_loss: -56.40539932\n",
      "Epoch: [90] [ 140/ 548] time: 1365.8980, train_loss: -56.96207428, val_loss: -57.38508606\n",
      "Epoch: [90] [ 150/ 548] time: 1366.1530, train_loss: -60.21201706, val_loss: -56.95701981\n",
      "Epoch: [90] [ 160/ 548] time: 1366.3996, train_loss: -51.63272858, val_loss: -57.15404129\n",
      "Epoch: [90] [ 170/ 548] time: 1366.6415, train_loss: -57.11951447, val_loss: -57.61228943\n",
      "Epoch: [90] [ 180/ 548] time: 1366.8842, train_loss: -45.55852509, val_loss: -53.95051193\n",
      "Epoch: [90] [ 190/ 548] time: 1367.1373, train_loss: -55.39107513, val_loss: -57.03392792\n",
      "Epoch: [90] [ 200/ 548] time: 1367.3886, train_loss: -52.90193176, val_loss: -54.67107391\n",
      "Epoch: [90] [ 210/ 548] time: 1367.6408, train_loss: -55.19663620, val_loss: -55.63513184\n",
      "Epoch: [90] [ 220/ 548] time: 1367.9136, train_loss: -51.26818085, val_loss: -56.14677429\n",
      "Epoch: [90] [ 230/ 548] time: 1368.1938, train_loss: -46.90268707, val_loss: -57.26489639\n",
      "Epoch: [90] [ 240/ 548] time: 1368.4696, train_loss: -49.12013626, val_loss: -55.48949432\n",
      "Epoch: [90] [ 250/ 548] time: 1368.7242, train_loss: -54.93020630, val_loss: -57.12710571\n",
      "Epoch: [90] [ 260/ 548] time: 1368.9735, train_loss: -55.53981400, val_loss: -56.16061783\n",
      "Epoch: [90] [ 270/ 548] time: 1369.2152, train_loss: -58.90779114, val_loss: -55.96949005\n",
      "Epoch: [90] [ 280/ 548] time: 1369.4603, train_loss: -51.95739746, val_loss: -55.01158524\n",
      "Epoch: [90] [ 290/ 548] time: 1369.6998, train_loss: -49.93901062, val_loss: -56.36620712\n",
      "Epoch: [90] [ 300/ 548] time: 1369.9375, train_loss: -52.91876221, val_loss: -56.52242279\n",
      "Epoch: [90] [ 310/ 548] time: 1370.1802, train_loss: -52.34381104, val_loss: -56.02102661\n",
      "Epoch: [90] [ 320/ 548] time: 1370.4208, train_loss: -56.95729065, val_loss: -55.87943268\n",
      "Epoch: [90] [ 330/ 548] time: 1370.6534, train_loss: -46.28324127, val_loss: -55.58186722\n",
      "Epoch: [90] [ 340/ 548] time: 1370.8861, train_loss: -47.30418396, val_loss: -54.81631470\n",
      "Epoch: [90] [ 350/ 548] time: 1371.1358, train_loss: -55.41595459, val_loss: -54.94461823\n",
      "Epoch: [90] [ 360/ 548] time: 1371.3746, train_loss: -56.24880600, val_loss: -57.08116531\n",
      "Epoch: [90] [ 370/ 548] time: 1371.6315, train_loss: -51.93861008, val_loss: -56.16447830\n",
      "Epoch: [90] [ 380/ 548] time: 1371.8947, train_loss: -59.50318146, val_loss: -56.35609055\n",
      "Epoch: [90] [ 390/ 548] time: 1372.2132, train_loss: -49.85120392, val_loss: -55.38017273\n",
      "Epoch: [90] [ 400/ 548] time: 1372.4896, train_loss: -55.65359116, val_loss: -55.59780121\n",
      "Epoch: [90] [ 410/ 548] time: 1372.7623, train_loss: -49.53209686, val_loss: -52.98388290\n",
      "Epoch: [90] [ 420/ 548] time: 1373.0175, train_loss: -47.03346252, val_loss: -53.17601776\n",
      "Epoch: [90] [ 430/ 548] time: 1373.2822, train_loss: -52.63244629, val_loss: -56.46998596\n",
      "Epoch: [90] [ 440/ 548] time: 1373.5568, train_loss: -53.01131439, val_loss: -56.54174423\n",
      "Epoch: [90] [ 450/ 548] time: 1373.8050, train_loss: -55.71308136, val_loss: -54.82530975\n",
      "Epoch: [90] [ 460/ 548] time: 1374.0622, train_loss: -54.20609283, val_loss: -47.45278931\n",
      "Epoch: [90] [ 470/ 548] time: 1374.3294, train_loss: -38.22174072, val_loss: -44.00339890\n",
      "Epoch: [90] [ 480/ 548] time: 1374.6051, train_loss: -44.17977905, val_loss: -40.98854065\n",
      "Epoch: [90] [ 490/ 548] time: 1374.8793, train_loss: -35.29425812, val_loss: -41.18093109\n",
      "Epoch: [90] [ 500/ 548] time: 1375.1428, train_loss: -48.18596649, val_loss: -45.65015411\n",
      "Epoch: [90] [ 510/ 548] time: 1375.3932, train_loss: -47.35253143, val_loss: -46.78726959\n",
      "Epoch: [90] [ 520/ 548] time: 1375.6359, train_loss: -47.70553207, val_loss: -47.42865753\n",
      "Epoch: [90] [ 530/ 548] time: 1375.8721, train_loss: -56.51334381, val_loss: -49.49901581\n",
      "Epoch: [90] [ 540/ 548] time: 1376.1051, train_loss: -53.22341156, val_loss: -53.93971252\n",
      "Epoch: [91] [   0/ 548] time: 1376.2944, train_loss: -50.23208618, val_loss: -51.78260422\n",
      "Epoch: [91] [  10/ 548] time: 1376.5461, train_loss: -58.20549393, val_loss: -56.19052124\n",
      "Epoch: [91] [  20/ 548] time: 1376.7799, train_loss: -54.43545151, val_loss: -55.69794464\n",
      "Epoch: [91] [  30/ 548] time: 1377.0151, train_loss: -59.04706573, val_loss: -57.17176819\n",
      "Epoch: [91] [  40/ 548] time: 1377.2539, train_loss: -59.03048706, val_loss: -56.09828949\n",
      "Epoch: [91] [  50/ 548] time: 1377.4927, train_loss: -54.16204453, val_loss: -54.99707794\n",
      "Epoch: [91] [  60/ 548] time: 1377.7420, train_loss: -41.54965973, val_loss: -55.78012085\n",
      "Epoch: [91] [  70/ 548] time: 1377.9867, train_loss: -58.90238190, val_loss: -56.09818268\n",
      "Epoch: [91] [  80/ 548] time: 1378.2331, train_loss: -50.26976395, val_loss: -55.33723450\n",
      "Epoch: [91] [  90/ 548] time: 1378.4824, train_loss: -55.91132736, val_loss: -55.38649750\n",
      "Epoch: [91] [ 100/ 548] time: 1378.7233, train_loss: -52.31861877, val_loss: -55.40589523\n",
      "Epoch: [91] [ 110/ 548] time: 1378.9656, train_loss: -51.08707809, val_loss: -56.23947525\n",
      "Epoch: [91] [ 120/ 548] time: 1379.2163, train_loss: -49.98181915, val_loss: -57.35389328\n",
      "Epoch: [91] [ 130/ 548] time: 1379.4778, train_loss: -55.50922394, val_loss: -56.21665955\n",
      "Saving checkpoint\n",
      "Epoch: [91] [ 140/ 548] time: 1380.7391, train_loss: -54.25730896, val_loss: -57.03694534\n",
      "Epoch: [91] [ 150/ 548] time: 1380.9836, train_loss: -45.81707764, val_loss: -56.27835083\n",
      "Epoch: [91] [ 160/ 548] time: 1381.2208, train_loss: -56.69349289, val_loss: -56.95732117\n",
      "Epoch: [91] [ 170/ 548] time: 1381.4482, train_loss: -44.39896011, val_loss: -57.00572205\n",
      "Epoch: [91] [ 180/ 548] time: 1381.6798, train_loss: -56.98656845, val_loss: -56.42779541\n",
      "Epoch: [91] [ 190/ 548] time: 1381.9123, train_loss: -52.95915222, val_loss: -55.91943359\n",
      "Epoch: [91] [ 200/ 548] time: 1382.1740, train_loss: -54.03641510, val_loss: -57.75451279\n",
      "Epoch: [91] [ 210/ 548] time: 1382.4196, train_loss: -60.16218567, val_loss: -55.68763733\n",
      "Epoch: [91] [ 220/ 548] time: 1382.6695, train_loss: -54.33660507, val_loss: -56.34135437\n",
      "Epoch: [91] [ 230/ 548] time: 1382.9177, train_loss: -56.47299194, val_loss: -57.50035858\n",
      "Epoch: [91] [ 240/ 548] time: 1383.1681, train_loss: -52.20470428, val_loss: -57.02530670\n",
      "Epoch: [91] [ 250/ 548] time: 1383.4155, train_loss: -39.49791336, val_loss: -56.29855347\n",
      "Epoch: [91] [ 260/ 548] time: 1383.6688, train_loss: -60.18500519, val_loss: -56.98646545\n",
      "Epoch: [91] [ 270/ 548] time: 1383.9147, train_loss: -55.84779358, val_loss: -55.60694122\n",
      "Epoch: [91] [ 280/ 548] time: 1384.1641, train_loss: -56.65761566, val_loss: -50.08118439\n",
      "Epoch: [91] [ 290/ 548] time: 1384.4080, train_loss: -56.73509598, val_loss: -56.99084473\n",
      "Epoch: [91] [ 300/ 548] time: 1384.6514, train_loss: -51.88106918, val_loss: -56.34281921\n",
      "Epoch: [91] [ 310/ 548] time: 1384.8953, train_loss: -53.46075058, val_loss: -54.16914368\n",
      "Epoch: [91] [ 320/ 548] time: 1385.1385, train_loss: -57.24711227, val_loss: -54.28139114\n",
      "Epoch: [91] [ 330/ 548] time: 1385.3949, train_loss: -57.65394974, val_loss: -53.34421539\n",
      "Epoch: [91] [ 340/ 548] time: 1385.6785, train_loss: -52.12548828, val_loss: -51.57704926\n",
      "Epoch: [91] [ 350/ 548] time: 1385.9540, train_loss: -50.19751358, val_loss: -45.70507812\n",
      "Epoch: [91] [ 360/ 548] time: 1386.2285, train_loss: -47.94494629, val_loss: -53.70661926\n",
      "Epoch: [91] [ 370/ 548] time: 1386.4909, train_loss: -47.33574677, val_loss: -48.34895325\n",
      "Epoch: [91] [ 380/ 548] time: 1386.7373, train_loss: -49.20649719, val_loss: -47.40567017\n",
      "Epoch: [91] [ 390/ 548] time: 1386.9818, train_loss: -48.40886307, val_loss: -39.10456085\n",
      "Epoch: [91] [ 400/ 548] time: 1387.2272, train_loss: -43.37596893, val_loss: 0.64013290\n",
      "Epoch: [91] [ 410/ 548] time: 1387.4814, train_loss: -42.45519638, val_loss: -37.00156021\n",
      "Epoch: [91] [ 420/ 548] time: 1387.7299, train_loss: -49.15025711, val_loss: -45.47658539\n",
      "Epoch: [91] [ 430/ 548] time: 1387.9786, train_loss: -25.54593277, val_loss: -48.58081818\n",
      "Epoch: [91] [ 440/ 548] time: 1388.2195, train_loss: -43.33167648, val_loss: -49.48707581\n",
      "Epoch: [91] [ 450/ 548] time: 1388.4565, train_loss: -45.71170425, val_loss: -50.68037415\n",
      "Epoch: [91] [ 460/ 548] time: 1388.6968, train_loss: -58.10861588, val_loss: -53.69446564\n",
      "Epoch: [91] [ 470/ 548] time: 1388.9371, train_loss: -51.29615784, val_loss: -50.96392441\n",
      "Epoch: [91] [ 480/ 548] time: 1389.1782, train_loss: -37.61398315, val_loss: -51.38932800\n",
      "Epoch: [91] [ 490/ 548] time: 1389.4192, train_loss: -49.22655487, val_loss: -48.21575165\n",
      "Epoch: [91] [ 500/ 548] time: 1389.6610, train_loss: -47.49449539, val_loss: -51.81722260\n",
      "Epoch: [91] [ 510/ 548] time: 1389.9015, train_loss: -44.48082352, val_loss: -49.24081421\n",
      "Epoch: [91] [ 520/ 548] time: 1390.1421, train_loss: -54.97862244, val_loss: -52.18745041\n",
      "Epoch: [91] [ 530/ 548] time: 1390.3827, train_loss: -56.72291183, val_loss: -51.43168259\n",
      "Epoch: [91] [ 540/ 548] time: 1390.6198, train_loss: -49.77730179, val_loss: -53.74815750\n",
      "Epoch: [92] [   0/ 548] time: 1390.8078, train_loss: -54.18494034, val_loss: -53.94687271\n",
      "Epoch: [92] [  10/ 548] time: 1391.0503, train_loss: -54.68833160, val_loss: -54.58941650\n",
      "Epoch: [92] [  20/ 548] time: 1391.3016, train_loss: -53.88318634, val_loss: -52.11344147\n",
      "Epoch: [92] [  30/ 548] time: 1391.5508, train_loss: -55.08779907, val_loss: -53.05665970\n",
      "Epoch: [92] [  40/ 548] time: 1391.8121, train_loss: -56.66206360, val_loss: -53.98604202\n",
      "Epoch: [92] [  50/ 548] time: 1392.0893, train_loss: -48.84613037, val_loss: -55.16255951\n",
      "Epoch: [92] [  60/ 548] time: 1392.3640, train_loss: -41.11654663, val_loss: -55.96973801\n",
      "Epoch: [92] [  70/ 548] time: 1392.6358, train_loss: -54.66561127, val_loss: -55.73840332\n",
      "Epoch: [92] [  80/ 548] time: 1392.8904, train_loss: -55.66379929, val_loss: -54.98752975\n",
      "Epoch: [92] [  90/ 548] time: 1393.1437, train_loss: -53.93053436, val_loss: -56.35800171\n",
      "Epoch: [92] [ 100/ 548] time: 1393.3885, train_loss: -59.10122681, val_loss: -56.56264877\n",
      "Epoch: [92] [ 110/ 548] time: 1393.6373, train_loss: -54.56580353, val_loss: -56.96154785\n",
      "Epoch: [92] [ 120/ 548] time: 1393.8868, train_loss: -59.31417847, val_loss: -56.42171097\n",
      "Epoch: [92] [ 130/ 548] time: 1394.1437, train_loss: -59.02164078, val_loss: -56.97190094\n",
      "Epoch: [92] [ 140/ 548] time: 1394.3961, train_loss: -58.99564362, val_loss: -57.19145584\n",
      "Epoch: [92] [ 150/ 548] time: 1394.6526, train_loss: -43.44345856, val_loss: -55.11573029\n",
      "Epoch: [92] [ 160/ 548] time: 1394.9054, train_loss: -58.79246902, val_loss: -56.51933670\n",
      "Epoch: [92] [ 170/ 548] time: 1395.1641, train_loss: -53.31358337, val_loss: -56.90578461\n",
      "Epoch: [92] [ 180/ 548] time: 1395.4181, train_loss: -57.26014709, val_loss: -57.72428513\n",
      "Epoch: [92] [ 190/ 548] time: 1395.6697, train_loss: -46.54767990, val_loss: -57.00641632\n",
      "Epoch: [92] [ 200/ 548] time: 1395.9155, train_loss: -56.69530869, val_loss: -53.68651962\n",
      "Epoch: [92] [ 210/ 548] time: 1396.1652, train_loss: -57.83001709, val_loss: -54.51106644\n",
      "Epoch: [92] [ 220/ 548] time: 1396.4154, train_loss: -50.76185226, val_loss: -55.50449753\n",
      "Epoch: [92] [ 230/ 548] time: 1396.6644, train_loss: -53.18989563, val_loss: -55.82923126\n",
      "Epoch: [92] [ 240/ 548] time: 1396.9087, train_loss: -58.77297211, val_loss: -56.25658417\n",
      "Epoch: [92] [ 250/ 548] time: 1397.1688, train_loss: -53.76669312, val_loss: -55.75728989\n",
      "Epoch: [92] [ 260/ 548] time: 1397.4230, train_loss: -36.14681625, val_loss: -54.47675323\n",
      "Epoch: [92] [ 270/ 548] time: 1397.7009, train_loss: -51.83859253, val_loss: -56.37583160\n",
      "Epoch: [92] [ 280/ 548] time: 1397.9555, train_loss: -55.77713776, val_loss: -56.64409256\n",
      "Epoch: [92] [ 290/ 548] time: 1398.2123, train_loss: -58.00558853, val_loss: -56.34167099\n",
      "Epoch: [92] [ 300/ 548] time: 1398.4902, train_loss: -50.69245529, val_loss: -54.44843292\n",
      "Epoch: [92] [ 310/ 548] time: 1398.7438, train_loss: -49.82487106, val_loss: -55.83421326\n",
      "Epoch: [92] [ 320/ 548] time: 1398.9932, train_loss: -56.19791412, val_loss: -53.58792114\n",
      "Epoch: [92] [ 330/ 548] time: 1399.2419, train_loss: -57.61610794, val_loss: -55.62068558\n",
      "Epoch: [92] [ 340/ 548] time: 1399.4877, train_loss: -54.36552429, val_loss: -53.52172089\n",
      "Epoch: [92] [ 350/ 548] time: 1399.7317, train_loss: -55.95522690, val_loss: -54.87213898\n",
      "Epoch: [92] [ 360/ 548] time: 1399.9841, train_loss: -56.74863434, val_loss: -55.59699631\n",
      "Epoch: [92] [ 370/ 548] time: 1400.2392, train_loss: -55.13750839, val_loss: -54.88657379\n",
      "Epoch: [92] [ 380/ 548] time: 1400.4943, train_loss: -54.22580719, val_loss: -56.11767578\n",
      "Epoch: [92] [ 390/ 548] time: 1400.7428, train_loss: -49.06501007, val_loss: -55.07719803\n",
      "Epoch: [92] [ 400/ 548] time: 1400.9908, train_loss: -53.84346771, val_loss: -53.70392609\n",
      "Epoch: [92] [ 410/ 548] time: 1401.2471, train_loss: -51.86477280, val_loss: -54.74448395\n",
      "Epoch: [92] [ 420/ 548] time: 1401.5009, train_loss: -60.42384720, val_loss: -56.51156616\n",
      "Epoch: [92] [ 430/ 548] time: 1401.7805, train_loss: -53.93311691, val_loss: -56.52053070\n",
      "Epoch: [92] [ 440/ 548] time: 1402.0308, train_loss: -59.85515213, val_loss: -56.30057907\n",
      "Epoch: [92] [ 450/ 548] time: 1402.2802, train_loss: -54.28018188, val_loss: -54.84620667\n",
      "Epoch: [92] [ 460/ 548] time: 1402.5275, train_loss: -55.57385635, val_loss: -55.63942719\n",
      "Epoch: [92] [ 470/ 548] time: 1402.7741, train_loss: -52.15537262, val_loss: -56.00480652\n",
      "Epoch: [92] [ 480/ 548] time: 1403.0114, train_loss: -47.83733368, val_loss: -55.97490692\n",
      "Epoch: [92] [ 490/ 548] time: 1403.2501, train_loss: -50.97727203, val_loss: -55.69853210\n",
      "Epoch: [92] [ 500/ 548] time: 1403.4865, train_loss: -56.02861786, val_loss: -56.43415451\n",
      "Epoch: [92] [ 510/ 548] time: 1403.7322, train_loss: -54.93370056, val_loss: -56.55009460\n",
      "Epoch: [92] [ 520/ 548] time: 1404.0048, train_loss: -56.93584061, val_loss: -55.50275803\n",
      "Epoch: [92] [ 530/ 548] time: 1404.2720, train_loss: -56.52732086, val_loss: -56.75205612\n",
      "Epoch: [92] [ 540/ 548] time: 1404.5707, train_loss: -51.07421112, val_loss: -56.15333176\n",
      "Epoch: [93] [   0/ 548] time: 1404.8011, train_loss: -55.48801804, val_loss: -56.13241959\n",
      "Epoch: [93] [  10/ 548] time: 1405.0757, train_loss: -48.07949829, val_loss: -56.32468033\n",
      "Epoch: [93] [  20/ 548] time: 1405.3487, train_loss: -53.52452087, val_loss: -56.63417053\n",
      "Epoch: [93] [  30/ 548] time: 1405.6242, train_loss: -51.67231750, val_loss: -56.39667511\n",
      "Saving checkpoint\n",
      "Epoch: [93] [  40/ 548] time: 1407.4097, train_loss: -54.22581100, val_loss: -56.34574127\n",
      "Epoch: [93] [  50/ 548] time: 1407.7786, train_loss: -52.44579315, val_loss: -55.75951385\n",
      "Epoch: [93] [  60/ 548] time: 1408.1402, train_loss: -50.41711426, val_loss: -56.27199173\n",
      "Epoch: [93] [  70/ 548] time: 1408.4876, train_loss: -57.84661102, val_loss: -50.16290665\n",
      "Epoch: [93] [  80/ 548] time: 1408.7878, train_loss: -28.66992188, val_loss: -54.57234955\n",
      "Epoch: [93] [  90/ 548] time: 1409.0751, train_loss: -52.85234451, val_loss: -45.90222931\n",
      "Epoch: [93] [ 100/ 548] time: 1409.3809, train_loss: -30.85639572, val_loss: -41.30313110\n",
      "Epoch: [93] [ 110/ 548] time: 1409.6539, train_loss: -50.35183716, val_loss: -52.20327377\n",
      "Epoch: [93] [ 120/ 548] time: 1409.9259, train_loss: -55.74171066, val_loss: -53.93163300\n",
      "Epoch: [93] [ 130/ 548] time: 1410.2242, train_loss: -52.39373016, val_loss: -55.69433975\n",
      "Epoch: [93] [ 140/ 548] time: 1410.6065, train_loss: -56.66201019, val_loss: -55.93999481\n",
      "Epoch: [93] [ 150/ 548] time: 1410.9750, train_loss: -47.96084213, val_loss: -56.26824188\n",
      "Epoch: [93] [ 160/ 548] time: 1411.3104, train_loss: -57.54410934, val_loss: -53.49984741\n",
      "Epoch: [93] [ 170/ 548] time: 1411.6380, train_loss: -49.08388519, val_loss: -54.81040955\n",
      "Epoch: [93] [ 180/ 548] time: 1411.9704, train_loss: -57.93301392, val_loss: -52.89904022\n",
      "Epoch: [93] [ 190/ 548] time: 1412.3449, train_loss: -55.08393097, val_loss: -56.96037292\n",
      "Epoch: [93] [ 200/ 548] time: 1412.6764, train_loss: -53.09005737, val_loss: -56.50299454\n",
      "Epoch: [93] [ 210/ 548] time: 1413.0223, train_loss: -55.76884460, val_loss: -57.02866745\n",
      "Epoch: [93] [ 220/ 548] time: 1413.3590, train_loss: -56.18231583, val_loss: -57.25973892\n",
      "Epoch: [93] [ 230/ 548] time: 1413.6375, train_loss: -54.90269470, val_loss: -57.00091934\n",
      "Epoch: [93] [ 240/ 548] time: 1413.9076, train_loss: -55.10214996, val_loss: -57.31389236\n",
      "Epoch: [93] [ 250/ 548] time: 1414.1762, train_loss: -58.07418823, val_loss: -57.76399231\n",
      "Epoch: [93] [ 260/ 548] time: 1414.4295, train_loss: -60.43787384, val_loss: -57.64142609\n",
      "Epoch: [93] [ 270/ 548] time: 1414.6768, train_loss: -60.52030945, val_loss: -58.04304123\n",
      "Epoch: [93] [ 280/ 548] time: 1414.9082, train_loss: -60.17492294, val_loss: -56.87796021\n",
      "Epoch: [93] [ 290/ 548] time: 1415.1418, train_loss: -55.02214432, val_loss: -56.36618805\n",
      "Epoch: [93] [ 300/ 548] time: 1415.4001, train_loss: -59.94623566, val_loss: -56.92292023\n",
      "Epoch: [93] [ 310/ 548] time: 1415.6562, train_loss: -55.12683868, val_loss: -57.72446823\n",
      "Epoch: [93] [ 320/ 548] time: 1415.9049, train_loss: -57.05934906, val_loss: -57.51984406\n",
      "Epoch: [93] [ 330/ 548] time: 1416.1647, train_loss: -52.62872696, val_loss: -56.57695007\n",
      "Epoch: [93] [ 340/ 548] time: 1416.4275, train_loss: -48.80332184, val_loss: -57.79301453\n",
      "Epoch: [93] [ 350/ 548] time: 1416.7021, train_loss: -58.57550812, val_loss: -57.33695984\n",
      "Epoch: [93] [ 360/ 548] time: 1416.9714, train_loss: -51.26248169, val_loss: -56.87241745\n",
      "Epoch: [93] [ 370/ 548] time: 1417.2434, train_loss: -46.84103394, val_loss: -56.59924316\n",
      "Epoch: [93] [ 380/ 548] time: 1417.5177, train_loss: -56.18180084, val_loss: -55.92677307\n",
      "Epoch: [93] [ 390/ 548] time: 1417.7946, train_loss: -59.07401657, val_loss: -55.89683151\n",
      "Epoch: [93] [ 400/ 548] time: 1418.0405, train_loss: -58.00371933, val_loss: -56.71603775\n",
      "Epoch: [93] [ 410/ 548] time: 1418.2855, train_loss: -55.79308701, val_loss: -56.82529068\n",
      "Epoch: [93] [ 420/ 548] time: 1418.5467, train_loss: -56.39706039, val_loss: -56.29124832\n",
      "Epoch: [93] [ 430/ 548] time: 1418.8060, train_loss: -51.80519867, val_loss: -56.99299622\n",
      "Epoch: [93] [ 440/ 548] time: 1419.0672, train_loss: -60.14677429, val_loss: -56.37678528\n",
      "Epoch: [93] [ 450/ 548] time: 1419.3205, train_loss: -53.48167419, val_loss: -57.16698456\n",
      "Epoch: [93] [ 460/ 548] time: 1419.5729, train_loss: -59.00043106, val_loss: -57.24166107\n",
      "Epoch: [93] [ 470/ 548] time: 1419.8259, train_loss: -60.17462158, val_loss: -57.49678040\n",
      "Epoch: [93] [ 480/ 548] time: 1420.0778, train_loss: -58.65320206, val_loss: -56.99176025\n",
      "Epoch: [93] [ 490/ 548] time: 1420.3379, train_loss: -53.86772919, val_loss: -57.18018341\n",
      "Epoch: [93] [ 500/ 548] time: 1420.6114, train_loss: -58.55904770, val_loss: -57.22015762\n",
      "Epoch: [93] [ 510/ 548] time: 1420.8609, train_loss: -55.97748566, val_loss: -57.65741730\n",
      "Epoch: [93] [ 520/ 548] time: 1421.1310, train_loss: -55.34199524, val_loss: -57.98874664\n",
      "Epoch: [93] [ 530/ 548] time: 1421.3930, train_loss: -59.45604324, val_loss: -57.59597778\n",
      "Epoch: [93] [ 540/ 548] time: 1421.6503, train_loss: -58.17560577, val_loss: -57.65329361\n",
      "Epoch: [94] [   0/ 548] time: 1421.8591, train_loss: -54.11829376, val_loss: -57.65332413\n",
      "Epoch: [94] [  10/ 548] time: 1422.1198, train_loss: -52.74288559, val_loss: -57.33061981\n",
      "Epoch: [94] [  20/ 548] time: 1422.3915, train_loss: -60.46144485, val_loss: -54.27307892\n",
      "Epoch: [94] [  30/ 548] time: 1422.6490, train_loss: -50.63228607, val_loss: -55.79601669\n",
      "Epoch: [94] [  40/ 548] time: 1422.8907, train_loss: -55.72603226, val_loss: -57.12942886\n",
      "Epoch: [94] [  50/ 548] time: 1423.1277, train_loss: -54.74449158, val_loss: -57.29381561\n",
      "Epoch: [94] [  60/ 548] time: 1423.3814, train_loss: -57.02627563, val_loss: -56.96354675\n",
      "Epoch: [94] [  70/ 548] time: 1423.6367, train_loss: -51.97830582, val_loss: -56.24296188\n",
      "Epoch: [94] [  80/ 548] time: 1423.8872, train_loss: -44.93622971, val_loss: -51.72893143\n",
      "Epoch: [94] [  90/ 548] time: 1424.1454, train_loss: -53.73582840, val_loss: -52.02005005\n",
      "Epoch: [94] [ 100/ 548] time: 1424.3922, train_loss: -53.87381744, val_loss: -55.35157394\n",
      "Epoch: [94] [ 110/ 548] time: 1424.6703, train_loss: -45.94869232, val_loss: -54.57875061\n",
      "Epoch: [94] [ 120/ 548] time: 1424.9396, train_loss: -50.61316681, val_loss: -56.00373077\n",
      "Epoch: [94] [ 130/ 548] time: 1425.1842, train_loss: -56.29366684, val_loss: -56.35559464\n",
      "Epoch: [94] [ 140/ 548] time: 1425.4350, train_loss: -58.69134521, val_loss: -54.85541534\n",
      "Epoch: [94] [ 150/ 548] time: 1425.6740, train_loss: -53.18209076, val_loss: -54.70711517\n",
      "Epoch: [94] [ 160/ 548] time: 1425.9108, train_loss: -53.94285965, val_loss: -50.01116943\n",
      "Epoch: [94] [ 170/ 548] time: 1426.1626, train_loss: -49.65376282, val_loss: -53.63719177\n",
      "Epoch: [94] [ 180/ 548] time: 1426.4228, train_loss: -36.61052322, val_loss: -53.69617462\n",
      "Epoch: [94] [ 190/ 548] time: 1426.6912, train_loss: -57.95167160, val_loss: -50.79743195\n",
      "Epoch: [94] [ 200/ 548] time: 1426.9602, train_loss: -42.35588074, val_loss: -48.39741898\n",
      "Epoch: [94] [ 210/ 548] time: 1427.2775, train_loss: -55.37075043, val_loss: -53.29070282\n",
      "Epoch: [94] [ 220/ 548] time: 1427.6217, train_loss: -56.83047867, val_loss: -53.86114883\n",
      "Epoch: [94] [ 230/ 548] time: 1428.0030, train_loss: -58.01996613, val_loss: -51.09138489\n",
      "Epoch: [94] [ 240/ 548] time: 1428.3746, train_loss: -53.55849075, val_loss: -51.06997681\n",
      "Epoch: [94] [ 250/ 548] time: 1428.7361, train_loss: -44.87623978, val_loss: -52.18934631\n",
      "Epoch: [94] [ 260/ 548] time: 1429.1183, train_loss: -45.02655029, val_loss: -32.39357758\n",
      "Epoch: [94] [ 270/ 548] time: 1429.4798, train_loss: -46.53060532, val_loss: -48.38928223\n",
      "Epoch: [94] [ 280/ 548] time: 1429.8308, train_loss: -47.93507385, val_loss: -51.75403595\n",
      "Epoch: [94] [ 290/ 548] time: 1430.1541, train_loss: -48.59295654, val_loss: -53.82184601\n",
      "Epoch: [94] [ 300/ 548] time: 1430.4621, train_loss: -60.96483994, val_loss: -55.39443207\n",
      "Epoch: [94] [ 310/ 548] time: 1430.7346, train_loss: -52.63296509, val_loss: -55.93047333\n",
      "Epoch: [94] [ 320/ 548] time: 1431.0153, train_loss: -57.87586212, val_loss: -56.13888931\n",
      "Epoch: [94] [ 330/ 548] time: 1431.3610, train_loss: -51.15477371, val_loss: -56.11348724\n",
      "Epoch: [94] [ 340/ 548] time: 1431.7181, train_loss: -53.50666428, val_loss: -56.17065430\n",
      "Epoch: [94] [ 350/ 548] time: 1432.0776, train_loss: -56.23106384, val_loss: -56.12152481\n",
      "Epoch: [94] [ 360/ 548] time: 1432.3626, train_loss: -55.20211029, val_loss: -56.83517838\n",
      "Epoch: [94] [ 370/ 548] time: 1432.6447, train_loss: -56.22886276, val_loss: -57.21332932\n",
      "Epoch: [94] [ 380/ 548] time: 1432.9672, train_loss: -54.11795807, val_loss: -56.85528183\n",
      "Epoch: [94] [ 390/ 548] time: 1433.3006, train_loss: -57.31646729, val_loss: -56.51801300\n",
      "Epoch: [94] [ 400/ 548] time: 1433.6296, train_loss: -54.98050690, val_loss: -55.98761749\n",
      "Epoch: [94] [ 410/ 548] time: 1433.9797, train_loss: -53.16438293, val_loss: -56.50250626\n",
      "Epoch: [94] [ 420/ 548] time: 1434.3220, train_loss: -52.65899277, val_loss: -55.76307678\n",
      "Epoch: [94] [ 430/ 548] time: 1434.6269, train_loss: -56.35039520, val_loss: -56.66101074\n",
      "Epoch: [94] [ 440/ 548] time: 1434.9306, train_loss: -52.12503052, val_loss: -55.59142685\n",
      "Epoch: [94] [ 450/ 548] time: 1435.2509, train_loss: -54.08870697, val_loss: -56.96883774\n",
      "Epoch: [94] [ 460/ 548] time: 1435.5495, train_loss: -54.52922440, val_loss: -57.61331558\n",
      "Epoch: [94] [ 470/ 548] time: 1435.8098, train_loss: -51.94726181, val_loss: -57.62817383\n",
      "Epoch: [94] [ 480/ 548] time: 1436.0526, train_loss: -54.15287018, val_loss: -56.28744888\n",
      "Saving checkpoint\n",
      "Epoch: [94] [ 490/ 548] time: 1437.3552, train_loss: -50.92620468, val_loss: -56.98516464\n",
      "Epoch: [94] [ 500/ 548] time: 1437.6007, train_loss: -56.09438324, val_loss: -56.74337387\n",
      "Epoch: [94] [ 510/ 548] time: 1437.8597, train_loss: -58.91451263, val_loss: -57.45671844\n",
      "Epoch: [94] [ 520/ 548] time: 1438.0856, train_loss: -58.97187042, val_loss: -57.15398788\n",
      "Epoch: [94] [ 530/ 548] time: 1438.3179, train_loss: -58.01957703, val_loss: -57.34709549\n",
      "Epoch: [94] [ 540/ 548] time: 1438.5463, train_loss: -56.49667358, val_loss: -57.37627029\n",
      "Epoch: [95] [   0/ 548] time: 1438.7271, train_loss: -59.78558350, val_loss: -57.11623383\n",
      "Epoch: [95] [  10/ 548] time: 1438.9825, train_loss: -60.92004395, val_loss: -56.51334763\n",
      "Epoch: [95] [  20/ 548] time: 1439.2103, train_loss: -60.46715164, val_loss: -57.81438446\n",
      "Epoch: [95] [  30/ 548] time: 1439.4393, train_loss: -58.82839203, val_loss: -57.40017700\n",
      "Epoch: [95] [  40/ 548] time: 1439.6633, train_loss: -55.41713715, val_loss: -57.60231400\n",
      "Epoch: [95] [  50/ 548] time: 1439.8957, train_loss: -58.42742538, val_loss: -57.36647034\n",
      "Epoch: [95] [  60/ 548] time: 1440.1340, train_loss: -54.37876892, val_loss: -56.10096359\n",
      "Epoch: [95] [  70/ 548] time: 1440.3998, train_loss: -55.92826080, val_loss: -57.74555206\n",
      "Epoch: [95] [  80/ 548] time: 1440.6671, train_loss: -50.46458817, val_loss: -57.02708054\n",
      "Epoch: [95] [  90/ 548] time: 1440.9485, train_loss: -55.44711685, val_loss: -56.92906952\n",
      "Epoch: [95] [ 100/ 548] time: 1441.2246, train_loss: -53.23324966, val_loss: -56.89145279\n",
      "Epoch: [95] [ 110/ 548] time: 1441.5273, train_loss: -60.24012375, val_loss: -57.38861847\n",
      "Epoch: [95] [ 120/ 548] time: 1441.8014, train_loss: -57.29327011, val_loss: -56.04508972\n",
      "Epoch: [95] [ 130/ 548] time: 1442.0883, train_loss: -51.66757965, val_loss: -55.66260147\n",
      "Epoch: [95] [ 140/ 548] time: 1442.3913, train_loss: -58.90263367, val_loss: -54.89192963\n",
      "Epoch: [95] [ 150/ 548] time: 1442.6586, train_loss: -59.27039337, val_loss: -57.25752640\n",
      "Epoch: [95] [ 160/ 548] time: 1442.9327, train_loss: -51.91339874, val_loss: -55.34789276\n",
      "Epoch: [95] [ 170/ 548] time: 1443.2169, train_loss: -48.26845169, val_loss: -54.53223801\n",
      "Epoch: [95] [ 180/ 548] time: 1443.5165, train_loss: -59.37514877, val_loss: -56.32991409\n",
      "Epoch: [95] [ 190/ 548] time: 1443.7848, train_loss: -53.18691254, val_loss: -56.42369843\n",
      "Epoch: [95] [ 200/ 548] time: 1444.0466, train_loss: -55.36820221, val_loss: -57.48954391\n",
      "Epoch: [95] [ 210/ 548] time: 1444.3025, train_loss: -60.48957443, val_loss: -57.99317551\n",
      "Epoch: [95] [ 220/ 548] time: 1444.5607, train_loss: -57.73374176, val_loss: -57.71861267\n",
      "Epoch: [95] [ 230/ 548] time: 1444.8094, train_loss: -60.75829315, val_loss: -57.49356079\n",
      "Epoch: [95] [ 240/ 548] time: 1445.0535, train_loss: -56.87310410, val_loss: -57.81414795\n",
      "Epoch: [95] [ 250/ 548] time: 1445.2914, train_loss: -44.77996445, val_loss: -56.85069656\n",
      "Epoch: [95] [ 260/ 548] time: 1445.5677, train_loss: -54.36604691, val_loss: -54.36272430\n",
      "Epoch: [95] [ 270/ 548] time: 1445.8068, train_loss: -52.87948608, val_loss: -53.36439133\n",
      "Epoch: [95] [ 280/ 548] time: 1446.0523, train_loss: -43.80171204, val_loss: -31.17983246\n",
      "Epoch: [95] [ 290/ 548] time: 1446.2963, train_loss: -48.66760635, val_loss: -49.72105026\n",
      "Epoch: [95] [ 300/ 548] time: 1446.5455, train_loss: -49.27965927, val_loss: -46.74450684\n",
      "Epoch: [95] [ 310/ 548] time: 1446.8135, train_loss: -37.58885574, val_loss: -41.80250549\n",
      "Epoch: [95] [ 320/ 548] time: 1447.1751, train_loss: -48.18946838, val_loss: -47.52992249\n",
      "Epoch: [95] [ 330/ 548] time: 1447.4607, train_loss: -39.83317566, val_loss: -49.43530273\n",
      "Epoch: [95] [ 340/ 548] time: 1447.7621, train_loss: -49.15872192, val_loss: -52.17375565\n",
      "Epoch: [95] [ 350/ 548] time: 1448.0519, train_loss: -37.67023468, val_loss: -52.55129242\n",
      "Epoch: [95] [ 360/ 548] time: 1448.3128, train_loss: -45.58753204, val_loss: -55.15779877\n",
      "Epoch: [95] [ 370/ 548] time: 1448.5612, train_loss: -53.75467682, val_loss: -54.78345871\n",
      "Epoch: [95] [ 380/ 548] time: 1448.8152, train_loss: -39.74331665, val_loss: -53.62910461\n",
      "Epoch: [95] [ 390/ 548] time: 1449.0746, train_loss: -51.20446014, val_loss: -52.50099945\n",
      "Epoch: [95] [ 400/ 548] time: 1449.3192, train_loss: -56.11572647, val_loss: -48.87219620\n",
      "Epoch: [95] [ 410/ 548] time: 1449.5615, train_loss: -54.18712616, val_loss: -52.84287643\n",
      "Epoch: [95] [ 420/ 548] time: 1449.7964, train_loss: 5.44905853, val_loss: -53.26712418\n",
      "Epoch: [95] [ 430/ 548] time: 1450.0282, train_loss: -58.13835144, val_loss: -51.27232361\n",
      "Epoch: [95] [ 440/ 548] time: 1450.2658, train_loss: -48.48194885, val_loss: -53.04079437\n",
      "Epoch: [95] [ 450/ 548] time: 1450.5012, train_loss: -49.68068314, val_loss: -54.45880890\n",
      "Epoch: [95] [ 460/ 548] time: 1450.7326, train_loss: -35.07222748, val_loss: -54.49780273\n",
      "Epoch: [95] [ 470/ 548] time: 1450.9656, train_loss: -50.76144409, val_loss: -48.68125534\n",
      "Epoch: [95] [ 480/ 548] time: 1451.2018, train_loss: -47.07931137, val_loss: -43.10965729\n",
      "Epoch: [95] [ 490/ 548] time: 1451.4376, train_loss: -54.94399261, val_loss: -53.33596802\n",
      "Epoch: [95] [ 500/ 548] time: 1451.6746, train_loss: -57.54071808, val_loss: -53.67085648\n",
      "Epoch: [95] [ 510/ 548] time: 1451.9042, train_loss: -45.91912079, val_loss: -55.74440765\n",
      "Epoch: [95] [ 520/ 548] time: 1452.1365, train_loss: -53.89896393, val_loss: -55.47325134\n",
      "Epoch: [95] [ 530/ 548] time: 1452.3721, train_loss: -53.14445496, val_loss: -54.80971527\n",
      "Epoch: [95] [ 540/ 548] time: 1452.6102, train_loss: -55.92456055, val_loss: -56.16082382\n",
      "Epoch: [96] [   0/ 548] time: 1452.8090, train_loss: -53.18395996, val_loss: -56.01054001\n",
      "Epoch: [96] [  10/ 548] time: 1453.0492, train_loss: -47.66812134, val_loss: -56.61242294\n",
      "Epoch: [96] [  20/ 548] time: 1453.3026, train_loss: -56.37577057, val_loss: -56.38274765\n",
      "Epoch: [96] [  30/ 548] time: 1453.5723, train_loss: -55.58032608, val_loss: -56.59252548\n",
      "Epoch: [96] [  40/ 548] time: 1453.8453, train_loss: -56.98462677, val_loss: -56.10145569\n",
      "Epoch: [96] [  50/ 548] time: 1454.0994, train_loss: -46.16464996, val_loss: -56.18721771\n",
      "Epoch: [96] [  60/ 548] time: 1454.3597, train_loss: -58.63482666, val_loss: -55.76216125\n",
      "Epoch: [96] [  70/ 548] time: 1454.5973, train_loss: -56.96762848, val_loss: -56.41067123\n",
      "Epoch: [96] [  80/ 548] time: 1454.8355, train_loss: -56.78423691, val_loss: -57.41142273\n",
      "Epoch: [96] [  90/ 548] time: 1455.0781, train_loss: -60.60138702, val_loss: -56.75522614\n",
      "Epoch: [96] [ 100/ 548] time: 1455.3163, train_loss: -55.26791382, val_loss: -56.71794128\n",
      "Epoch: [96] [ 110/ 548] time: 1455.5560, train_loss: -53.07169342, val_loss: -56.87220001\n",
      "Epoch: [96] [ 120/ 548] time: 1455.8066, train_loss: -56.40019989, val_loss: -57.11627579\n",
      "Epoch: [96] [ 130/ 548] time: 1456.0540, train_loss: -54.51213837, val_loss: -57.45030594\n",
      "Epoch: [96] [ 140/ 548] time: 1456.3071, train_loss: -58.01388550, val_loss: -57.54420090\n",
      "Epoch: [96] [ 150/ 548] time: 1456.5522, train_loss: -52.28692245, val_loss: -57.33503723\n",
      "Epoch: [96] [ 160/ 548] time: 1456.8140, train_loss: -56.71790695, val_loss: -56.23226929\n",
      "Epoch: [96] [ 170/ 548] time: 1457.0714, train_loss: -59.77550507, val_loss: -57.52091980\n",
      "Epoch: [96] [ 180/ 548] time: 1457.3222, train_loss: -52.28304291, val_loss: -56.49220657\n",
      "Epoch: [96] [ 190/ 548] time: 1457.5750, train_loss: -42.99058533, val_loss: -57.86519623\n",
      "Epoch: [96] [ 200/ 548] time: 1457.8363, train_loss: -59.14949036, val_loss: -56.56763077\n",
      "Epoch: [96] [ 210/ 548] time: 1458.0941, train_loss: -57.43114090, val_loss: -57.95774460\n",
      "Epoch: [96] [ 220/ 548] time: 1458.3512, train_loss: -57.78981018, val_loss: -57.51852798\n",
      "Epoch: [96] [ 230/ 548] time: 1458.5960, train_loss: -55.91139221, val_loss: -57.90369415\n",
      "Epoch: [96] [ 240/ 548] time: 1458.8543, train_loss: -57.65639496, val_loss: -57.60604477\n",
      "Epoch: [96] [ 250/ 548] time: 1459.1588, train_loss: -59.07819366, val_loss: -58.11560440\n",
      "Epoch: [96] [ 260/ 548] time: 1459.4306, train_loss: -57.55185318, val_loss: -57.29864883\n",
      "Epoch: [96] [ 270/ 548] time: 1459.7500, train_loss: -59.07858658, val_loss: -57.96557236\n",
      "Epoch: [96] [ 280/ 548] time: 1460.0468, train_loss: -55.56984329, val_loss: -57.94254303\n",
      "Epoch: [96] [ 290/ 548] time: 1460.3272, train_loss: -55.45021057, val_loss: -57.51375580\n",
      "Epoch: [96] [ 300/ 548] time: 1460.6112, train_loss: -56.14311981, val_loss: -57.63582993\n",
      "Epoch: [96] [ 310/ 548] time: 1460.8702, train_loss: -54.98416901, val_loss: -57.84192657\n",
      "Epoch: [96] [ 320/ 548] time: 1461.1372, train_loss: -54.95888901, val_loss: -57.85411835\n",
      "Epoch: [96] [ 330/ 548] time: 1461.3936, train_loss: -58.38101959, val_loss: -57.78682327\n",
      "Epoch: [96] [ 340/ 548] time: 1461.6379, train_loss: -59.01616669, val_loss: -57.98695755\n",
      "Epoch: [96] [ 350/ 548] time: 1461.8876, train_loss: -55.73890305, val_loss: -56.91639709\n",
      "Epoch: [96] [ 360/ 548] time: 1462.1480, train_loss: -51.68860626, val_loss: -56.93877411\n",
      "Epoch: [96] [ 370/ 548] time: 1462.4297, train_loss: -58.65635681, val_loss: -57.07695770\n",
      "Epoch: [96] [ 380/ 548] time: 1462.6969, train_loss: -58.53123474, val_loss: -54.81234360\n",
      "Epoch: [96] [ 390/ 548] time: 1462.9824, train_loss: -50.69626617, val_loss: -56.43163681\n",
      "Saving checkpoint\n",
      "Epoch: [96] [ 400/ 548] time: 1464.5726, train_loss: -57.60594940, val_loss: -57.62031937\n",
      "Epoch: [96] [ 410/ 548] time: 1464.8370, train_loss: -55.39517212, val_loss: -57.71580887\n",
      "Epoch: [96] [ 420/ 548] time: 1465.0997, train_loss: -56.29941177, val_loss: -56.83261108\n",
      "Epoch: [96] [ 430/ 548] time: 1465.3303, train_loss: -56.30567551, val_loss: -57.53601074\n",
      "Epoch: [96] [ 440/ 548] time: 1465.5725, train_loss: -60.86463165, val_loss: -56.89196396\n",
      "Epoch: [96] [ 450/ 548] time: 1465.8369, train_loss: -53.63706589, val_loss: -55.28311920\n",
      "Epoch: [96] [ 460/ 548] time: 1466.1151, train_loss: -36.99408722, val_loss: -57.58731461\n",
      "Epoch: [96] [ 470/ 548] time: 1466.4013, train_loss: -37.43122101, val_loss: -55.55270767\n",
      "Epoch: [96] [ 480/ 548] time: 1466.7018, train_loss: -53.23632812, val_loss: -54.16812134\n",
      "Epoch: [96] [ 490/ 548] time: 1466.9804, train_loss: -46.45120621, val_loss: -55.50442505\n",
      "Epoch: [96] [ 500/ 548] time: 1467.2716, train_loss: -53.76097870, val_loss: -47.42623138\n",
      "Epoch: [96] [ 510/ 548] time: 1467.5770, train_loss: -23.78477859, val_loss: -54.82322693\n",
      "Epoch: [96] [ 520/ 548] time: 1467.8525, train_loss: -44.27867126, val_loss: -52.92380524\n",
      "Epoch: [96] [ 530/ 548] time: 1468.1214, train_loss: -39.99556732, val_loss: -37.76053619\n",
      "Epoch: [96] [ 540/ 548] time: 1468.3971, train_loss: -43.30567551, val_loss: -47.03059387\n",
      "Epoch: [97] [   0/ 548] time: 1468.6118, train_loss: -54.98884583, val_loss: -52.46133041\n",
      "Epoch: [97] [  10/ 548] time: 1468.8754, train_loss: -22.84233475, val_loss: -53.03894806\n",
      "Epoch: [97] [  20/ 548] time: 1469.1698, train_loss: -41.10617065, val_loss: -51.28214645\n",
      "Epoch: [97] [  30/ 548] time: 1469.4445, train_loss: -51.10627747, val_loss: -54.35633087\n",
      "Epoch: [97] [  40/ 548] time: 1469.7147, train_loss: -51.07094574, val_loss: -56.03020477\n",
      "Epoch: [97] [  50/ 548] time: 1469.9653, train_loss: -49.68555450, val_loss: -54.50567627\n",
      "Epoch: [97] [  60/ 548] time: 1470.2115, train_loss: -51.51757050, val_loss: -54.53912354\n",
      "Epoch: [97] [  70/ 548] time: 1470.4652, train_loss: -54.79276276, val_loss: -55.92380142\n",
      "Epoch: [97] [  80/ 548] time: 1470.7086, train_loss: -46.38061142, val_loss: -55.94301224\n",
      "Epoch: [97] [  90/ 548] time: 1470.9559, train_loss: -53.92779541, val_loss: -56.50516891\n",
      "Epoch: [97] [ 100/ 548] time: 1471.2405, train_loss: -55.59486008, val_loss: -57.11869431\n",
      "Epoch: [97] [ 110/ 548] time: 1471.5109, train_loss: -59.47920227, val_loss: -56.87366104\n",
      "Epoch: [97] [ 120/ 548] time: 1471.7831, train_loss: -55.22178650, val_loss: -55.76930618\n",
      "Epoch: [97] [ 130/ 548] time: 1472.0711, train_loss: -54.89515686, val_loss: -56.28985214\n",
      "Epoch: [97] [ 140/ 548] time: 1472.3875, train_loss: -58.84561539, val_loss: -55.77471924\n",
      "Epoch: [97] [ 150/ 548] time: 1472.6535, train_loss: -55.98122787, val_loss: -56.56756973\n",
      "Epoch: [97] [ 160/ 548] time: 1472.9616, train_loss: -57.26602173, val_loss: -57.09651184\n",
      "Epoch: [97] [ 170/ 548] time: 1473.2401, train_loss: -58.14617157, val_loss: -57.93345642\n",
      "Epoch: [97] [ 180/ 548] time: 1473.4990, train_loss: -57.61664581, val_loss: -57.93724442\n",
      "Epoch: [97] [ 190/ 548] time: 1473.7575, train_loss: -60.73032379, val_loss: -58.06414795\n",
      "Epoch: [97] [ 200/ 548] time: 1474.0545, train_loss: -57.13196564, val_loss: -57.92515182\n",
      "Epoch: [97] [ 210/ 548] time: 1474.3397, train_loss: -58.57047653, val_loss: -58.48267365\n",
      "Epoch: [97] [ 220/ 548] time: 1474.6179, train_loss: -59.06661224, val_loss: -58.05672073\n",
      "Epoch: [97] [ 230/ 548] time: 1474.8786, train_loss: -54.73925018, val_loss: -57.60031509\n",
      "Epoch: [97] [ 240/ 548] time: 1475.1467, train_loss: -56.62963486, val_loss: -57.18644714\n",
      "Epoch: [97] [ 250/ 548] time: 1475.4928, train_loss: -54.36051559, val_loss: -56.54105377\n",
      "Epoch: [97] [ 260/ 548] time: 1475.7817, train_loss: -57.81673813, val_loss: -56.52318573\n",
      "Epoch: [97] [ 270/ 548] time: 1476.0721, train_loss: -58.82061005, val_loss: -57.22867966\n",
      "Epoch: [97] [ 280/ 548] time: 1476.3764, train_loss: -58.79384995, val_loss: -56.56871033\n",
      "Epoch: [97] [ 290/ 548] time: 1476.6719, train_loss: -45.48421860, val_loss: -55.86525345\n",
      "Epoch: [97] [ 300/ 548] time: 1476.9415, train_loss: -58.08400726, val_loss: -56.70422363\n",
      "Epoch: [97] [ 310/ 548] time: 1477.2033, train_loss: -45.24079132, val_loss: -57.83823395\n",
      "Epoch: [97] [ 320/ 548] time: 1477.4659, train_loss: -48.77828979, val_loss: -57.03641129\n",
      "Epoch: [97] [ 330/ 548] time: 1477.7576, train_loss: -50.43597031, val_loss: -52.05071259\n",
      "Epoch: [97] [ 340/ 548] time: 1478.0510, train_loss: -44.12090683, val_loss: -49.33565521\n",
      "Epoch: [97] [ 350/ 548] time: 1478.3677, train_loss: -50.41033936, val_loss: -50.11479950\n",
      "Epoch: [97] [ 360/ 548] time: 1478.6331, train_loss: -56.83153152, val_loss: -48.76054382\n",
      "Epoch: [97] [ 370/ 548] time: 1478.8843, train_loss: -36.95551300, val_loss: -48.25865555\n",
      "Epoch: [97] [ 380/ 548] time: 1479.1374, train_loss: -37.86287689, val_loss: -52.56920624\n",
      "Epoch: [97] [ 390/ 548] time: 1479.3812, train_loss: -51.98508835, val_loss: -51.34817886\n",
      "Epoch: [97] [ 400/ 548] time: 1479.6344, train_loss: -54.97196960, val_loss: -53.90898514\n",
      "Epoch: [97] [ 410/ 548] time: 1479.8970, train_loss: -52.23119354, val_loss: -56.29097748\n",
      "Epoch: [97] [ 420/ 548] time: 1480.1472, train_loss: -48.38653564, val_loss: -55.52040863\n",
      "Epoch: [97] [ 430/ 548] time: 1480.4437, train_loss: -58.05890656, val_loss: -52.91570663\n",
      "Epoch: [97] [ 440/ 548] time: 1480.7069, train_loss: -53.83109665, val_loss: -56.59580994\n",
      "Epoch: [97] [ 450/ 548] time: 1480.9647, train_loss: -54.19029999, val_loss: -55.36323547\n",
      "Epoch: [97] [ 460/ 548] time: 1481.2298, train_loss: -55.61164093, val_loss: -55.01460266\n",
      "Epoch: [97] [ 470/ 548] time: 1481.4650, train_loss: -53.24796295, val_loss: -55.21759415\n",
      "Epoch: [97] [ 480/ 548] time: 1481.7025, train_loss: -40.94425964, val_loss: -56.49348831\n",
      "Epoch: [97] [ 490/ 548] time: 1481.9626, train_loss: -53.35293579, val_loss: -55.33397675\n",
      "Epoch: [97] [ 500/ 548] time: 1482.3023, train_loss: -51.23264313, val_loss: -57.13916779\n",
      "Epoch: [97] [ 510/ 548] time: 1482.6089, train_loss: -53.03385925, val_loss: -55.52695465\n",
      "Epoch: [97] [ 520/ 548] time: 1482.8869, train_loss: -47.49339294, val_loss: -55.98388672\n",
      "Epoch: [97] [ 530/ 548] time: 1483.2173, train_loss: -55.06976318, val_loss: -57.21516800\n",
      "Epoch: [97] [ 540/ 548] time: 1483.5024, train_loss: -60.16469193, val_loss: -57.72983170\n",
      "Epoch: [98] [   0/ 548] time: 1483.7750, train_loss: -55.32006073, val_loss: -57.51169205\n",
      "Epoch: [98] [  10/ 548] time: 1484.1144, train_loss: -55.20828629, val_loss: -57.38206482\n",
      "Epoch: [98] [  20/ 548] time: 1484.4499, train_loss: -47.16690826, val_loss: -56.82278442\n",
      "Epoch: [98] [  30/ 548] time: 1484.7864, train_loss: -57.30168152, val_loss: -57.74074554\n",
      "Epoch: [98] [  40/ 548] time: 1485.0977, train_loss: -53.74960327, val_loss: -57.07765961\n",
      "Epoch: [98] [  50/ 548] time: 1485.3846, train_loss: -39.36588287, val_loss: -57.27832794\n",
      "Epoch: [98] [  60/ 548] time: 1485.6738, train_loss: -59.48214340, val_loss: -57.63697815\n",
      "Epoch: [98] [  70/ 548] time: 1485.9593, train_loss: -58.02883911, val_loss: -57.01180649\n",
      "Epoch: [98] [  80/ 548] time: 1486.2256, train_loss: -55.93810272, val_loss: -57.33895111\n",
      "Epoch: [98] [  90/ 548] time: 1486.5241, train_loss: -53.85437393, val_loss: -57.73557281\n",
      "Epoch: [98] [ 100/ 548] time: 1486.7824, train_loss: -52.80142212, val_loss: -56.72099304\n",
      "Epoch: [98] [ 110/ 548] time: 1487.0506, train_loss: -52.59630585, val_loss: -56.46141434\n",
      "Epoch: [98] [ 120/ 548] time: 1487.3164, train_loss: -55.52690887, val_loss: -56.01504517\n",
      "Epoch: [98] [ 130/ 548] time: 1487.6080, train_loss: -54.45494080, val_loss: -57.04825211\n",
      "Epoch: [98] [ 140/ 548] time: 1487.8633, train_loss: -43.11925888, val_loss: -56.60869980\n",
      "Epoch: [98] [ 150/ 548] time: 1488.1243, train_loss: -50.64662170, val_loss: -56.53188705\n",
      "Epoch: [98] [ 160/ 548] time: 1488.3852, train_loss: -57.03931808, val_loss: -55.34430695\n",
      "Epoch: [98] [ 170/ 548] time: 1488.6309, train_loss: -59.49552917, val_loss: -54.86391449\n",
      "Epoch: [98] [ 180/ 548] time: 1488.8762, train_loss: -57.46214676, val_loss: -55.34613800\n",
      "Epoch: [98] [ 190/ 548] time: 1489.1242, train_loss: -46.91761017, val_loss: -48.92893219\n",
      "Epoch: [98] [ 200/ 548] time: 1489.3667, train_loss: -53.62082672, val_loss: -49.23645401\n",
      "Epoch: [98] [ 210/ 548] time: 1489.6079, train_loss: -47.10069275, val_loss: -52.79177094\n",
      "Epoch: [98] [ 220/ 548] time: 1489.8451, train_loss: -42.72043228, val_loss: -48.78932190\n",
      "Epoch: [98] [ 230/ 548] time: 1490.0859, train_loss: -38.02706146, val_loss: -41.80122375\n",
      "Epoch: [98] [ 240/ 548] time: 1490.3393, train_loss: -53.48360443, val_loss: -54.58996964\n",
      "Epoch: [98] [ 250/ 548] time: 1490.5999, train_loss: -39.86912537, val_loss: -55.78620911\n",
      "Epoch: [98] [ 260/ 548] time: 1490.8802, train_loss: -56.48878098, val_loss: -54.92026520\n",
      "Epoch: [98] [ 270/ 548] time: 1491.1347, train_loss: -55.80458832, val_loss: -56.64489746\n",
      "Epoch: [98] [ 280/ 548] time: 1491.3990, train_loss: -47.08585739, val_loss: -55.71910858\n",
      "Epoch: [98] [ 290/ 548] time: 1491.6807, train_loss: -48.97565842, val_loss: -56.28841782\n",
      "Saving checkpoint\n",
      "Epoch: [98] [ 300/ 548] time: 1493.4012, train_loss: -55.77115250, val_loss: -55.96004105\n",
      "Epoch: [98] [ 310/ 548] time: 1493.7303, train_loss: -45.72204590, val_loss: -56.27111435\n",
      "Epoch: [98] [ 320/ 548] time: 1494.0406, train_loss: -52.84072113, val_loss: -56.34918976\n",
      "Epoch: [98] [ 330/ 548] time: 1494.3203, train_loss: -55.31859589, val_loss: -56.67270279\n",
      "Epoch: [98] [ 340/ 548] time: 1494.6128, train_loss: -58.37210083, val_loss: -57.60861206\n",
      "Epoch: [98] [ 350/ 548] time: 1494.8891, train_loss: -56.58688354, val_loss: -57.85256577\n",
      "Epoch: [98] [ 360/ 548] time: 1495.2060, train_loss: -53.63774872, val_loss: -57.16270828\n",
      "Epoch: [98] [ 370/ 548] time: 1495.4875, train_loss: -55.52429962, val_loss: -56.41769409\n",
      "Epoch: [98] [ 380/ 548] time: 1495.7522, train_loss: -58.70684052, val_loss: -56.75330734\n",
      "Epoch: [98] [ 390/ 548] time: 1496.0259, train_loss: -50.93744659, val_loss: -56.91231537\n",
      "Epoch: [98] [ 400/ 548] time: 1496.3119, train_loss: -56.15525055, val_loss: -56.31008530\n",
      "Epoch: [98] [ 410/ 548] time: 1496.6048, train_loss: -55.54159546, val_loss: -57.04327393\n",
      "Epoch: [98] [ 420/ 548] time: 1496.8936, train_loss: -52.48947144, val_loss: -56.93676376\n",
      "Epoch: [98] [ 430/ 548] time: 1497.1592, train_loss: -59.32570648, val_loss: -57.24378204\n",
      "Epoch: [98] [ 440/ 548] time: 1497.4251, train_loss: -57.50929260, val_loss: -57.86950302\n",
      "Epoch: [98] [ 450/ 548] time: 1497.6888, train_loss: -57.37757492, val_loss: -56.12808228\n",
      "Epoch: [98] [ 460/ 548] time: 1497.9364, train_loss: -54.97607422, val_loss: -57.93423843\n",
      "Epoch: [98] [ 470/ 548] time: 1498.2113, train_loss: -56.79068375, val_loss: -57.66963959\n",
      "Epoch: [98] [ 480/ 548] time: 1498.4646, train_loss: -56.68722534, val_loss: -55.11578369\n",
      "Epoch: [98] [ 490/ 548] time: 1498.7391, train_loss: -57.08324051, val_loss: -56.63364029\n",
      "Epoch: [98] [ 500/ 548] time: 1498.9955, train_loss: -53.34191895, val_loss: -56.60905457\n",
      "Epoch: [98] [ 510/ 548] time: 1499.2741, train_loss: -59.15524292, val_loss: -58.01876068\n",
      "Epoch: [98] [ 520/ 548] time: 1499.5380, train_loss: -48.34308624, val_loss: -57.34512711\n",
      "Epoch: [98] [ 530/ 548] time: 1499.7955, train_loss: -50.89793396, val_loss: -56.70050049\n",
      "Epoch: [98] [ 540/ 548] time: 1500.0938, train_loss: -54.00789261, val_loss: -57.60891342\n",
      "Epoch: [99] [   0/ 548] time: 1500.2971, train_loss: -51.48914337, val_loss: -57.31637955\n",
      "Epoch: [99] [  10/ 548] time: 1500.5449, train_loss: -55.52757263, val_loss: -57.28414917\n",
      "Epoch: [99] [  20/ 548] time: 1500.7896, train_loss: -57.46356964, val_loss: -58.10201263\n",
      "Epoch: [99] [  30/ 548] time: 1501.0425, train_loss: -59.49021912, val_loss: -57.38263702\n",
      "Epoch: [99] [  40/ 548] time: 1501.3114, train_loss: -54.58723450, val_loss: -57.06745148\n",
      "Epoch: [99] [  50/ 548] time: 1501.5613, train_loss: -4.27156830, val_loss: -53.42162323\n",
      "Epoch: [99] [  60/ 548] time: 1501.8137, train_loss: -40.75775528, val_loss: -55.61555862\n",
      "Epoch: [99] [  70/ 548] time: 1502.1061, train_loss: -51.16235733, val_loss: -56.39603806\n",
      "Epoch: [99] [  80/ 548] time: 1502.4658, train_loss: -49.69478989, val_loss: -52.69308472\n",
      "Epoch: [99] [  90/ 548] time: 1502.7890, train_loss: -51.64583588, val_loss: -56.89040375\n",
      "Epoch: [99] [ 100/ 548] time: 1503.1208, train_loss: -45.01177216, val_loss: -55.65774918\n",
      "Epoch: [99] [ 110/ 548] time: 1503.4905, train_loss: -44.24208450, val_loss: -55.72639847\n",
      "Epoch: [99] [ 120/ 548] time: 1503.9207, train_loss: -60.00282669, val_loss: -55.16958237\n",
      "Epoch: [99] [ 130/ 548] time: 1504.2868, train_loss: -51.93228149, val_loss: -55.69384766\n",
      "Epoch: [99] [ 140/ 548] time: 1504.6318, train_loss: -53.58418274, val_loss: -53.57595062\n",
      "Epoch: [99] [ 150/ 548] time: 1504.9671, train_loss: -57.70309067, val_loss: -53.60130692\n",
      "Epoch: [99] [ 160/ 548] time: 1505.2728, train_loss: -57.77111053, val_loss: -52.99377060\n",
      "Epoch: [99] [ 170/ 548] time: 1505.6156, train_loss: -57.55535507, val_loss: -53.17525482\n",
      "Epoch: [99] [ 180/ 548] time: 1505.9153, train_loss: -58.96326828, val_loss: -55.67704010\n",
      "Epoch: [99] [ 190/ 548] time: 1506.2102, train_loss: -58.17404175, val_loss: -55.55686951\n",
      "Epoch: [99] [ 200/ 548] time: 1506.5031, train_loss: -51.42856598, val_loss: -57.06806564\n",
      "Epoch: [99] [ 210/ 548] time: 1506.8277, train_loss: -40.62926483, val_loss: -57.54672241\n",
      "Epoch: [99] [ 220/ 548] time: 1507.2293, train_loss: -54.41464233, val_loss: -58.34984589\n",
      "Epoch: [99] [ 230/ 548] time: 1507.5833, train_loss: -50.11618042, val_loss: -57.88350296\n",
      "Epoch: [99] [ 240/ 548] time: 1507.9484, train_loss: -45.64186859, val_loss: -57.36968613\n",
      "Epoch: [99] [ 250/ 548] time: 1508.3087, train_loss: -54.57261658, val_loss: -56.49551010\n",
      "Epoch: [99] [ 260/ 548] time: 1508.6439, train_loss: -55.93759155, val_loss: -57.15456009\n",
      "Epoch: [99] [ 270/ 548] time: 1508.9866, train_loss: -57.78998184, val_loss: -57.78059387\n",
      "Epoch: [99] [ 280/ 548] time: 1509.3661, train_loss: -54.78121948, val_loss: -58.26966476\n",
      "Epoch: [99] [ 290/ 548] time: 1509.7505, train_loss: -60.49210739, val_loss: -57.70323563\n",
      "Epoch: [99] [ 300/ 548] time: 1510.1399, train_loss: -51.11313629, val_loss: -56.86154556\n",
      "Epoch: [99] [ 310/ 548] time: 1510.5130, train_loss: -55.28875351, val_loss: -58.08087158\n",
      "Epoch: [99] [ 320/ 548] time: 1510.8713, train_loss: -54.39946747, val_loss: -57.64128494\n",
      "Epoch: [99] [ 330/ 548] time: 1511.2255, train_loss: -60.14873886, val_loss: -57.27873230\n",
      "Epoch: [99] [ 340/ 548] time: 1511.5391, train_loss: -56.68421555, val_loss: -57.10975266\n",
      "Epoch: [99] [ 350/ 548] time: 1511.8392, train_loss: -56.71948242, val_loss: -56.84341812\n",
      "Epoch: [99] [ 360/ 548] time: 1512.1283, train_loss: -57.60361099, val_loss: -57.43035507\n",
      "Epoch: [99] [ 370/ 548] time: 1512.4218, train_loss: -57.79586029, val_loss: -58.48244095\n",
      "Epoch: [99] [ 380/ 548] time: 1512.7228, train_loss: -59.23623276, val_loss: -57.34413910\n",
      "Epoch: [99] [ 390/ 548] time: 1513.0400, train_loss: -57.39055634, val_loss: -58.02698135\n",
      "Epoch: [99] [ 400/ 548] time: 1513.3382, train_loss: -53.85265350, val_loss: -55.29360199\n",
      "Epoch: [99] [ 410/ 548] time: 1513.6436, train_loss: -56.38710403, val_loss: -56.82986450\n",
      "Epoch: [99] [ 420/ 548] time: 1513.9826, train_loss: -53.10604477, val_loss: -58.11824799\n",
      "Epoch: [99] [ 430/ 548] time: 1514.2868, train_loss: -61.75395584, val_loss: -57.86006165\n",
      "Epoch: [99] [ 440/ 548] time: 1514.5919, train_loss: -57.93521881, val_loss: -57.70204544\n",
      "Epoch: [99] [ 450/ 548] time: 1514.8952, train_loss: -58.20181274, val_loss: -58.43428421\n",
      "Epoch: [99] [ 460/ 548] time: 1515.2030, train_loss: -60.24020004, val_loss: -58.07888412\n",
      "Epoch: [99] [ 470/ 548] time: 1515.5086, train_loss: -57.58610916, val_loss: -57.67499924\n",
      "Epoch: [99] [ 480/ 548] time: 1515.8152, train_loss: -54.58872223, val_loss: -57.80982208\n",
      "Epoch: [99] [ 490/ 548] time: 1516.1122, train_loss: -57.43150330, val_loss: -58.08917999\n",
      "Epoch: [99] [ 500/ 548] time: 1516.4166, train_loss: -53.05672455, val_loss: -56.76840973\n",
      "Epoch: [99] [ 510/ 548] time: 1516.7380, train_loss: -52.04347992, val_loss: -55.95711517\n",
      "Epoch: [99] [ 520/ 548] time: 1517.0685, train_loss: -48.64231873, val_loss: -56.34606171\n",
      "Epoch: [99] [ 530/ 548] time: 1517.3994, train_loss: -56.52018356, val_loss: -56.86612320\n",
      "Epoch: [99] [ 540/ 548] time: 1517.7267, train_loss: -54.53167725, val_loss: -56.46738815\n"
     ]
    }
   ],
   "source": [
    "cfg = MLP_DM_cfg\n",
    "cfg[\"lr\"] = 5e-4\n",
    "cfg[\"batch_size\"] = 10\n",
    "cfg[\"n_epochs\"] = 100\n",
    "cfg[\"store_val\"] = True\n",
    "with sess.as_default():\n",
    "    pdm.train(transitions, cfg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
